issue
feat: prototype of higher-level API and helper functions#TITLE_END#* Addresses issue #4064 by providing a much-needed parallelization API (`NxParallel`) for Networkx that aspires to be backend-agnostic by leveraging a joblib framework. * Supports default multiprocessing, loky, and threading backends, and by extension ipyparallel, dask, and ray backends with associated optional imports as well. * The API avoids the need to write redundant _parallel variants of each parallelizable algorithm. Rather, to minimize footprint and avoid breaking changes across the repo, capitalizing on the API to parallelize existing or future NetworkX algorithms would simply involve adding an additional kwarg to the algorithm of interest, where the kwarg consumes a single callable instance generated by `NxParallel`. * Harmonizes the efforts in several PR's:   - https://github.com/networkx/networkx/pull/2265   - https://github.com/networkx/networkx/pull/3440   - https://github.com/networkx/networkx/pull/3581   - https://github.com/networkx/networkx/pull/3587   - https://github.com/networkx/networkx/pull/4007  * Builds upon the work done in `https://github.com/networkx/networkx/blob/master/examples/advanced/plot_parallel_betweenness.py`  * Includes unit testing.  * Something like `pip install networkx[parallel]` might be a nice bottom-line for ultimately addressing the added joblib dependency, but the current dependency handling in this PR should be considered a stub, and will likely still need to undergo strategic planning by the NetworkX core team.  * Pending any other necessary revisions, this PR will still need to add a brief developer guide + example of usage before it can be merged.   Happy new year,  @dPys
issue
draw_networkx_edges breaks with latest matplotlib-3.3.0#TITLE_END#FYI   ```     def draw_networkx_edges(G, pos,                             edgelist=None,                             width=1.0,                             edge_color='k',                             style='solid',                             alpha=1.0,                             arrowstyle='-|>',                             arrowsize=10,                             edge_cmap=None,                             edge_vmin=None,                             edge_vmax=None,                             ax=None,                             arrows=True,                             label=None,                             node_size=300,                             nodelist=None,                             node_shape="o",                             connectionstyle=None,                             **kwds):         """Draw the edges of the graph G.              This draws only the edges of the graph G.              Parameters         ----------         G : graph            A networkx graph              pos : dictionary            A dictionary with nodes as keys and positions as values.            Positions should be sequences of length 2.              edgelist : collection of edge tuples            Draw only specified edges(default=G.edges())              width : float, or array of floats            Line width of edges (default=1.0)              edge_color : color string, or array of floats            Edge color. Can be a single color format string (default='r'),            or a sequence of colors with the same length as edgelist.            If numeric values are specified they will be mapped to            colors using the edge_cmap and edge_vmin,edge_vmax parameters.              style : string            Edge line style (default='solid') (solid|dashed|dotted,dashdot)              alpha : float            The edge transparency (default=1.0)              edge_ cmap : Matplotlib colormap            Colormap for mapping intensities of edges (default=None)              edge_vmin,edge_vmax : floats            Minimum and maximum for edge colormap scaling (default=None)              ax : Matplotlib Axes object, optional            Draw the graph in the specified Matplotlib axes.              arrows : bool, optional (default=True)            For directed graphs, if True draw arrowheads.            Note: Arrows will be the same color as edges.              arrowstyle : str, optional (default='-|>')            For directed graphs, choose the style of the arrow heads.            See :py:class: `matplotlib.patches.ArrowStyle` for more            options.              arrowsize : int, optional (default=10)            For directed graphs, choose the size of the arrow head head's length and            width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute            `mutation_scale` for more info.              connectionstyle : str, optional (default=None)            Pass the connectionstyle parameter to create curved arc of rounding            radius rad. For example, connectionstyle='arc3,rad=0.2'.            See :py:class: `matplotlib.patches.ConnectionStyle` and            :py:class: `matplotlib.patches.FancyArrowPatch` for more info.              label : [None| string]            Label for legend              Returns         -------         matplotlib.collection.LineCollection             `LineCollection` of the edges              list of matplotlib.patches.FancyArrowPatch             `FancyArrowPatch` instances of the directed edges              Depending whether the drawing includes arrows or not.              Notes         -----         For directed graphs, arrows are drawn at the head end.  Arrows can be         turned off with keyword arrows=False. Be sure to include `node_size` as a         keyword argument; arrows are drawn considering the size of nodes.              Examples         --------         >>> G = nx.dodecahedral_graph()         >>> edges = nx.draw_networkx_edges(G, pos=nx.spring_layout(G))              >>> G = nx.DiGraph()         >>> G.add_edges_from([(1, 2), (1, 3), (2, 3)])         >>> arcs = nx.draw_networkx_edges(G, pos=nx.spring_layout(G))         >>> alphas = [0.3, 0.4, 0.5]         >>> for i, arc in enumerate(arcs):  # change alpha values of arcs         ...     arc.set_alpha(alphas[i])              Also see the NetworkX drawing examples at         https://networkx.github.io/documentation/latest/auto_examples/index.html              See Also         --------         draw()         draw_networkx()         draw_networkx_nodes()         draw_networkx_labels()         draw_networkx_edge_labels()         """         try:             import matplotlib             import matplotlib.pyplot as plt             import matplotlib.cbook as cb             from matplotlib.colors import colorConverter, Colormap, Normalize             from matplotlib.collections import LineCollection             from matplotlib.patches import FancyArrowPatch             import numpy as np         except ImportError:             raise ImportError("Matplotlib required for draw()")         except RuntimeError:             print("Matplotlib unable to open display")             raise              if ax is None:             ax = plt.gca()              if edgelist is None:             edgelist = list(G.edges())              if not edgelist or len(edgelist) == 0:  # no edges!             return None              if nodelist is None:             nodelist = list(G.nodes())              # set edge positions         edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist])      >       if not cb.iterable(width): E       AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'  /opt/circleci/.pyenv/versions/3.6.5/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py:579: AttributeError ```  cbook.iterable is now deprecated. Should just be a quick swap out with np.iterable?
comment
@stefanv @jarrodmillman @MridulS @SultanOrazbayev   Not sure where this discussion went, but as an avid user of many parallelizable NetworkX algorithms, I still see a pressing need for this functionality, and would really like to help out.  Per the wish-list from the above comments, below is a prototype for a higher-level, joblib-centric API that provides an easy framework for developers who'd like to parallelize existing (or future) algorithms in the package. The API avoids the need to write redundant `_parallel` variants of each parallelizable algorithm. Rather, it instead just requires invoking a single `parallel_callable` kwarg to existing algorithms that avoids creating major breaking changes across the repo. The API, which is really just a callable-generating class, aspires to be backend-agnostic and verifiably works with multiprocessing, dask, ray, loky, threading, and ipyparallel backends.  ``` from typing import Callable, Iterable, Tuple, Optional  SUPPORTED_BACKENDS = ['multiprocessing', 'dask', 'ray', 'loky', 'threading', 'ipyparallel']  class NxParallel:     """A class to instantiate a callable object for handling parallelization of functions in      NetworkX. The class is initialized by specifying a backend and the number of processes to use,      and can then be called with a function object and an associated iterable as input. The      function will be called on each element of the iterable in parallel. The class can be used      with the multiprocessing, ipyparallel, dask, ray, and other native joblib backends.          Attributes     ----------     backend : str         The backend to use. Choose from 'multiprocessing', 'dask', 'ray', 'loky', 'threading',          'ipyparallel'.     processes : int         The number of processes to use. If None, the number of processes will be set to the number         of CPUs on the machine.      Raises     ------     `ImportError`         If joblib, or any of the optional backends are not installed.     `ValueError`         If an invalid backend is specified, or if the number of elements in the provided          iterable is not equal to the number of parameters in the provided function.              """     def __init__(self, backend: str='multiprocessing', processes: Optional[int]=None, **kwargs):         try:             import joblib         except ImportError:             raise ImportError("joblib is not installed. Install joblib using 'pip install joblib'.")         self.backend = backend         if processes is None:             from os import cpu_count             self.processes = cpu_count()         else:             self.processes = processes                  if self.backend in SUPPORTED_BACKENDS:             # Business logic restricted to this block             if self.backend == 'dask':                 try:                     from dask.distributed import Client                     from joblib._dask import DaskDistributedBackend                 except ImportError:                     raise ImportError("dask is not installed. Install dask using 'pip install dask distributed'.")                 client = Client(**kwargs)                 joblib.register_parallel_backend('dask', lambda : DaskDistributedBackend(client=client))             elif self.backend == 'ray':                 try:                     from ray.util.joblib.ray_backend import RayBackend                 except ImportError:                     raise ImportError("ray is not installed. Install ray using 'pip install ray'.")                 rb = RayBackend(**kwargs)                 joblib.register_parallel_backend("ray", lambda : rb)             elif self.backend == 'ipyparallel':                 try:                     from ipyparallel import Client                     from ipyparallel.joblib import IPythonParallelBackend                 except ImportError:                     raise ImportError("ipyparallel is not installed. Install ipyparallel using 'pip install ipyparallel'.")                 c = Client(**kwargs)                 bview = c.load_balanced_view()                 joblib.register_parallel_backend('ipyparallel', lambda : IPythonParallelBackend(view=bview))         else:             raise ValueError(                 f"Invalid backend specified. Choose from {SUPPORTED_BACKENDS}.")      def __call__(self, func: Callable, iterable: Iterable[Tuple], **kwargs):         """Call the class instance with a function and an iterable.          The function will be called on each element of the iterable in parallel."""         import joblib, inspect         params = list(inspect.signature(func).parameters.keys())          with joblib.parallel_backend(self.backend):             return joblib.Parallel(n_jobs=self.processes, **kwargs)(joblib.delayed(func)(**dict(zip(params, i))) for i in iterable) ```  In the spirit of the `betweenness_centrality` example, this would be used as follows: ```     import time     import itertools     import networkx as nx      # Create an instance of the NxParallel class     nx_parallel = NxParallel(backend='dask', processes=8)      G_ba = nx.barabasi_albert_graph(1000, 3)     G_er = nx.gnp_random_graph(1000, 0.01)     G_ws = nx.connected_watts_strogatz_graph(1000, 4, 0.1)              def chunks(l, n):         """Divide a list of nodes `l` in `n` chunks"""         l_c = iter(l)         while 1:             x = tuple(itertools.islice(l_c, n))             if not x:                 return             yield x       def betweenness_centrality(G, parallel_callable=nx_parallel):         """Parallel betweenness centrality function"""         node_divisor = parallel_callable.processes * 4         node_chunks = list(chunks(G.nodes(), G.order() // node_divisor))         num_chunks = len(node_chunks)         iterable = zip(                 [G] * num_chunks,                 node_chunks,                 [list(G)] * num_chunks,                 [True] * num_chunks,                 [None] * num_chunks,             )         bt_sc = parallel_callable(nx.betweenness_centrality_subset, iterable)          # Reduce the partial solutions         bt_c = bt_sc[0]         for bt in bt_sc[1:]:             for n in bt:                 bt_c[n] += bt[n]         return bt_c       G_ba = nx.barabasi_albert_graph(1000, 3)     G_er = nx.gnp_random_graph(1000, 0.01)     G_ws = nx.connected_watts_strogatz_graph(1000, 4, 0.1)     for G in [G_ba, G_er, G_ws]:         print("\nComputing betweenness centrality for:")         print(nx.info(G))         print("\tParallel version")         start = time.time()         bt = betweenness_centrality(G, nx_parallel)         print(f"\t\tTime: {(time.time() - start):.4F} seconds")         print(f"\t\tBetweenness centrality for node 0: {bt[0]:.5f}")         print("\tNon-Parallel version")         start = time.time()         bt = nx.betweenness_centrality(G)         print(f"\t\tTime: {(time.time() - start):.4F} seconds")         print(f"\t\tBetweenness centrality for node 0: {bt[0]:.5f}\n") ```  I would love to at least start a PR with something like this (including tests), if it at all interests the NetworkX team?  @dPys
