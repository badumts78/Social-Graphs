issue
[WIP] Graph edit distance 2361#TITLE_END#An implementation of https://github.com/networkx/networkx/issues/2361 . On my system this works terribly slow on not-so-similar graphs, but hopefully this serves as initial step.
issue
Shortest path algorithms with restrictions#TITLE_END#Many interesting algorithms e.g. Yen's k-shortest simple paths, White's node-independent paths require a procedure for finding shortest path with restrictions: - ignore a subset of graph nodes - ignore certain graph edges  It is proposed to introduce optional ignore_nodes and ignore_edges parameters for all shortest path procedures.  Here is the initial version (only supporting shortest_path, unweighted case). 
issue
Native serialization to GraphViz DOT#TITLE_END#Currently NetworkX uses PyGraphViz or PyDot to read/write graphs in DOT format. However, both options suffer from fatal drawbacks: - PyGraphViz is very hard/impossible to install on MS Windows. - PyDot requires too much memory (for some 5000 nodes/100000 edges digraph, PyDot did consume 2GB and died).  It is proposed that NetworkX implements it's own fast and efficient DOT serialization procedures. Understanding that complete DOT file format is not trivial, it is proposed that NetworkX implements a subset of DOT file specification. It turns out that attached read_simple_dot/write_simple_dot (see below) work surprisingly well in majority of cases.  It is essential that serialization procedures can work on file-like objects. The implementation should of course be improved (spacing, quoting, pyparsing instead of regexps in read_simple_dot), but I hope it could be used as a inspiration/starting point.  ``` python def read_simple_dot(dotfile):     """A (very) naive GraphViz DOT file reader.     dotfile: file-like object,     returns networkx.DiGraph."""      def parseattrs(line):         if line:             attrs = OrderedDict()             for rec in line.split(', '):                 (key, value) = rec.split('=')                 attrs[key] = value             return attrs         else:             return      head = re.compile(r'strict digraph ("?)([^"]+)(\1) {$')     node = re.compile(r'([^-]+?)( \[(.+)\])?;$')     edge = re.compile(r'([^-]+?)->([^-]+?)( \[(.+)\])?;$')     foot = re.compile(r'}')     for line in dotfile.readlines():         m = head.match(line)         if m:             graph = nx.DiGraph(name = m.group(2))         m = node.match(line)         if m:             graph.add_node(m.group(1), parseattrs(m.group(3)))         m = edge.match(line)         if m:             graph.add_edge(m.group(1), m.group(2), parseattrs(m.group(4)))         m = foot.match(line)         if m:             return graph ```  ``` python def write_simple_dot(graph, dotfile):     """A (very) naive GraphViz DOT file writer.     graph: networkx.DiGraph,     dotfile: file-like object."""      def writerec(rec, attrs):         dotfile.write(rec)         if attrs:             dotfile.write(' [' + ', '.join('='.join([key, value])                                            for key, value in attrs.iteritems()) + ']')         dotfile.write(';\n')      dotfile.write('strict digraph "' + graph.name + '" {\n')     for node, attrs in graph.nodes(data = True):         writerec(node, attrs)     for u, v, attrs in graph.edges(data = True):         writerec('->'.join([u, v]), attrs)     dotfile.write('}\n') ``` 
issue
Shortest path algorithms with restrictions#TITLE_END#Many interesting algorithms e.g. Yen's k-shortest simple paths, White's node-independent paths require a procedure for finding shortest path with restrictions: - ignore a subset of graph nodes - ignore certain graph edges  It is proposed to introduce optional ignore_nodes and ignore_edges parameters for all shortest path procedures. 
comment
I am willing to try implement it for small graphs (molecules) using [DF-GED](https://hal-univ-tours.archives-ouvertes.fr/hal-01168816/document) algorithm.
comment
Please review initial implementation sketch: https://github.com/aparamon/networkx/commit/9095478b6e1daef55e663d966d091e7a4ae50d2f I'm considering replacing **node_match/edge_match** with **node_cost/edge_cost** which would provide more flexibility but would disable usage of existing isomorphism helpers **categorical_node_match, numerical_node_match** etc, and make code a bit more complicated. What do you think?
comment
Now works faster: https://github.com/aparamon/networkx/commit/83821ed2519900fba224586fc7e984690f2eef05 However even faster performance is desired. Current bottleneck is **linear_sum_assignment**, but in fact slightly suboptimal solution should do equally well. Any suggestions wrt greedy linear sum assignment algorithms welcome ;-)
comment
@ramaroberto  I think the question is whether additional dependency is Ok for networkx. Hopefully my code gets approved soon, so we can make your change an additional Pull request.  Thank you for your contribution!
comment
@Silberschleier Your contribution would be very welcome! I think you could fork my branch https://github.com/aparamon/networkx/tree/graph-edit-distance-2361 to share your implementation.  @ramaroberto Agree about the timeout feature. It is called "anytime GED" in the literature, and can readily be achieved by adding an *external* timeout when using advanced interface `optimize_graph_edit_distance`/`optimize_edit_paths`. Due to depth-first nature of the algorithm, *some* solution is always found very quickly.
comment
Hello!  I've just discovered a rare edge matching problem, the fix is below. The important part is ``` -            inf = Ce.C.max()  # always has at least one inf +            inf = min(min(Ce.C.sum(axis = 0)), min(Ce.C.sum(axis = 1))) + 1 ```  For some reason, I cannot push changes to github any more due to some cryptic ssh keys problem. It would be awesome if someone could commit the fix.  Thank you for your patience.  ``` diff --git a/networkx/algorithms/similarity.py b/networkx/algorithms/similarity.py index 9c5d664..a1fd1a7 100644 --- a/networkx/algorithms/similarity.py +++ b/networkx/algorithms/similarity.py @@ -285,7 +285,7 @@ def optimal_edit_paths(G1, G2, node_match=None, edge_match=None,                              node_subst_cost, node_del_cost, node_ins_cost,                              edge_subst_cost, edge_del_cost, edge_ins_cost,                              upper_bound, False): -        assert bestcost is None or cost <= bestcost +        #assert bestcost is None or cost <= bestcost          if bestcost is not None and cost < bestcost:              paths = list()          paths.append((vertex_path, edge_path)) @@ -556,49 +556,49 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,        class CostMatrix:          def __init__(self, C, lsa_row_ind, lsa_col_ind, ls): -            ##assert C.shape[0] == len(lsa_row_ind) -            ##assert C.shape[1] == len(lsa_col_ind) -            ##assert len(lsa_row_ind) == len(lsa_col_ind) -            ##assert set(lsa_row_ind) == set(range(len(lsa_row_ind))) -            ##assert set(lsa_col_ind) == set(range(len(lsa_col_ind))) -            ##assert ls == C[lsa_row_ind, lsa_col_ind].sum() +            #assert C.shape[0] == len(lsa_row_ind) +            #assert C.shape[1] == len(lsa_col_ind) +            #assert len(lsa_row_ind) == len(lsa_col_ind) +            #assert set(lsa_row_ind) == set(range(len(lsa_row_ind))) +            #assert set(lsa_col_ind) == set(range(len(lsa_col_ind))) +            #assert ls == C[lsa_row_ind, lsa_col_ind].sum()              self.C = C              self.lsa_row_ind = lsa_row_ind              self.lsa_col_ind = lsa_col_ind              self.ls = ls        def make_CostMatrix(C, m, n): -        ##assert(C.shape == (m + n, m + n)) +        #assert(C.shape == (m + n, m + n))          lsa_row_ind, lsa_col_ind = linear_sum_assignment(C)            # Fixup dummy assignments:          # each substitution i<->j should have corresponding dummy assignment m+j<->n+i          # NOTE: fast reduce of Cv relies on it -        ##assert len(lsa_row_ind) == len(lsa_col_ind) +        #assert len(lsa_row_ind) == len(lsa_col_ind)          subst_ind = list(k for k, i, j in zip(range(len(lsa_row_ind)), lsa_row_ind, lsa_col_ind)                           if i < m and j < n)          dummy_ind = list(k for k, i, j in zip(range(len(lsa_row_ind)), lsa_row_ind, lsa_col_ind)                           if i >= m and j >= n) -        ##assert len(subst_ind) == len(dummy_ind) +        #assert len(subst_ind) == len(dummy_ind)          lsa_row_ind[dummy_ind] = lsa_col_ind[subst_ind] + m          lsa_col_ind[dummy_ind] = lsa_row_ind[subst_ind] + n            return CostMatrix(C, lsa_row_ind, lsa_col_ind, C[lsa_row_ind, lsa_col_ind].sum())        def extract_C(C, i, j, m, n): -        ##assert(C.shape == (m + n, m + n)) +        #assert(C.shape == (m + n, m + n))          row_ind = [k in i or k - m in j for k in range(m + n)]          col_ind = [k in j or k - n in i for k in range(m + n)]          return C[row_ind,:][:,col_ind]        def reduce_C(C, i, j, m, n): -        ##assert(C.shape == (m + n, m + n)) +        #assert(C.shape == (m + n, m + n))          row_ind = [k not in i and k - m not in j for k in range(m + n)]          col_ind = [k not in j and k - n not in i for k in range(m + n)]          return C[row_ind,:][:,col_ind]        def reduce_ind(ind, i): -        ##assert set(ind) == set(range(len(ind))) +        #assert set(ind) == set(range(len(ind)))          rind = ind[[k not in i for k in ind]]          for k in set(i):              rind[rind >= k] -= 1 @@ -623,7 +623,7 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,          """          M = len(pending_g)          N = len(pending_h) -        ##assert Ce.C.shape == (M + N, M + N) +        #assert Ce.C.shape == (M + N, M + N)            g_ind = list(i for i in range(M)                       if any(pending_g[i] in ((p, u), (u, p), (u, u)) @@ -636,10 +636,10 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,            if m or n:              C = extract_C(Ce.C, g_ind, h_ind, M, N) -            ##assert C.shape == (m + n, m + n) +            #assert C.shape == (m + n, m + n)                # Forbid structurally invalid matches -            inf = Ce.C.max()  # always has at least one inf +            inf = min(min(Ce.C.sum(axis = 0)), min(Ce.C.sum(axis = 1))) + 1              for k, i in zip(range(m), g_ind):                  g = pending_g[i]                  for l, j in zip(range(n), h_ind): @@ -696,7 +696,7 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,          """          m = len(pending_u)          n = len(pending_v) -        ##assert Cv.C.shape == (m + n, m + n) +        #assert Cv.C.shape == (m + n, m + n)            # 1) a vertex mapping from optimal linear sum assignment          i, j = min((k, l) for k, l in zip(Cv.lsa_row_ind, Cv.lsa_col_ind) @@ -704,7 +704,7 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,          xy, localCe = match_edges(pending_u[i] if i < m else None, pending_v[j] if j < n else None,                                    pending_g, pending_h, Ce, matched_uv)          Ce_xy = reduce_Ce(Ce, xy, len(pending_g), len(pending_h)) -        ##assert Ce.ls <= localCe.ls + Ce_xy.ls +        #assert Ce.ls <= localCe.ls + Ce_xy.ls          if prune(matched_cost + Cv.ls + localCe.ls + Ce_xy.ls):              pass          else: @@ -730,7 +730,7 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,              Cv_ij = make_CostMatrix(reduce_C(Cv.C, (i,), (j,), m, n),                                      m - 1 if i < m else m,                                      n - 1 if j < n else n) -            ##assert Cv.ls <= Cv.C[i, j] + Cv_ij.ls +            #assert Cv.ls <= Cv.C[i, j] + Cv_ij.ls              if prune(matched_cost + Cv.C[i, j] + Cv_ij.ls + Ce.ls):                  continue              xy, localCe = match_edges(pending_u[i] if i < m else None, pending_v[j] if j < n else None, @@ -738,7 +738,7 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,              if prune(matched_cost + Cv.C[i, j] + Cv_ij.ls + localCe.ls):                  continue              Ce_xy = reduce_Ce(Ce, xy, len(pending_g), len(pending_h)) -            ##assert Ce.ls <= localCe.ls + Ce_xy.ls +            #assert Ce.ls <= localCe.ls + Ce_xy.ls              if prune(matched_cost + Cv.C[i, j] + Cv_ij.ls + localCe.ls + Ce_xy.ls):                  continue              other.append(((i, j), Cv_ij, xy, Ce_xy, Cv.C[i, j] + localCe.ls)) @@ -780,23 +780,23 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,          #debug_print('pending-u:', pending_u)          #debug_print('pending-v:', pending_v)          #debug_print(Cv.C) -        ##assert list(sorted(G1.nodes)) == list(sorted(list(u for u, v in matched_uv if u is not None) + pending_u)) -        ##assert list(sorted(G2.nodes)) == list(sorted(list(v for u, v in matched_uv if v is not None) + pending_v)) +        #assert list(sorted(G1.nodes)) == list(sorted(list(u for u, v in matched_uv if u is not None) + pending_u)) +        #assert list(sorted(G2.nodes)) == list(sorted(list(v for u, v in matched_uv if v is not None) + pending_v))          #debug_print('pending-g:', pending_g)          #debug_print('pending-h:', pending_h)          #debug_print(Ce.C) -        ##assert list(sorted(G1.edges)) == list(sorted(list(g for g, h in matched_gh if g is not None) + pending_g)) -        ##assert list(sorted(G2.edges)) == list(sorted(list(h for g, h in matched_gh if h is not None) + pending_h)) +        #assert list(sorted(G1.edges)) == list(sorted(list(g for g, h in matched_gh if g is not None) + pending_g)) +        #assert list(sorted(G2.edges)) == list(sorted(list(h for g, h in matched_gh if h is not None) + pending_h))          #debug_print()            if prune(matched_cost + Cv.ls + Ce.ls):              return            if not max(len(pending_u), len(pending_v)): -            ##assert not len(pending_g) -            ##assert not len(pending_h) +            #assert not len(pending_g) +            #assert not len(pending_h)              # path completed! -            ##assert matched_cost <= maxcost.value +            #assert matched_cost <= maxcost.value              maxcost.value = min(maxcost.value, matched_cost)              yield matched_uv, matched_gh, matched_cost   @@ -805,7 +805,7 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,                                                  pending_g, pending_h, Ce, matched_cost)              for ij, Cv_ij, xy, Ce_xy, edit_cost in edit_ops:                  i, j = ij -                ##assert Cv.C[i, j] + sum(Ce.C[t] for t in xy) == edit_cost +                #assert Cv.C[i, j] + sum(Ce.C[t] for t in xy) == edit_cost                  if prune(matched_cost + edit_cost + Cv_ij.ls + Ce_xy.ls):                      continue   @@ -942,12 +942,12 @@ def optimize_edit_paths(G1, G2, node_match=None, edge_match=None,      for vertex_path, edge_path, cost in \          get_edit_paths([], pending_u, pending_v, Cv,                         [], pending_g, pending_h, Ce, 0): -        ##assert list(sorted(G1.nodes)) == list(sorted(list(u for u, v in vertex_path if u is not None))) -        ##assert list(sorted(G2.nodes)) == list(sorted(list(v for u, v in vertex_path if v is not None))) -        ##assert list(sorted(G1.edges)) == list(sorted(list(g for g, h in edge_path if g is not None))) -        ##assert list(sorted(G2.edges)) == list(sorted(list(h for g, h in edge_path if h is not None))) +        #assert list(sorted(G1.nodes)) == list(sorted(list(u for u, v in vertex_path if u is not None))) +        #assert list(sorted(G2.nodes)) == list(sorted(list(v for u, v in vertex_path if v is not None))) +        #assert list(sorted(G1.edges)) == list(sorted(list(g for g, h in edge_path if g is not None))) +        #assert list(sorted(G2.edges)) == list(sorted(list(h for g, h in edge_path if h is not None)))          #print(vertex_path, edge_path, cost, file = sys.stderr) -        ##assert cost == maxcost.value +        #assert cost == maxcost.value          yield list(vertex_path), list(edge_path), cost ```
comment
@ramaroberto I get so unlucky every time using git :-( It would be truly best if someone could just commit the fix proposed. 
comment
@dschult Yes, the other lines unify the comment style of asserts (and one assert was forgotten to be commented out). I think it would be nice to commit that too, but crucial bugfix is `inf` assignment.
comment
Hmm, strange -- I don't think any of my code is non-deterministic. Is your problem reproducible with https://github.com/networkx/networkx/pull/2798 ? 
comment
@jfbeaumont  To debug, I suggest you do the following: 1. Use `optimal_edit_paths()` to explain minimal edit cost. 2. Uncomment all `assert`s. 3. Uncomment `debug_print()` and `print()` calls, and provide the output.  Thank you for your patience!
comment
@jfbeaumont Great! Could you please provide me with debug output from Python2 version, for the sake of comparison? Could you please also try with https://github.com/networkx/networkx/pull/2798 applied?
comment
@mesnico Thank you for your comment! The `DiGraph`s and `MultiDiGraph`s are not currently supported, however adding that should be quite straight. Please look into `match_edges()`, specifically `g_ind`/`h_ind` calculation and conditions for `C[k, l] = inf` assignment. Your contribution would be really welcome, esp. if you accompany it with some nice tests!
comment
@jfbeaumont I looked into code and although I couldn't reproduce the problem, I have a suspicion that my first attempt to fix edge mapping bug was not successful in all cases. Please try the attached patch. It additionally includes your tests. [patch.txt](https://github.com/networkx/networkx/files/1571236/patch.txt) 
comment
@jfbeaumont Great! I believe it would be nice if any additional tests you might create could be committed to test_similarity.py. I think my last patch should be committed as well, as it fixes potential bugs for non-unit insertion/deletion costs, and for multigraphs (not yet supported). I propose that it is committed during digraph/multigraph support development.
comment
@jfbeaumont Thank you for your comment. I've checked and I could reproduce your problem. Albeit I don't think your test is any realistic, for me the run-time was still long even when omitting `node_match`, `edge_match`. There is a room for improvement.  I'm not sure whether the combinatorial explosion can be efficiently prevented in your case, but you could try. I propose that you try to track what's going on by un-commenting the `debug_pring`s.  Additionally, below is excerpt from my message to Zeina Abu-Aisheh, one of the algorithm article co-authors. Maybe the idea described there would help. I also remember considering storing the matrices of possible edge mappings related to a particular node mapping "inside" the node mapping matrix, but at that point I decided to postpone this complication. Please also note that there are other GED algorithms, in particular Quadratic Programming approach was reported to be (more) efficient.  ---- While working on the implementation, I was thinking about evident sub-optimality of considering `Cv` and `Ce` separately. For example, if we consider all vertices and edges compatible for the following graphs: ```   2     B  / \    |\ 1   4   | C - D  \ /    |/   3     A ``` the lower-bound estimate based solely on `Cv`, `Ce` would be 0. Taking graph structure into account initially allows to explore most promising nodes faster, but still we will get more-or-less accurate lower-bound estimate only towards edit path completion. We need to go deep enough to let lower-bound pruning become efficient.  At the same time, I believe it's possible to make initial lower-bound estimates much more accurate, by partly incorporating graph structure information into the cost matrix. Let's consider matrix `Cve` similar to `Cv` but with adjacent edge correction: `Cve_i,j = Cv_i,j + abs(N_i - N_j)`, where `N_k` is the number of edges adjacent to node `k` (for vertex replacement) `Cve_i,j = Cv_i,j + abs(N_i)/2` (for vertex insertion/deletion) (for simplicity, all edges insertions/deletions = 1)  For above example, `Cve` would be ```    A   B   C   D    1   2   3   4 1  0   0   1   1    2   ∞   ∞   ∞ 2  0   0   1   1    ∞   2   ∞   ∞ 3  0   0   1   1    ∞   ∞   2   ∞  4  0   0   1   1    ∞   ∞   ∞   2 A  2   ∞   ∞   ∞    0   0   0   0 B  ∞   2   ∞   ∞    0   0   0   0 C  ∞   ∞  2.5  ∞    0   0   0   0 D  ∞   ∞   ∞  1.5   0   0   0   0 ``` which yields accurate lower-bound estimate of graph edit distance = 2.  It seems that `Cve` could be used for more optimal selection of promising edit nodes. `Cve` could be re-built on each depth-first step (for more accurate estimates), but also can be used as-is (only rows/cols deleted) till edit path completion (for faster depth-first exploration). In the latter case, the lower-bound estimate on each step would be `Max(Munkres(Cve), Munkres(Cv) + Munkres(Ce))`. The trade-off needs to be investigated.  It's possible to build more precise `Cve` for the case of not-all-equal edges -- I'm omitting it now for simplicity.
comment
@jfbeaumont All nodes and edges in your graphs have unique labels, which seems hardly practical for GED problem statement. GED makes most sense when you have classes of compatible/match-able nodes and/or edges.  Wrt QAP GED, a quick googling by "quadratic programming graph edit distance" revealed https://hal.archives-ouvertes.fr/hal-01418937/document among others.
comment
@jfbeaumont Yes, please take a look at `optimize_graph_edit_distance` which returns intermediate approximations.
comment
@jfbeaumont Yes, the algorithm is deterministic.
comment
Hello @bgauzere! Thank you for your research work on graph similarity measures; it is inspiring what you and your French colleagues could achieve recently on the royal problem of Graph Edit Distance.  I contributed an initial GED implementation for networkx in order to start a tighter collaboration of researchers and talented coders. Your GDC 2016 contest was a great step forward; I now have in mind an ambitious task of calculating GED similarity matrix for all chemical substances from ChEBI "3 star" database: http://www.ebi.ac.uk/chebi .  With regard to the implementation, I tried to lay out a simple but flexible interface that would enable both exact and approximate GED calculation, and allow to get optimal Graph Edit Path(s). Currently, the functions `graph_edit_distance`, `optimal_edit_paths`, `optimize_graph_edit_distance` are wrappers around the workhorse `optimize_edit_paths` which does the heavy lifting. Do you think it could be possible that all these functions get an additional argument `algorithm` with a sensible default, and `optimize_graph_edit_distance` becomes a dispatcher for the actual implementations like `optimize_graph_edit_distance_riesen`, `optimize_graph_edit_distance_qap` etc?  One of the missing features of current implementation is support for `DiGraph`s and `MultiGraph`s (surprisingly, some users explicitly mentioned even the latter as actually desired). It didn't stop me from contributing the initial implementation ;-) but it's a thing to keep in mind.
comment
Hi @mesnico ! I'm not sure that additional dimension is needed for multigraph edges: `Ce` structure and matching algorithm do inherently support multiple matching items (from my memory -- but please correct me if I'm wrong). Also, I'm not quite sure that separate operation "edge flip" is a good idea. It *could* be justified given significant performance benefits, but apparantly that's not the case. Just insert/delete/edit triple should be enough. I think what you need to do it to optionally remove symmetry in `(p, u), (u, p)` and `(q, v), (v, q)` while matching edges, for directed graphs. It would be great if you could start your pull request with tests, so different implementation ideas could be checked and compared.
comment
@mozark24 The quick answer to your question is yes, please see `test_graph_edit_distance_edge_cost` for an example. Agree that the more comprehensive documentation would be a valuable addition; for now please see the doc-strings for a basic description. 
comment
I'll prepare a documentation update, but don't promise it to happen soon. Also, I'm not sure what to include there in addition to what's already present in doc-strings and tests :-)
comment
Hi @kleinias ,  probably you'll have more luck with `optimize_graph_edit_distance`.
comment
@dschult I believe the procedure should **ultimately work** for the particular example, quickly.  However, **current** algorithm/implementation is sub-optimal, for this example. Moreover, I'm pretty sure it will always be possible to find an example for which exact GED calculation is slow, as it's NP-hard. So, `optimize_graph_edit_distance` will always have its uses. The algorithm interface was designed to be both simple (`graph_edit_distance`) and flexible (`optimize_graph_edit_distance`/`optimize_edit_paths`), and if the simple interface doesn't yield good results, one has to dig a bit deeper.  At the same time, I encourage capable people to investigate alternative GED algorithms, in order to fix this particular example.
comment
Please take a look at https://github.com/networkx/networkx/pull/762 
comment
Hello Greg!  It would be great if mine or yours version could be finally integrated into NextworkX :-)  Regarding your code, I propose that instead of separate methods findFirstShortestPath, getNextShortestPath, object YenKShortestPaths uses standard Python iterator protocol (e.g. is generator, see https://wiki.python.org/moin/Generators).  Best wishes, Andrey Paramonov 
comment
2015-04-06 23:21 GMT+03:00 Greg Bernstein notifications@github.com:  > Couldn't we (NetworkX) decide on the API for a K-shortest paths algorithm > then use Andrey's or my implementation and possibly swap it out in the > future if a more efficient implementation gets implemented?  I believe that the main interface problem is that all_simple_paths name is already taken :-)  My experience suggests that the user (almost always) naturally expects simple paths to be ordered by length, and the ability to terminate the iteration prematurely is invaluable, for serious graphs. It should be the default interface for getting simple paths of a graph.  Thus, the name yen_simple_paths seems less fortunate (what is yen?). I think simple_paths is better name in this regard.  Best wishes, Andrey Paramonov 
comment
2015-04-08 6:00 GMT+03:00 Jordi Torrents notifications@github.com:  > @aparamon https://github.com/aparamon Do you think that the asserts in > shorest_simple_paths are worth keeping? I was about to remove them, but I > thought it was better to ask first. >  > I think it's safe to remove them. I've used the implementation for quite > some years by this time and didn't hit it.  Best wishes, Andrey Paramonov 
comment
Thank you Jordi for your work!  2015-04-09 2:56 GMT+03:00 Jordi Torrents notifications@github.com:  > I think we should move shortest_simple_paths to the SP package instead of > the simple_paths module in which now is. Comments on this are very > welcomed. >  >  +1 on move to SP package, if it means "Simple Paths" :-)  Probably the function can be named just simple_paths, because in fact it returns all simple paths (if not terminated), not k shortest. I think it should be the recommended interface for simple paths problem. However, this naming issue seems minor.  Best wishes, Andrey Paramonov 
comment
2015-04-13 19:35 GMT+03:00 Jordi Torrents notifications@github.com:  > @aparamon https://github.com/aparamon would you like to appear in the > credits file of NetworkX? If so, you can add a link to your webpage/github > user/whatever (see #1444 https://github.com/networkx/networkx/pull/1444 > for a recent change in this). Let me know and I'll add you to that file. >  > Please use the following information: > Andrey Paramonov > http://aparamon.msk.ru (currently down, but whatever :-) ) >  > Regarding the name, I think that shortest_simple_paths is more > informative that just simple_paths, and given that all_simple_paths is > faster I think that it will still be the most used function for getting all > simple paths between two nodes. >  > I still disagree, but I trust your decision :-)  Thank you for your work on NetworkX -- it is one awesome library!  Best wishes, Andrey Paramonov 
