issue
Strange behavior in `nx.effective_size` for the single node graph#TITLE_END#Hello! It seems I've created quite a few issue reports, and I apologize for any inconvenience. Please feel free to review them at your own pace, or you can assign them to me if I can assist in creating PR to fix them.  According to the formula ![image](https://github.com/networkx/networkx/assets/37923722/ca45adbf-b793-41cc-83b4-a8bd01be22ce) The `effective_size` should have a well-defined value of `0` for a graph with a single node. However, if we use Borgatti's method to calculate this graph, the value will lose its definition, and NetworkX will return some strange behavior:  For instance: ```Python import networkx as nx  G = nx.Graph() G.add_node(0) print(nx.effective_size(G))  G = nx.Graph([(0, 0)]) print(nx.effective_size(G)) ``` #### Result: ``` {0: nan} ZeroDivisionError ``` I am not sure whether such behaviors are expected. So it would be highly appreciated if you could further confirm and investigate it. If they are unexpected, I will create a PR to fix it by returning a single `0` if the graph contains only one node.  Best regards, Joye  ### Environment NetworkX 3.1 Python 3.10
issue
"nx.trophic_levels" returning strange INF value caused by insufficient checking for singular matrix #TITLE_END#Hello here and sorry for bothering you again. I noticed that `nx.trophic_levels` will sometimes return INF values for an unsupported graph instead of the following message. ``` networkx.exception.NetworkXError:  Trophic levels are only defined for graphs where every node has a path from a basal node (basal nodes are nodes with no incoming edges). ``` By investigating the source code, I found that the root cause may be the insufficient checking for whether the matrix can be inverse (reference [link](https://stackoverflow.com/questions/13249108/efficient-pythonic-check-for-singular-matrix)).  To solve the issue, the lines 57 to 66 of [trophic.py](https://github.com/networkx/networkx/blob/main/networkx/algorithms/centrality/trophic.py) could be changed by the following code: ```Python     if np.linalg.cond(i - p) < np.finfo((i - p).dtype).eps:         n = np.linalg.inv(i - p)     else:         # LinAlgError is raised when there is a non-basal node         msg = (             "Trophic levels are only defined for graphs where every "             + "node has a path from a basal node (basal nodes are nodes "             + "with no incoming edges)."         )         raise nx.NetworkXError(msg)  ``` After I use this effective way to check it, this problem is solved well. It would be highly appreciated if you could further confirm and investigate the issue. I will also create a PR for fixing it if you approve.  Best regards, Joye  ### Step to Reproduce Running the following Python code: ```Python import networkx as nx  edges = [(0, 5), (0, 3), (0, 33), (3, 2), (3, 24), (3, 32), (33, 1), (33, 10), (2, 3), (2, 16), (1, 33), (10, 16), (16, 4), (16, 9), (18, 11), (11, 5), (11, 21), (4, 2), (4, 33), (9, 16), (9, 26), (9, 17), (26, 19), (17, 10), (19, 10), (19, 9), (19, 7), (19, 0)] G = nx.DiGraph(edges) res = nx.trophic_levels(G) print(res[0]) ``` #### Actual Result: an extremely large positive value  #### Expected Result: ``` networkx.exception.NetworkXError ```  ### Environment Python 3.10 NetworkX 3.1
issue
Unstable and Incorrect "nx.eigenvector_centrality_numpy" result when the graph is disconnected#TITLE_END#Hello! Sorry for bothering you again! I found that when the graph is disconnected, the result of the `nx.eigenvector_centrality_numpy` is unstable and different from the `nx.eigenvector_centrality`. Here is the reduced test case with 4 nodes and 2 edges:  ### Step to Reproduce: ```Python import networkx as nx  G = nx.from_edgelist([(1, 2), (3, 4)]) print(nx.eigenvector_centrality_numpy(G)) G = nx.from_edgelist([(1, 2), (3, 4)]) print(nx.eigenvector_centrality_numpy(G)) print(nx.eigenvector_centrality(G)) ``` #### Results: ``` #nx.eigenvector_centrality_numpy (unstable!) {1: -0.14904837055016898, 2: -0.14904837055016898, 3: 0.6912196345853752, 4: 0.6912196345853752} {1: -0.18977204610658815, 2: -0.1897720461065881, 3: 0.6811655969854312, 4: 0.6811655969854313} #nx.eigenvector_centrality {1: 0.5, 2: 0.5, 3: 0.5, 4: 0.5} ``` I believe that it may be related to a logic bug in the implementation of `nx.eigenvector_centrality_numpy`. Would it be possible for you to further confirm and investigate it?  Best regards, Joye  ### Environments NetworkX: 3.1 Python: 3.10 
issue
ZeroDivisionError in "nx.global_reaching_centrality" and "nx.local_reaching_centrality" caused by the graph contains only one node.#TITLE_END#Hello! Sorry for bothering you again. When testing NetworkX, I found a `ZeroDivisonError` crash in `nx.global_reaching_centrality` when the input graph only contains one node, with the following message: ``` File "/home/qiuyang/.local/lib/python3.10/site-packages/networkx/algorithms/centrality/reaching.py", line 196, in local_reaching_centrality     return (len(paths) - 1) / (len(G) - 1) ``` I am not sure whether `reaching_centrality` has a good definition in such cases, but this `ZeroDivisonError` may not be good to show for users. Could you further help me confirm and investigate it, it would be highly appreciated.  The statement that triggers the exception is [here](https://github.com/networkx/networkx/blob/88097f7d7f798ec49eb868691dde77cf791a67ec/networkx/algorithms/centrality/reaching.py#L198).  Best regards, Joye  ### Step to Reproduce ```Python import networkx as nx  G = nx.DiGraph([(1, 1)]) G.add_node(1) print(nx.global_reaching_centrality(G)) print(nx.local_reaching_centrality(G, v=1)) ``` #### Result ``` ZeroDivisionError ``` ### Environment NetworkX 3.1 Python 3.10
issue
Adding the definition of `nx.effective_size` for isolated nodes, and solve the division error in #6916#TITLE_END#Hi all! Sorry for being late to investigate my bug reports~ Based on our discussion, I try to fix #6916 and define `effective size` for isolated nodes by giving the value `0` as the original formula.  Please feel free to tell me if my implementation needs to improve.  Best regards, Joye 
issue
Fix the recursive version of strongly_connected_components#TITLE_END#Hello! Sorry for bothering you.  I have investigated the issue of the Tarjan algorithm for `strongly_connected_components_recursive` in #6897 and tried to fix it. I believe that the root cause of the issue is that we let `cnt` be independent for different visiting in the following code: ```Python     for source in G:         if source not in visited:             yield from visit(source, cnt) ``` In addition, the updating of the `root` array also had some problems and I corrected it. Please kindly review my code for fixing, it would be highly appreciated.  Best regards, Joye 
issue
`nx.negative_edge_cycle` gets crashes for MultiDiGraph in two corner cases#TITLE_END#Hello! I found that `nx.negative_edge_cycle` will get crashes in the following two cases on MultiDiGraph that contain self-loops.  The interesting thing is that `nx.negative_edge_cycle` will not get crashes for the same test cases but in other graph types (e.g., DiGraph), and different ways to construct the same graph will lead to different error messages :P.  Please kindly run the following Python codes:  ```Python import networkx as nx G = nx.MultiDiGraph() G.add_edge(0, 0) print(nx.negative_edge_cycle(G))  G = nx.MultiDiGraph() G.add_edge(0, 0, weight = 0) print(nx.negative_edge_cycle(G)) ``` ``` ValueError: min() arg is an empty sequence AttributeError: 'int' object has no attribute 'get' ```  These behaviors look strange and may need further investigation. Any help in this case will be highly appreciated!  Best regards, Joye
issue
ValueError caused by `nx.random_triad` when the input graph contains less 3 nodes#TITLE_END# If there are not enough nodes to sample in the `nx.random_triad`. It will raise a crash from `numpy` instead of NetworkXError with a message.  We can change the code [here](https://github.com/networkx/networkx/blob/88097f7d7f798ec49eb868691dde77cf791a67ec/networkx/algorithms/triads.py#L554) to this version to avoid the issue: ```Python if (len(G.nodes()) < 3:      msg = (             "There are not enough nodes in the graph to form a triad."         )         raise nx.NetworkXError(msg)  nodes = seed.sample(list(G.nodes()), 3) G2 = G.subgraph(nodes) return G2 ``` Should I create a PR for this potential issue and let it return a good exception? It would be highly appreciated if you could also help me take a look at this issue.  Best regards, Joye  ### Step to Reproduce Running the following Python code ```Python import networkx as nx  G = nx.DiGraph([(1, 2)]) print(nx.random_triad(G)) ``` #### Result: ``` ValueError: Sample larger than population or is negative ```  #### Expected Result: ``` NetworkXError("There are not enough nodes in the graph to form a triad") ```  ### Environment NetworkX 3.1 Python 3.10
issue
Unexpected Crash in "nx.percolation_centrality" caused by KeyError: 0#TITLE_END#Hello! Sorry for bothering you again. I noticed that "nx.percolation_centrality" will sometimes crash by a `KeyError: 0` exception. Since this exception does not belong to NetworkX.Exceptions, I believe that it may related to an unexpected exception issue. Would it be possible for you to confirm and investigate this?  Best regards, Joye   ### Step to Reproduce  Please run the following Python code: ```Python import networkx as nx  L = [(0, 1101, 0), (0, 597, 0), (2, 986, 0), (4, 829, 0), (7, 885, 0), (9, 587, 0), (10, 218, 0), (11, 5, 0), (19, 498, 0), (24, 591, 0), (26, 131, 0), (45, 344, 0), (53, 152, 0), (55, 736, 0), (57, 9, 0), (59, 79, 0), (64, 1095, 0), (78, 167, 0), (78, 578, 0), (85, 365, 0), (93, 451, 0), (96, 1088, 0), (97, 107, 0), (105, 568, 0), (107, 801, 0), (109, 1109, 0), (110, 411, 0), (112, 532, 0), (113, 815, 0), (114, 329, 0), (121, 114, 0), (123, 1057, 0), (124, 333, 0), (124, 471, 0), (124, 690, 0), (125, 932, 0), (141, 916, 0), (149, 589, 0), (152, 1011, 0), (152, 753, 0), (153, 850, 0), (156, 65, 0), (159, 469, 0), (173, 272, 0), (177, 557, 0), (182, 629, 0), (186, 594, 0), (188, 675, 0), (193, 664, 0), (194, 215, 0), (200, 966, 0), (206, 366, 0), (220, 176, 0), (223, 414, 0), (224, 657, 0), (224, 378, 0), (227, 1192, 0), (232, 809, 0), (233, 322, 0), (239, 964, 0), (244, 515, 0), (246, 457, 0), (252, 1085, 0), (260, 674, 0), (263, 231, 0), (265, 86, 0), (275, 661, 0), (276, 161, 0), (279, 1012, 0), (282, 995, 0), (295, 366, 0), (306, 582, 0), (307, 341, 0), (308, 501, 0), (308, 1189, 0), (314, 1085, 0), (315, 236, 0), (317, 1165, 0), (332, 436, 0), (333, 668, 0), (337, 143, 0), (339, 409, 0), (342, 1206, 0), (345, 1101, 0), (348, 1192, 0), (353, 533, 0), (358, 1015, 0), (375, 38, 0), (378, 712, 0), (378, 387, 0), (378, 279, 0), (381, 422, 0), (390, 760, 0), (399, 73, 0), (399, 859, 0), (399, 724, 0), (401, 311, 0), (402, 906, 0), (408, 568, 0), (409, 909, 0), (413, 39, 0), (419, 61, 0), (420, 454, 0), (424, 1158, 0), (426, 167, 0), (430, 839, 0), (430, 120, 0), (432, 336, 0), (432, 67, 0), (435, 88, 0), (436, 303, 0), (437, 317, 0), (445, 707, 0), (447, 915, 0), (450, 313, 0), (450, 407, 0), (456, 586, 0), (457, 833, 0), (461, 1130, 0), (462, 128, 0), (464, 283, 0), (464, 1183, 0), (469, 477, 0), (469, 597, 0), (472, 356, 0), (477, 88, 0), (480, 437, 0), (481, 953, 0), (483, 1024, 0), (483, 1065, 0), (485, 449, 0), (488, 791, 0), (492, 79, 0), (494, 646, 0), (498, 1002, 0), (499, 197, 0), (504, 1120, 0), (505, 13, 0), (512, 361, 0), (513, 1189, 0), (513, 534, 0), (517, 59, 0), (522, 706, 0), (529, 392, 0), (531, 247, 0), (531, 749, 0), (535, 833, 0), (537, 3, 0), (537, 943, 0), (540, 308, 0), (546, 369, 0), (553, 191, 0), (554, 426, 0), (561, 662, 0), (564, 602, 0), (568, 1003, 0), (570, 605, 0), (576, 1125, 0), (580, 81, 0), (591, 1228, 0), (607, 270, 0), (608, 120, 0), (609, 854, 0), (615, 1125, 0), (623, 891, 0), (625, 1217, 0), (628, 278, 0), (628, 1160, 0), (633, 981, 0), (638, 912, 0), (640, 315, 0), (645, 422, 0), (647, 467, 0), (650, 786, 0), (653, 323, 0), (658, 333, 0), (659, 1024, 0), (661, 1163, 0), (662, 810, 0), (666, 761, 0), (666, 41, 0), (669, 1167, 0), (670, 1206, 0), (673, 722, 0), (676, 766, 0), (692, 968, 0), (694, 1157, 0), (695, 561, 0), (704, 428, 0), (704, 815, 0), (706, 360, 0), (719, 1030, 0), (720, 1086, 0), (723, 368, 0), (724, 704, 0), (737, 928, 0), (751, 99, 0), (751, 651, 0), (757, 938, 0), (765, 617, 0), (767, 1236, 0), (768, 264, 0), (774, 24, 0), (777, 34, 0), (777, 99, 0), (779, 1018, 0), (790, 550, 0), (790, 244, 0), (793, 1035, 0), (801, 253, 0), (807, 843, 0), (809, 393, 0), (810, 563, 0), (811, 902, 0), (813, 486, 0), (816, 954, 0), (817, 29, 0), (822, 56, 0), (824, 94, 0), (834, 1040, 0), (835, 834, 0), (845, 50, 0), (863, 1136, 0), (871, 993, 0), (877, 212, 0), (880, 864, 0), (885, 1019, 0), (890, 228, 0), (899, 963, 0), (907, 949, 0), (907, 212, 0), (910, 144, 0), (916, 992, 0), (920, 398, 0), (922, 671, 0), (922, 131, 0), (924, 178, 0), (925, 562, 0), (925, 302, 0), (935, 609, 0), (935, 150, 0), (936, 60, 0), (939, 672, 0), (949, 140, 0), (950, 957, 0), (960, 761, 0), (963, 184, 0), (967, 1092, 0), (982, 1176, 0), (986, 891, 0), (989, 431, 0), (992, 858, 0), (996, 475, 0), (996, 32, 0), (1002, 234, 0), (1006, 278, 0), (1009, 968, 0), (1021, 1117, 0), (1021, 1006, 0), (1026, 996, 0), (1034, 699, 0), (1035, 387, 0), (1036, 1120, 0), (1042, 1235, 0), (1049, 413, 0), (1053, 881, 0), (1056, 1018, 0), (1078, 1131, 0), (1080, 596, 0), (1087, 711, 0), (1090, 294, 0), (1096, 939, 0), (1097, 1087, 0), (1099, 1127, 0), (1114, 858, 0), (1119, 59, 0), (1126, 702, 0), (1128, 494, 0), (1134, 318, 0), (1135, 666, 0), (1135, 301, 0), (1142, 1007, 0), (1145, 877, 0), (1148, 37, 0), (1152, 606, 0), (1153, 182, 0), (1153, 546, 0), (1157, 488, 0), (1160, 1120, 0), (1163, 1170, 0), (1166, 1077, 0), (1168, 905, 0), (1169, 1014, 0), (1173, 957, 0), (1174, 849, 0), (1179, 194, 0), (1180, 180, 0), (1183, 206, 0), (1185, 1072, 0), (1186, 639, 0), (1194, 230, 0), (1195, 654, 0), (1195, 714, 0), (1202, 517, 0), (1204, 1072, 0), (1206, 529, 0), (1212, 946, 0), (1214, 621, 0), (1225, 221, 0), (1227, 338, 0), (1229, 1092, 0), (1232, 547, 0), (1233, 896, 0), (1236, 793, 0)] edge_list = [(x[0], x[1]) for x in L] #import the Grpah data  G = nx.from_edgelist(edge_list) nx.percolation_centrality(G) ``` #### Results: ``` File "/home/qiuyang/.local/lib/python3.10/site-packages/networkx/algorithms/centrality/percolation.py", line 122, in _accumulate_percolation     pw_s_w = states[s] / (p_sigma_x_t - states[w]) KeyError: 0 ```  ### Environments: NetworkX: 3.1 Python: 3.10 
issue
KeyError Crash in "nx.combinatorial_embedding_to_pos"#TITLE_END#Hello! When testing NetworkX, I found a strange crash in `nx.combinatorial_embedding_to_pos`, with the following message: ``` Exception has occurred: KeyError File "/home/qiuyang/.local/lib/python3.10/site-packages/networkx/algorithms/planarity.py", line 910, in neighbors_cw_order     start_node = self.nodes[v]["first_nbr"] KeyError: 'first_nbr' ``` I have tried to identify the root cause of the strange behavior but still got some confusion. I believe that if the behavior is unexpected, the problem may be in [here](https://github.com/networkx/networkx/blob/88097f7d7f798ec49eb868691dde77cf791a67ec/networkx/algorithms/planarity.py#L915). Could you help me further confirm and investigate it?  Best regard, Joye  ### Step to Reproduce Running the following Python code: ```Python G = nx.from_edgelist([(5, 7), (5, 6), (8, 5)]) print(nx.is_planar(G)) res = nx.combinatorial_embedding_to_pos(G) ``` #### Result: ``` True Exception has occurred: KeyError ``` ### Environment NetworkX 3.1 Python 3.10 
issue
Request to filter out negative communicability results caused by rounding, and set them to 0#TITLE_END#Greetings! I've noticed a potential issue with NetworkX concerning **negative values** in communicability calculations when the source and target nodes are disconnected. I believe that this negative value occurrence appears to be a result of rounding errors during the use of eigenvectors for calculations.   It's worth noting that, according to the original definition, these values should remain non-negative. The presence of negative values may also pose challenges for downstream tasks, such as assessing non-zero status and calculating reciprocals (expected `inf` but may obtain `-inf`).  Therefore, I kindly request you to filter out these negative values after the calculation. This adjustment also would enhance the robustness of NetworkX.  Thank you for your time and consideration. Your attention to this matter is highly appreciated.  Best regards, Joye  ### Steps to Reproduce Please running the following Python code: ```Python import networkx as nx  if __name__ == "__main__":     graph = nx.from_dict_of_lists({         0: [3, 4],          1 : [],          2: [3, 4],          3: [0, 2],          4: [0, 2]     })      res = nx.communicability(graph)     print(res[1][2])  ``` *Result:* ``` -3.3306690738754696e-16 ```  ### Environment  Python version: 3.10 NetworkX version: 3.1 
comment
Hi @iany0 ! I am not on the team of NetworkX, but I am also interested in the robustness of NetworkX. I investigated your graph data and found that `node: 8` should not be in an isolated strongest component. I also find the issue of the code is here in lines 246 to 249 of [strongly_connected.py](https://github.com/networkx/networkx/blob/main/networkx/algorithms/components/strongly_connected.py), and another issue of this code is that `cnt` should not be independent for different visitings. These codes should be: ```Python     def visit(v, cnt):         root[v] = cnt[0]         visited[v] = cnt[0]         cnt[0] += 1         stack.append(v)         for w in G[v]:             if w not in visited:                 yield from visit(w, cnt)                 root[v] = min(root[v], root[w])             elif w not in component:                 root[v] = min(root[v], visited[w])         print(v, root[v], visited[v])         if root[v] == visited[v]:             component[v] = root[v]             tmpc = {v}  # hold nodes in this component             while stack[-1] != v:                 w = stack.pop()                 component[w] = root[v]                 tmpc.add(w)             stack.remove(v)             yield tmpc      visited = {}     component = {}     root = {}     cnt = [0]     stack = []     for source in G:         if source not in visited:             yield from visit(source, cnt) ```  This change can fix the inconsistency and return the correct result for `strongly_connected_components_recursive` I will also try to commit my fix for the issue.  Cheers for your findings!   Best regards, Joye
