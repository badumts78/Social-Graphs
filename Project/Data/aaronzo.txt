issue
Fix pygraphviz tests causing segmentation faults in backend test#TITLE_END#Fixes #7354   excludes `nx_agraph.read_dot` from backend equivalence checks. algorithms that accept `TextIOWrapper` arguments ignore this check.  FYI @rossbar @MridulS @eriknw 
issue
Add aaronzo as contributor#TITLE_END#merged PRs: https://github.com/networkx/networkx/pulls?q=is%3Apr+is%3Amerged+author%3Aaaronzo+
issue
Option to include initial labels in `weisfeiler_lehman_subgraph_hashes`#TITLE_END#Apologies for the spam folks, I thought I had caught the mistakes in #6598  but had to correct some things further down too - good catch from @dschult in the PR comments.  I've read the whole docstring through a couple of times now and it looks right.
issue
add seed to `nx.generate_random_paths`#TITLE_END#Fixes #7286 
issue
Release notes for 3.2 do not make it clear that python 3.8 support is dropped#TITLE_END#All releases pre-3.2 have a top line specifying supported python versions, e.g. [3.1](https://networkx.org/documentation/stable/release/release_3.1.html). However, 3.2 is lacking this information. I had to look through closed issues to realise 3.8 is not supported for networkx >=3.2.  Could this be updated on the website?
issue
add implementation to re-dispatch all functions for easier testing#TITLE_END#the `--backend=nx-loopback` option reregisters all algorithms before the tests execute. the ability to reregister all (or some) functions I can see being useful in other situations, e.g. if a function is monkey-patched. additionally, all dispatched functions keep a `dispatchargs` attribute which can be queried to see which aspects are kept when dispatching, which I think is also useful.  Came from discussion on #6819 
issue
Quotient Graph with breaking changes#TITLE_END#a version of https://github.com/networkx/networkx/pull/6557 where we allow breaking API changes for simpler code and more efficiency
issue
corrections to docstring of `weisfeiler_lehman_subgraph_hashes`#TITLE_END#mistakenly the docstrings reference the diameter of the subgraphs rather than the radius, and I've rephrased the docstrings to make more sense.
issue
Bipartite projection on nodes with duplicates raises ZeroDivisionError#TITLE_END#When calculating the 'top' nodes for the `weighted_projected_graph` [here](https://github.com/networkx/networkx/blob/6a0b4faf09ec9d3d40ad93e2ec9b431d6bab5dc4/networkx/algorithms/bipartite/projection.py#L192), if the user submits a list with duplicates, the function either gives incorrect results or a `ZeroDivisionError` when `ratio=True`. If the user first checks their set with `is_bipartite_node_set`. this returns `True`: ```python import networkx as nx from networkx.algorithms import bipartite  B = nx.complete_bipartite_graph(2,2) a = [0,1] * 2  bipartite.is_bipartite_node_set(B, a) # returns True  bipartite.weighted_projected_graph(B, a, ratio=True) # raises ZeroDivisionError ``` I can understand that in `weighted_projected_graph` we burden the user with supplying a valid node set to avoid the inefficiency of converting a `list` into a `set`, but I do think anything that passes `is_bipartite_node_set` should definitely give correct and error-free answers when passed to the projection function, else this behaviour is surprising.  Of course in the example above, it's obvious I've made duplicates but in real use-cases the node set could come through a chain of functions and the user is none the wiser. 
issue
Fixes #5403: Errors on non-distinct bipartite node sets#TITLE_END#- `is_bipartite_node_set` raises an exception if the node set is not distinct. This is to avoid unexpected errors or incorrect results when using bipartite algorithms, for instance `weighted_projected_graph`, where results can be out by a factor. - `weighted_projected_graph` raises an exception if the node set is greater than or equal to the graph size. Previously the user recieved an enigmatic `ZeroDivisionError` in this case.   Follows the discussion of #5403.  I think there's still some discussion to be had on whether `is_bipartite_node_set` should raise an exception or simply return `False` like it does for other invalid partitions.
issue
Add weisfeiler lehman subgraph hashing#TITLE_END### Changes - add a new method `weisfeiler_lehman_hash_subgraphs`, and refactored `weisfeiler_lehman_hash_graph` so the two methods share common steps and are more efficient. - added docstring with example for `weisfeiler_lehman_hash_subgraphs` - added test class for `weisfeiler_lehman_hash_subgraphs` with randomly generated graphs for each test - replaced tests for  `weisfeiler_lehman_hash_graph`  to be aligned with the coverage of tests for `weisfeiler_lehman_hash_subgraphs`  ## Description The current `weisfeiler_lehman_hash_graph` returns a hash for a graph, but sometimes it is useful to keep the subgraph hashes induced by k-hops from each node generated by the iterations along the way. For example when building general WL graph kernels [1] or in the popular 'Graph2Vec' algorithm [2] where these subgraph hashes are viewed as 'words' in the graph to build features from. Non-isomorphic graphs may have different graph hashes but may share lots of subgraph hashes, implying that locally the graphs are similar.  As a result I've added the `weisfeiler_lehman_hash_subgraphs` method which returns a dictionary indexed by node of subgraph hash lists in order of iteration depth.  Similarly to `weisfeiler_lehman_hash_graph`, the user can choose to set: initial node labels for the hashing, an edge attribute used in neighborhood aggregations, iteration depth, or hash digest size with optional keyword arguments.   ### References [1] W-L graph kernels https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf [2]  Graph2Vec: https://arxiv.org/abs/1707.05005  Possibly of interest to @cgoliver & @rossbar, authors of the original implementation here.
comment
Extra point on `quotient_graph` - though it's a pattern that could repeat: The function takes a `weight` parameter (since #6814), but this is only used by the function logic if another parameter, `edge_data` is `None`. Therefore there is efficiency lost in keeping the `weight` attribute if `edge_data != None`. This also applies to the open PR #6557.
comment
Possibly closeable after #7305 ?
comment
Can confirm I could reproduce the seg fault errors (. Graphviz makes no promises about being thread-safe, but unsure why only the backend causes the faults...
comment
Narrowing it down to a single test (quicker to reproduce): ``` NETWORKX_TEST_BACKEND=nx-loopback pytest networkx -k "test_agraph_roundtripping"   # FAILS pytest networkx -k "test_agraph_roundtripping"                                     # PASSES ``` and the error is: <details close> <summary>pytest log</summary> <br>  ``` platform linux -- Python 3.10.12, pytest-8.0.2, pluggy-1.4.0 rootdir: /mnt/c/dev/networkx plugins: cov-4.1.0, xdist-3.5.0 collected 5556 items / 5552 deselected / 4 selected                                                                                                                                                                                                   networkx/drawing/tests/test_agraph.py Fatal Python error: Segmentation fault  Current thread 0x00007f83f4bd1000 (most recent call first):   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pygraphviz/graphviz.py", line 226 in agnameof   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pygraphviz/agraph.py", line 228 in __repr__   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_io/saferepr.py", line 73 in repr_instance   File "/usr/lib/python3.10/reprlib.py", line 62 in repr1   File "/usr/lib/python3.10/reprlib.py", line 52 in repr   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_io/saferepr.py", line 61 in repr   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_io/saferepr.py", line 111 in saferepr   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_code/code.py", line 842 in repr_args   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_code/code.py", line 938 in repr_traceback_entry   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_code/code.py", line 993 in <listcomp>   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_code/code.py", line 992 in repr_traceback   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_code/code.py", line 1063 in repr_excinfo   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/_code/code.py", line 698 in getrepr   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/nodes.py", line 496 in _repr_failure_py   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/python.py", line 1874 in repr_failure   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/reports.py", line 363 in from_item_and_call   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/runner.py", line 369 in pytest_runtest_makereport   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_callers.py", line 102 in _multicall   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_manager.py", line 119 in _hookexec   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_hooks.py", line 501 in __call__   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/runner.py", line 225 in call_and_report   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/runner.py", line 134 in runtestprotocol   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/runner.py", line 115 in pytest_runtest_protocol   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_callers.py", line 102 in _multicall   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_manager.py", line 119 in _hookexec   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_hooks.py", line 501 in __call__   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/main.py", line 352 in pytest_runtestloop   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_callers.py", line 102 in _multicall   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_manager.py", line 119 in _hookexec   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_hooks.py", line 501 in __call__   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/main.py", line 327 in _main   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/main.py", line 273 in wrap_session   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/main.py", line 320 in pytest_cmdline_main   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_callers.py", line 102 in _multicall   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_manager.py", line 119 in _hookexec   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/pluggy/_hooks.py", line 501 in __call__   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/config/__init__.py", line 175 in main   File "/mnt/c/dev/networkx/.venv/lib/python3.10/site-packages/_pytest/config/__init__.py", line 198 in console_main   File "/mnt/c/dev/networkx/.venv/bin/pytest", line 8 in <module>  Extension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, scipy._lib._ccallback_c, matplotlib._c_internal_utils, PIL._imaging, matplotlib._path, kiwisolver._cext, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pygraphviz._graphviz, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._flinalg, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, matplotlib._image (total: 83) Segmentation fault (core dumped) ``` <br> </details>  ---  Edit: It seems the issue arises when a file handler is passed to `networkx.nx_agraph.read_dot`. Exchanging  ```python with open(fname) as fh:     Hin = nx.nx_agraph.read_dot(fh) ``` for ```python Hin = nx.nx_agraph.read_dot(fname) ``` [here](https://github.com/networkx/networkx/blob/f0b5a6d884ac7e303f2e2092d3a0a48723815239/networkx/drawing/tests/test_agraph.py#L44-L45) causes the test to no longer error for me. Interestingly the write method is fine either way.  Also, running the test code in a python file works fine too. It seems like the seg fault happens due to some thing pytest is doing with the handler/agraph  ---  Edit 2: I've managed to circumvent the seg-fault - it's happening when pytest tries to call `repr` on the `pygraphviz.AGraph` during an error trace. I patched `lambda _: "<redacted>"` onto `AGraph.__repr__`, and now I believe the real error is:  <details close> <summary>pytest log 2</summary> <br>  ```python <class 'networkx.utils.decorators.argmap'> compilation 117:3: in argmap_read_dot_114     ??? networkx/utils/backends.py:662: in __call__     return self._convert_and_call_for_tests( networkx/utils/backends.py:1248: in _convert_and_call_for_tests     G = self.orig_func(*args2, **kwargs2) networkx/drawing/nx_agraph.py:222: in read_dot     A = pygraphviz.AGraph(file=path) .venv/lib/python3.10/site-packages/pygraphviz/agraph.py:157: in __init__     self.read(filename) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = <redacted>, path = <_io.TextIOWrapper name='/tmp/pytest-of-aaronzo/pytest-109/test_agraph_roundtripping_G0_0/fh_test.dot' mode='r' encoding='UTF-8'>      def read(self, path):         """Read graph from dot format file on path.              path can be a file name or file handle              use::                 G.read('file.dot')              """         fh = self._get_fh(path)         try:             self._close_handle()             try:                 self.handle = gv.agread(fh, None)             except ValueError: >               raise DotError("Invalid Input") E               pygraphviz.agraph.DotError: Invalid Input  .venv/lib/python3.10/site-packages/pygraphviz/agraph.py:1252: DotError ``` <br> </details>
comment
Figured it out - that was a tough nut to crack! Continuing from above, `_dispatchable._convert_and_call_for_tests` was evaluating `networkx.nx_agraph.read_dot` twice using the same open file handler (since this method evaluates the original function for comparison, but this all happens inside a file context).  So, the fix is to add `networkx.nx_agraph.read_dot` to the list of functions this is not done for - I see from the code comment that `TextIOWrapper` cases are ignored for other functions too, so it makes sense to exclude `networkx.nx_agraph.read_dot` .  I've raised #7380 with the fix (_lol, one line for all that debugging_). Perhaps pygraphviz experts can advise on whether `from_agraph` should also be excluded (perhaps the unit tests aren't covering the file handler case for that).  The hardest part of debugging this was getting over the initial seg-fault as mentioned in my [previous comment](https://github.com/networkx/networkx/issues/7354#issuecomment-2027429432). I've raised an [issue against pygraphviz](https://github.com/pygraphviz/pygraphviz/issues/519), since `pygraphviz.AGraph.__repr__` - assumes that `__init__` did not fail. This was discussed at length on [pytest's issue forum](https://github.com/pytest-dev/pytest/issues/4659).
comment
Hi - @kalekundert - I implemented this algorithm initially and you are absolutely correct. I had been meaning to add a parameter `include_initial_labels` to control whether this is on or off, I think both settings can be useful. It's nice to see this is getting some use. I already have #6601 open to fix other docstring issues, so I could incorporate this there.
comment
Added this to #6601 @kalekundert - a review would be greatly appreciated :)
comment
@rossbar I had a quick go at implementing this - changing the signature to: ```python @py_random_state(5) @nx._dispatchable(edge_attrs="weight") def generate_random_paths(     G, sample_size, path_length=5, index_map=None, weight="weight", seed=None ): ``` The convention in the codebase seems to be to use the numpy-backed `random.Random` subclass `PythonRandomViaNumpyBits` for new code. This was simple enough to achieve, but I had to substitute `np.random.choice` with `seed.choices` to get the same weighted choice behaviour. However, this generates different choices than `np.random.choice`, I guess through a different (probably less efficient) implementation that calls `seed.getrandbits`.  This would mean that user code that uses a set random seed would break when upgrading. Would we be okay with that? Or should we try and guarantee the state is the same as the current implementation if the global numpy RNG is seeded (this might be very difficult)?
comment
Ah - ok, wasn't aware of `np_random_state`. To get a random integer, `np.random.Generator` and `np.random.RandomState` aren't consistent with method names - the former has `integers` and the latter has `randint`. This seems like an issue? I've added the line: ```python randint_fn = seed.integers if isinstance(seed, np.random.Generator) else seed.randint ``` and this does work but seems a bit unsatisfactory
comment
There doesn't seem to be a natural interface to use in numpy (there's no shared base class), so it would have to be maintained in networkx. Do we consider this a requirement for this issue, or would we be ok with the instance check just for this function, for now, with a view to migrating all functions using `np_random_state` to a common interface? If so I can submit a PR.
comment
Agree that your proposals are better than current behaviour, with the note that  > Thus, NetworkX should raise an exception when a graph with zero edges (ignoring self loops) is passed to the laplacian_centrality method.  should only happen if `normalized=True` is requested.  I also wonder if there isn't something clever to be done with identities in cases that are currently undefined. For example, is should be true that  $$ C_L(u, G) = C_L(u, G \cup \{ v \} ) $$  for all $u \in G$ where $v$ is a new, isolated node, because we're adding zero rows/cols to a matrix just adds a 0 eigenvalue and keeps others the same. Thus, it might make sense to add a second, isolated node to a single node graph to obtain a sensible value for the first node - which would be $0$ everytime in the unnormalized case.
comment
Is there overlap between this and #6829 ?
comment
Maybe also worth thinking about the thread on #3745 looking at implementing [InfoMap](https://arxiv.org/pdf/0906.1405.pdf) community detection. The optimization algorithm for InfoMap follows the Louvain algorithm (both stages), except that it minimizes 'the map equation' (heuristically this is something like the information flow between communities) rather than maximising modularity.  Perhaps it is worth exploring which pieces of this PR could be decoupled from the modularity equation, if at all. However, performance is quite key with these algorithms and I'm aware that many time gains are achieved by exploiting the mathematical structure of the target equation - as the `_one_level` function does here - so a na√Øve approach of allowing a developer to input a cost function to optimise against would be no good.  I see for example, that the `generate_dendrogram` function could be used for infomap - if we could swap the `_one_level` and the `modularity` function out. 
comment
@z3y50n I actually think yielding the 'base' partitions is more expected behaviour for a user anyway - I would guess `louvain_partitions` would have more niche usage than `louvain_communities`, I would use it in the case I'm investigating how the algorithm built partitions and I think it's nice to see the first layer combines single nodes.  If you really wanted to avoid it you could do on https://github.com/networkx/networkx/blob/9629af4cdc9757368cd44bea3365ea1fe04b6a2d/networkx/algorithms/community/louvain.py#L110 ```python return d.pop() if d else [{u} for u in G.nodes()] ``` but I think yielding the base case is better as you have done 
