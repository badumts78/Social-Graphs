issue
Unable to parallelize with large graph objects#TITLE_END#<!-- If you have a general question about NetworkX, please use the discussions tab to create a new discussion -->  <!--- Provide a general summary of the issue in the Title above -->  With a large graph object (~6 GB), parallel jobs started with Dask and/or Ray fail to compute. The processes are distributed to the workers, but they will be inactive for large periods of time. The same parallel processing setup works with smaller graphs (<1 GB), and using forked workers via the `multiprocessing` package instead of Dask or Ray also works with the large graph object.   ### Current Behavior <!--- Tell us what happens instead of the expected behavior -->  I need to compute lots of shortest paths on a relatively large graph. Through my university department, I have access to a compute cluster, so I wrote code to compute these shortest paths in parallel. A subset of nodes in the graph is analyzed, and for each of those nodes, I have to compute shortest paths to ~30 other nodes. The parallelization is at the node level, and each individual node should not take more than a few seconds to analyze.  With a smaller graph, the processes are distributed to the workers, and the computation runs in parallel as expected. However, with a larger graph, the processes are distributed, but the vast majority remain inactive for long periods of time. Then one will briefly come alive for a few seconds, complete the task, before falling silent again. The computation does not complete.  This is *not* an issue caused by memory constraints in the cluster. The large graph object is about 6 GB, and the compute nodes these were run on have between 128 GB and 256 GB of memory. Between 4 and 16 workers were chosen, and the same behavior was observed in all cases.   ### Expected Behavior The nodes should be processed in parallel, networkx should do the computation, and the program returns at the end. Currently, the processes are distributed, but no computation is being done.  ### Steps to Reproduce <!--- Provide a minimal example that reproduces the bug -->  This one is tough as my code is fairly convoluted. But here is the structure of my code:  ``` import dask import dask.multiprocessing import networkx as nx  if __name__ == '__main__':     dask.config.set(scheduler = 'processes', num_workers = 16)     # load data and preprocess     def analyze(node): # do a bunch of shortest paths and return something      futures = []     for departureNode in G.nodes:         if condition:             futures.append(dask.delayed(analyze)(departureNode))     results = dask.compute(futures)      # do a bunch of post processing and save to files ```  ### Environment <!--- Please provide details about your local environment --> Python version: 3.8.3 NetworkX version: 2.8  ### Additional context CCing @paciorek, who is the admin of the compute cluster and is the one who spent lots of time trying to investigate this issue. I want to re-emphasize that there is nothing wrong with the parallel structure or the analysis code itself, considering that:  1. With a smaller graph, everything runs fine. 2. With the large graph, forked workers via `multiprocessing` runs as expected  The issue is that with Dask and Ray, the computation fails.  Per @paciorek:  >  So it seems like it has something to do with the fact that all the workers are sharing the (somewhat large) G object. That said, the behavior as I see it doesn't seem particularly consistent with delays involved in copying G to the worker processes, which was one initial hypothesis I had. (It's not entirely clear to me what copies are / are not made given G is a global variable used within analyze()). Given that, I also tried making G a variable that is passed into analyze()  but that didn't seem to have any effect.  > I tried running your workflow using ipyparallel and Ray instead of Dask and had similar problems. So it feels like there is something about the big network object that causes various parallelization frameworks to choke in some fashion. It almost seems like two workers can't be actively working on their tasks at the same time. Ray has a nice 'object store' paradigm where you can control things such that each worker gets a copy of an object rather than a copy being made for each task, but even with that more explicit control over copies to the workers, I still had the problem.  > I experimented some with Ray and simply passing 'G' in as an argument to analyze() without using it in analyze(), causes the weird behavior (either with or without G being put in the Ray object store). So it seems like something about the structure of the G object is causing extreme lags before the core computation in analyze() even starts, though it's not clear to me that it is as simple as the lag being the time involved to make a copy of G. Once the computation starts, it seems to go as quickly as expected.  It may also be worth noting that 6 GB seems fairly excessive for my graph object, considering that it "only" has about 1.6 million nodes and 2.4 million edges, and its XML representation is about 300 MB.
