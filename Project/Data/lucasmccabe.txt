issue
Add characteristic polynomial example to polynomials docs#TITLE_END#Implements the suggestion from #5726 to add an example of the characteristic polynomial to the `polynomials` docstring.
issue
refactor: modifications and additional tests for weighted distance#TITLE_END#Fixes #5257  Additional tests have been added for weighted graph distance computations.
issue
Characteristic polynomial#TITLE_END#This PR implements the characteristic polynomial, continuing development of [graph polynomial algorithms](https://networkx.org/documentation/latest/reference/algorithms/polynomials.html?highlight=graph+polynomials).  I was curious how best to implement the matrix conversion. Sympy already [implements](https://github.com/sympy/sympy/blob/77f1d79c705da5e9b3dee456a14b1b4e92dd620c/sympy/matrices/determinant.py#L333) the [Samuelson-Berkowitz algorithm](https://en.wikipedia.org/wiki/Samuelson%E2%80%93Berkowitz_algorithm), which is fast, but doesn't take scipy's `csr_matrix` format. I considered the following three variants:  ``` def chromatic_polynomial_method_1(G):     x = sympy.Symbol("x")     A = nx.adjacency_matrix(G)     M = sympy.Matrix(A.todense())     return M.charpoly(x).as_expr()  def chromatic_polynomial_method_2(G):     n = len(G)     x = sympy.Symbol("x")     A = nx.adjacency_matrix(G)     M = sympy.SparseMatrix(n, n, dict(A.todok()))     return M.charpoly(x).as_expr()  def chromatic_polynomial_method_3(G):     x = sympy.Symbol("x")     A = nx.adjacency_matrix(G)     M = sympy.SparseMatrix(A.todense())     return M.charpoly(x).as_expr() ```  and took the average run time of binomial random graphs G(n, p) with n from 10 to 34, over p from 0.05 to 0.95 (increments of 0.05):  ![benchmark](https://user-images.githubusercontent.com/12187602/173261607-cec53634-0cbc-4012-b35e-9c7fdc464c90.png)  Differences are negligible for small graphs, but method 3 (implemented in this commit) appears preferable as n grows.  Thank you!
issue
Chromatic polynomial#TITLE_END#This PR implements the chromatic polynomial, continuing development of [graph polynomial algorithms](https://networkx.org/documentation/stable/reference/algorithms/polynomials.html).  To follow the stack-based pattern of [#5265](https://github.com/networkx/networkx/pull/5265), I increment a `contraction_idx` graph attribute to track signs in the deletion-contraction expansion.  Code has been run through black and has been tested locally.  Thank you! 
issue
Tutte polynomial#TITLE_END#This PR implements the Tutte polynomial, with space for additional graph polynomials to be included in the future.  Code has been run through black and flake8. All methods have been tested locally.  Thank you!  <!-- Please run black to format your code. See https://networkx.org/documentation/latest/developer/contribute.html for details. --> 
issue
Multigraph bridges#TITLE_END#This PR modifies `nx.bridges` to accommodate multigraphs.   The fast bridge-finding algorithm used by `nx.bridges` ([Algorithm 1](https://arxiv.org/abs/1209.0700)) requires a simple graph. A bridge in a multigraph must have multiplicity one, so running the algorithm on the simple version of a multigraph and verifying that any discovered bridges are not multi-edges should be sufficient.
issue
Edge contraction misses multi-edges#TITLE_END#<!--- Provide a general summary of the issue in the Title above --> It's possible that we are working with different definitions of edge contraction, but I figured I should bring this up:  [1] defines contraction of an edge e with endpoints u, v in a graph G as follows:  ![image](https://user-images.githubusercontent.com/12187602/149555923-1eef1736-8284-4024-9c39-ccccdb3e3bc2.png)  This seems inconsistent with the behavior of `nx.contracted_edge`. If this is deliberate, it may interfere with potential downstream tasks.  ### Current Behavior As far as I can tell, `nx.contracted_edge` does not return a graph with multi-edges when appropriate (e.g. when contracting an edge of a triangle).  ### Expected Behavior In the above example, I would expect edge contraction to result in a MultiGraph with two multi-edges.  ### Steps to Reproduce Consider the example above:  ```bash >>> import networkx as nx >>> e = [ ...         (1, 2), ...         (2, 3), ...         (3, 4), ...         (4, 1), ...         (4, 5), ...         (3, 5) ] >>> G = nx.Graph(e) # left graph in image above >>> H = nx.contracted_edge(G, (4, 3)) >>> print(H.edges) [(1, 2), (1, 4), (2, 4), (4, 5), (4, 4)] >>> J = nx.contracted_edge(G, (4, 3), self_loops = False) >>> print(J.edges) [(1, 2), (1, 4), (2, 4), (4, 5)] ```  ### Environment <!--- Please provide details about your local environment --> Python version:  3.10.1 NetworkX version: 2.7rc1.dev0  ### Addressing the Issue If we agree that this is an issue, I am happy to work on it.  ### References [1] West, Douglas B.:         Introduction to Graph Theory, p.84.         2018
comment
If one has multiple examples in a single docstring, should each example import networkx?
comment
To be clear, we mean `distance_measures.py`, right? Or is `distance_measurements.py` somewhere and I'm just not seeing it?
comment
Hi All, I would also be interested in contributing to this.  It looks like there are handful of functions to address - perhaps we can split the work among ourselves?
comment
Hello, I think I have things figured out in [#5305](https://github.com/networkx/networkx/pull/5305). What do you think?
comment
Hi @joranp1, thanks for looking into this - unfortunately your images aren't showing here.  It's not so uncommon for [load centrality](https://github.com/networkx/networkx/blob/ec267cff8d092534fb0b2616e8f075142d2cd75b/networkx/algorithms/centrality/load.py#L9) and [betweenness centrality](https://github.com/networkx/networkx/blob/ec267cff8d092534fb0b2616e8f075142d2cd75b/networkx/algorithms/centrality/betweenness.py#L15) to be the same, especially for small graphs. Here's an illustrative experiment with binomial random graphs `G(n, p)` with n from 5 to 99 and p from 1/50 to 1:  ![btwn](https://user-images.githubusercontent.com/12187602/173277462-1afb0c8a-b78c-4d7c-8f41-1dddbdee43b9.png)  
comment
> As per my reasoning the centrality value of node number 2 in image2 only depends on the shortest path between nodes 1 and 7, since no other shortest paths pass through it.  Several other shortest paths pass through node 2 - for instance, the shortest paths from 1 to 4 and 1 to 5.
comment
Your calculation of betweenness appears correct, though non-normalized.  Unfortunately, your calculation of load is not. Nodes 4 and 5 (via source node 1) contribute 4/3 each to the non-normalized load score for node 2. This can be seen by adding something like ```if source == 1 and v in [4, 5]: print(v, x, between[v], num_paths)``` between lines 119 and 120 [here](https://github.com/networkx/networkx/blob/192f5e15c7a6879d99ecfd107f07b2327582434d/networkx/algorithms/centrality/load.py#L119).  That said, the accumulation routine performed in Algorithm 13 of the [paper](https://www.sciencedirect.com/science/article/abs/pii/S0378873307000731) your figure is from makes it unwieldy to track down load attribution in a spreadsheet like you can for betweenness.  Hope this helps!
comment
@dschult @jarrodmillman Not super important, but I've been noticing the behavior below a few times recently - the checks appear to be passing, but the **ci/circleci: image artifact** action gets stuck in limbo. Any idea why this occurs?
