issue
address 'flake8-pytest-style' lints#TITLE_END#addresses 'flake8-pytest-style' lints.  - reduce scope of `pytest.raises` - separate 'stacked' assertions - consistent usage of types in `pytest.parametrize` - remove 'assert False'
issue
remove usage of 'tempfile.mkstemp' in favour of a 'NamedTemporaryFile'#TITLE_END#replaces a low-level API with a context manager
issue
Lint using Ruff#TITLE_END#closes #6325
issue
bump pre-commit hooks (and fix CI)#TITLE_END#I'm seeing a bug in the install of isort with pre-commit. Looks Poetry-related. Bumping the isort version solves it.  ``` pre-commit run --all-files [INFO] Installing environment for https://github.com/pycqa/isort. [INFO] Once installed this environment will be reused. [INFO] This may take a few minutes... An unexpected error has occurred: CalledProcessError: command: ('/home/dan/.cache/pre-commit/repo4zn7v0sy/py_env-python3.10/bin/python', '-mpip', 'install', '.') return code: 1 stdout:     Processing /home/dan/.cache/pre-commit/repo4zn7v0sy       Installing build dependencies: started       Installing build dependencies: finished with status 'done'       Getting requirements to build wheel: started       Getting requirements to build wheel: finished with status 'done'       Preparing metadata (pyproject.toml): started       Preparing metadata (pyproject.toml): finished with status 'error'      stderr:       error: subprocess-exited-with-error              × Preparing metadata (pyproject.toml) did not run successfully.       │ exit code: 1       ╰─> [14 lines of output]           Traceback (most recent call last):             File "/home/dan/.cache/pre-commit/repo4zn7v0sy/py_env-python3.10/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 351, in <module>               main()             File "/home/dan/.cache/pre-commit/repo4zn7v0sy/py_env-python3.10/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 333, in main               json_out['return_val'] = hook(**hook_input['kwargs'])             File "/home/dan/.cache/pre-commit/repo4zn7v0sy/py_env-python3.10/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 152, in prepare_metadata_for_build_wheel               return hook(metadata_directory, config_settings)             File "/tmp/pip-build-env-sv1g2j58/overlay/lib/python3.10/site-packages/poetry/core/masonry/api.py", line 40, in prepare_metadata_for_build_wheel               poetry = Factory().create_poetry(Path(".").resolve(), with_groups=False)             File "/tmp/pip-build-env-sv1g2j58/overlay/lib/python3.10/site-packages/poetry/core/factory.py", line 57, in create_poetry               raise RuntimeError("The Poetry configuration is invalid:\n" + message)           RuntimeError: The Poetry configuration is invalid:             - [extras.pipfile_deprecated_finder.2] 'pip-shims<=0.3.4' does not match '^[a-zA-Z-_.0-9]+$'                      [end of output]              note: This error originates from a subprocess, and is likely not a problem with pip.     error: metadata-generation-failed          × Encountered error while generating package metadata.     ╰─> See above for output.          note: This is an issue with the package mentioned above, not pip.     hint: See above for details. ```
issue
Tracking issue - linting/code quality using Ruff#TITLE_END#This is a tracking issue for the introduction of code quality linting to this repo. Linting can provide the following benefits  - correctness - identify bugs, dead code, inconsistencies, performance issues, antipatterns in code - consistency - promote a consistent code style to improve readability  I propose an incremental approach where lints are added one at a time, and only where they add clear value.  I propose using [ruff](https://github.com/charliermarsh/ruff). The alternative would be to use flake8. Compared to flake8, ruff - is faster (by a couple of orders of magnitude) - can automatically fix code in many cases - has no dependencies  Ruff is particularly suited for use as a pre-commit hook, due to its speed.  see-  - [x] #6321  - [x]  #6319 https://pypi.org/project/flake8-simplify/0.19.3/ - [ ]  #6320  - [x] #6315  - [x] #6317  - [x] #6345 - [x] #6350  - [x] #6351    ---------------------------------------------------------------------------------------------  Current "approved" rust.toml (with atleast one approval) ``` select = [     "C4",     "E713",     "SIM2",  # simplify boolean comparisons     "SIM110",  # convert loop to 'any'     "SIM111",  # convert loop to 'all'     "SIM109",  # use a tuple for multiple comparisons     "SIM118",  # use 'key in dict'     "PGH003",  # forbid blanket 'type: ignore' comments ] ```
issue
lint implicit str concatenation using ruff#TITLE_END#this lint is essentially a workaround for a limitation in black (which is addressed in black's unstable 'preview' feature).  see https://pypi.org/project/flake8-implicit-str-concat/0.3.0/ for details  see #6316 for additional context
issue
use ruff to lint and fix E713#TITLE_END#see the [flake8-docs](https://www.flake8rules.com/rules/E713.html)  > Tests for membership should use the form `x not in the_list` rather than `not x in the_list`. The former example is simply more readable. >  > ### Anti-pattern >  > ```python > my_list = [1, 2, 3] > if not num in my_list: >     print(num) > ``` >  > ### Best practice >  > ```python > my_list = [1, 2, 3] > if num not in my_list: >     print(num) > ```  [ruff](https://github.com/charliermarsh/ruff) is a linting tool similar to flake8, but which is a couple of orders of magnitude faster, and is capable of auto-fixing most of its lints. This PR only enables a single lint (E713).
issue
use ruff to lint and fix C4 (comprehensions)#TITLE_END#this is equivalent to introducing the 'flake8-comprehenions' plugin, however using [ruff](https://github.com/charliermarsh/ruff) is a couple of orders of magnitude faster, and provides the ability to auto-fix the lints.  using list/dict/set literals provides a small performance boost, as well as improving readability.
issue
forbid blanket 'type: ignore' comments#TITLE_END#error suppression should use the smallest possible scope. Additionally, if specific error codes are used, then mypy will return an error if that error is no longer triggered (with a blanket statement this behaviour does not occur)  This PR uses ruff to forbid blanket ignore statements and requires users to set a specific error code.
issue
add SIM2* lints#TITLE_END#adds all of the SIM2* lints  see [the docs(https://pypi.org/project/flake8-simplify/0.19.3/) for detals
issue
add SIM11* lints#TITLE_END#use 'any' and 'all' to simplify checking conditions against every element in an iterator
issue
fix whitespace issue in test_internet_as_graphs#TITLE_END#the original strings are incorrectly split. I suspect rather than  ```python                 raise ValueError(                     "Inconsistent data in the graph\                         node attributes"                 ) ```  the intention was probably to have  ```python                 raise ValueError(                     "Inconsistent data in the graph"                     " node attributes"                 ) ```  but it all fits on one line anyway
issue
Mypy CI failures in `main` branch#TITLE_END#the mypy CI job is failing in `main`.
issue
use black '--preview' to normalise strings#TITLE_END#by default, Black doesn't attempt to normalise strings. Enabling the '--preview' feature enables this feature. It also reformats some tuples.  the '--preview' feature isn't stabilised since there are edge cases it doesn't handle well. Therefore I propose to run it as a one-time deal for now, rather than leaving it enabled.
issue
apply flake8-linting#TITLE_END#improve code quality by addressing `flake8` lints.  This PR does *not* add flake8 linting to pre-commit or CI
comment
another vote for comprehensive inline typing here  inline typing adds more visual clutter by virtue of having more sigils on the screen, but provides greater clarity in literally every other aspect. Non-annotated methods are clean, concise, and **completely opaque** unless you're already familiar with them.  Type annotations are the difference between inspecting a method signature to understand the intent (with an IDE backing you up) and having to find and consult documentation, and interpret the author's intent.  It's also the difference between a 'lint-time' error and a runtime error. Failing faster is absolutely critical when working at scale.  I sincerely hope this PR gets over the line
comment
> You're right that the code you wrote is hard to read. But you don't need to write code like that. Just create a type alias with a descriptive name: >  > ```python > GraphFactory: TypeAlias = Callable[[], Graph] > # and then > def build_graph(graph_builder: Optional[Union[Graph, GraphFactory]]) -> Graph: > ```  in fact i think you could just write  ```python GraphFactory = Callable[[], Graph] # and then def build_graph(graph_builder: Union[Graph, GraphFactory, None]) -> Graph: ```
comment
@NeilGirdhar what are the main impediments to getting this PR wrapped up now? Anything I can help with?
comment
> > what are the main impediments to getting this PR wrapped up now? Anything I can help with? >  > @danieleades One thing you could do is try to replace the class variables: >  > ```python >     node_dict_factory: ClassVar[MapFactory] = dict >     node_attr_dict_factory: ClassVar[MapFactory] = dict >     adjlist_outer_dict_factory: ClassVar[MapFactory] = dict >     adjlist_inner_dict_factory: ClassVar[MapFactory] = dict >     edge_attr_dict_factory: ClassVar[MapFactory] = dict >     graph_attr_dict_factory: ClassVar[MapFactory] = dict > ``` >  > with ordinary methods >  > ```python >      def node_dict_factory(self): >          return dict() > # etc. > ``` >  > This involves: >  > * Removing the class variables > * Adding member functions > * Fixing various tests that override these functions to override them in the usual way of overriding methods > * Running some timing tests to verify that the code is not significantly slower (since that seems to be the networkx's team main concern with their design decision to use class variables), and > * then opening a pull request and getting the change merged. >  > Doing this would greatly simplify this pull request, and it would resolve all but two of the remaining 27 mypy errors that this pull request currently has.  i'm not totally clear what these tests are actually testing-  here's an example-  ```python class mydict1(dict):     pass  class MyGraph(Graph):     node_dict_factory = mydict1  G = MyGraph() assert isinstance(G._node, mydict1) ```  is this just testing that the factory is correctly overridden in the derived class? If you use a normal member function and inheritance, any tests of this nature surely become redundant?
comment
> I'll just insert a short comment here. For this case, a PR was merged 2 days ago that removes the lines which set instance variables that have the same name as the class variables. So, if you can pull in those latest changes from the upstream main branch it will get rid of all those errors.  does this help @NeilGirdhar?
comment
> > does this help @NeilGirdhar? >  > @danieleades It helps a lot! This fixes a lot of the MyPy errors. However, MyPy still doesn't support calling callable class variables, which is one reason I suggest trying to replace them with ordinary methods. It's also more flexible. But yes, now it's not as pressing, and if the callable class variables are desired, then you can just ignore the errors until mypy catches up.  That's a win then. I'd still prefer that ordinary methods were used- I would consider that Least Surprising. I'm also wary there's a bunch of redundant test cases around this initialisation that are going to confuse future would-be contributors by making them believe there's some black magic going on, when it's really just obfuscated inheritance.
comment
> I've personally run into an issue where `Type | AnotherType` raised issues in Python3.8 environments and had to change everything back to `Union` and `Optional`. I honestly can't remember what the exact issue was, and maybe there was a misstep on my part, but just a mention for now to double check any edge cases for older versions before making any major changes.  most likely a missing `from __future__ import annotations` line. I think this is a red herring though, since CI can be made to catch this very easily
comment
These damn kids and their inline annotations!  ---  > But I think the reluctance is also deeper than that. For many years a selling point and design choice for python packages has been "duck-typing", where you don't check types. You try to make it quack and if it does, then you treat it like a duck. If Python code starts to look like C or Java code then we might as well be programming in C or Java -- which are often faster anyway because they are compiled. So there is a long history of phrases like "use hasattr, not isinstance". And the goal of writing code to accept any reasonable input is a reasonable goal.  see ['Protocols'](https://peps.python.org/pep-0544/)  >  > The code I have seen with inline annotations requires a novice to learn a huge amount -- or else just try to ignore all the annotations at first. I'm hopeful that Python can find a way to ease the learning curve required to read code with annotations.  please try to understand that type annotations make it easier to read code you are not familiar with. They are not a burden to tolerate simply because of the static analysis benefits- they are actively helpful in creating understanding. As Guido Van Rossum has noted: "Code is read more often than it is written". That's probably why he's on the core `mypy` team.  > * it would be good to add a stub files version of typing as a PR. People can make suggestions and improvements similar to the work in this PR. We can try it out.  Having stubs in separate files makes it difficult to reason about how to edit or improve stub files. Tooling to check for consistency does exist, but that'll run in CI, and won't have IDE support. In short, this will have a chilling effect on typing contributions  > * We have been including type information in our doc-strings for a long time. It would be good to have tools that can check the doc_string type information against the inline or stub annotations.  A good place for this code is likely to be mypy. But other avenues for contribution are available or can be created.  this is the wrong approach. Annotations *replace* type information in doc-strings. You absolutely don't want two sources of truth. Modern python documentation generators will generate the same html. If you *must* do this, you have [darglint](https://github.com/terrencepreilly/darglint).  > * it would be good to improve the tools like mypy and others which work with code and annotations to allow people to see the code they want with annotations as they want. This includes: >    >   * merging stub files with code to get inline annotations.  like this - https://pypi.org/project/retype/ ?  >   * splitting inline annotations into stub files and code files.  I don't imagine there's a lot of appetite in the community to develop this. Maybe limited to people trying to write python-2 compat.  >   * pulling type annotations out of numpy-style documentation and creating inline annotations (or stub files)  sounds useful  >   * taking inline type annotations and putting that information into doc_strings.  why would anyone want this? it's entirely redundant.  ---  This is a disappointing outcome.
comment
strongly agree with @songololo  - the type annotations are relatively complex, because the underlying domain which they encode is relatively complex - there are good strategies for simplifying them, and they are well-shown in this PR - **the type signatures of these methods are no less complex without annotations, they are simply more opaque!**  > This situation will improve as type syntax is simplified, but currently typing can quickly get hairy for, e.g., Callables, as well as most other non-trivial examples  I understand where you're coming from here, but I have to disagree. The type annotations are only as complicated as they need to be to specify the domain you're working with. I'll take up-front complexity over opacity *any day*.  there are methods in `networkx` that are complex, generic, and overloaded. Type annotations are a specification of the signature of a method (among other things). We should therefore *expect* some complexity in the annotations. Omitting the specification of the behaviour of a method does not simplify the method. And it makes it infinitely harder to correctly use that method *especially for new users*  to use your specific example. `Callable` *is* verbose, because it's a complex thing to specify. This is probably why callbacks and factories are usually among the worst-documented objects in any given code-base that uses them. Note too that most of the `Callable`s in this PR would disappear if #5890 were to be merged...
comment
for those who came here looking for type stubs, you may wish to try [rustworkx](https://github.com/Qiskit/rustworkx), which has a similar API and is fully-typed. It's also [significantly faster](https://www.rustworkx.org/dev/benchmarks.html).
comment
> As noted in #3988 , NetworkX is relying on typeshed for developing and maintaining the type annotations for networkx. The NX developers are incredibly grateful both for the typeshed project and all of the folks who have contributed/continue to contribute to the annotations there!  this is a noble endeavour, but i don't think it should obviate engagement on making very minor changes in-source to networkx to improve integration with out-of-source type stubs. such as:  - https://github.com/networkx/networkx/pull/5890 - https://github.com/networkx/networkx/issues/3988#issuecomment-1863509645
comment
i've just started using this library, and i strongly agree with this. Usage would be far more discoverable with type annotations.  One slight speedbump with adding stricter mypy config to this library is that the `src` and `tests` are not separated. Often you'll want a stricter mypy config for source than for tests (at least, while incrementally adding annotations), which is painful to do when there's no separation. Is there a reason for not having separate directories? 
comment
> Hi folks, wanted to share a small library I made for typehinting (and checking!) attributed graphs: https://github.com/a-r-j/graphtype >  > If there’s interest I’d be happy to help build this in to NetworkX  as you can probably see from the discussion over at #4014 the real challenge here is in convincing maintainers that type annotations are a welcome improvement to the library.
comment
they look possibly auto-generated? lots of `${arg}: Any` in there. certainly a lot less accurate and less useful (at least, at this stage) than what was proposed in #4014   maybe the author can comment? (@eggplants)
comment
any movement on this?  The [adoption rate of type annotations in python libraries is extremely high](https://py-code.org/stats) and i feel the maintainers of this library are *very* much on the wrong side of history here...
comment
> I'm personally starting to become motivated to switch to a library that has better support for type integrity checks and better runtime and memory performance.  I feel like the best outcome would be a small, highly-performant, and fully-annotated graph structure library, and then a larger, separate library implementing a rich collection of algorithms on top of that. Basically I would propose that `networkx` split out the core graph data structures into a separate library for general use, and then continue tinkering away in a separate library that imports it as a dependency.  In the meantime, i'm going to take a look at [rustworkx](https://github.com/Qiskit/rustworkx) (formally retworkx). it still uses out of source annotations, but at least they're in the same repository. Looks like they're possibly autogenerated from Rust bindings.
comment
> Well, scratch all that; Windows doesn't allow you to use the `name` attribute of a `NamedTemporaryFile` object more than once! PR updated accordingly.  can you expand on this? does setting `delete=False` resolve this? 
comment
there are a couple of open issues in ruff for small inconsistencies between it and isort, so i don't think that's quite settled yet. That said, I don't think they're worth losing any sleep over. You might see some of the changes revert down the line after a ruff update
comment
> It seems like this should be included in the upstream library `flask` rather than trying to get every Python library in PyPI to import a second library in order to fix flask.  flask will not implement this upstream - https://github.com/pallets/flask/pull/4797
comment
see #5890 
