issue
Keep omega within [-1, 1] bounds#TITLE_END#Closes #5064   The problem of #5064 regards network examples, where the calculated small-world omega metric does not lie within the bounds of the specified [-1,1] intervall. In order to check where this is coming from, I tried to find any differences in the description of the calculation from the original paper to the implemented version. The following was changed in this PR:  - Changing from nx.transitivity to nx.clustering for the clustering coefficient - Changing default values for niter and nrand. Note: niter=5 is specified for the lattice and niter=10 is specified for the random reference. And nrand_random=50 is mentioned in the section "Random and lattice network construction" for the random reference graph. nrand_lattice is not explicitly stated, which is why I leave the default value for nrand=10, as the computation of omega quickly becomes unfeasible, mostly due to the lattice calculation. - Changing from average clustering to maximal clustering: In the original paper they only accept a new lattice reference graph, if the clustering in the generated graph is higher than that from the previos generated lattice. The aim of this procedure is to find a lattice reference with the maximum clustering while preserving the degree distribution of the original graph. - Adding tests for some graphs to check if there lie within the bounds. I used the graph from the issue, the already used graphs in the testing function and added the karate graph. In a previous version I had various additional graphs, but the calculation took quite a while, which is why I kept the graph examples to a minimum in order to not blew up the test suite execution time. 
comment
I would like to look into this issue including the comments from the discussion. From the contributor guide I could not identify if issues get assigned, so I would just start? If I am missing something, please let me know.
comment
I tried to keep it as short as possible, but I think the explanation is necessary for further discussion.  Following the comments from @jtrim-ons, I started by inspecting if the \[-1, 1\] bounds are meant to be tight. From what I understand,  yes, they should be tight bounds, even if they mention a deviation for small networks:  *Note that as the size of the network is reduced, the tails of the x curve deviate from the bounds of the [1,1] interval, particularly from 1. This finding is due to the fact that in a very small network the real path length never becomes very large relative to the path length of the random network.*  But from my understanding this part means that the values for omega do not converge (from within the bounds) to the bounds of the interval, regardless of the used rewiring probability.  Then, further following the comments from @jtrim-ons, I changed from transitivity to clustering coefficient (nx.average_clustering(G)) as used in the paper and also adjusted the values for niter and nrand (more details on this below). But both changes did not change the value for `omega` being around -1.5 for the graph mentioned by @mamonu (nx.barbell_graph(5, 1)).  Then I turned back to the paper and tried to understand in more detail the construction of the random and lattice reference and I noticed a clear difference. While the random reference graph seems to be constructed with the Maslov and Sneppen algorithm (I checked the values for some graphs against the examples in the paper and they match exactly), the lattice reference _"(...) was generated by using a modified version of the 'latticization' algorithm (Sporns and Zwi, 2004) found in the brain connectivity toolbox (www.brainconnectivity-toolbox.net) (Rubinov and Sporns, 2010) (...)"_. I checked the Matlab Code from this toolbox against the Sporns and Zwi implementation for the lattice reference and this seems to be fine. The key difference is the *adjusted* version they mention, which is explained in more detail in the supplemental material. In short: They do not calculate the mean clustering coefficient over several generated lattice reference graphs (as the omega implementation does now), but rather try to maximize the clustering coefficient  by only accepting a new lattice reference, if the clustering is higher. Otherwise the old lattice is kept.   Changing this yields an omega of around -0.28 for the mentioned barbell graph (I tried different seeds and iterations and this is rather robust). With this adjustments I get for the Karate graph an omega of around -0.065 and for the word adjacency graph 0.55. (It should be noted though, that even if this values are now closer to the reported values for omega from the paper, there is still a gap which could be due to something else than only random variation. At least in my calculations the variation for omega with different seeds does not vary for the same graph that much).  If you agree with my findings, I would continue to implement the following:  - Changing from transitivity to clustering coefficient - Changing default values for niter and nrand: 	- Note: Not all of this values are explicitly mentioned. 	- niter_lattice=5 is mentioned in the supplemental material 	- niter_random=10 and nrand_random=50 is mentioned in the section "Random and lattice network construction" 	- nrand_lattice is not explicitly mentioned and only described as "performed over several user-defined repetitions". For my calculations I used also 50, but I would question this choice as the default value, as e.g. the calculation of omega took 23 minutes for the word adjaceny graph with 112 nodes. Furthermore, for larger networks (N>1000) they completely switch to a "sliding-window approach" for the lattice generation, which is further described in the supplemental material. It could be worth digging into this for the sake of efficiency. - Changing the calculation of clustering coefficient for the lattice using a maximal measure of the clustering coefficient as describe above
comment
And of course adding tests for `omega` being within the bounds, if we come to the conclusion that these are indeed tight bounds
