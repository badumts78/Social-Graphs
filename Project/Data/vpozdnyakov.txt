issue
Fix numeric and degree assortativity coefficient calculation#TITLE_END#It fixes #4776 and wrong assortativity coefficient calculation in some cases that follow PR #4851.  A cause of the issue is in `numeric_ac` in [correlation.py](https://github.com/networkx/networkx/blob/main/networkx/algorithms/assortativity/correlation.py). Before my fixes in `numeric_ac` ```python x = np.arange(nx) y = np.arange(ny) ``` we create supports for random variables x and y. We assume that node values are integer and coincide with mixing matrix indices — 0 is in the first row/column, 1 is in the second row/column and so on. But after PR #4851, node values can also be negative or float. In such cases we need to know a mixing matrix indices for each unique pair of values. After my fixes, supports of x and y contain all node values, not only integers. The same for degree assortativity coefficient calculation.  Note that the PR #4851 version also correctly calculates assortativity coefficient in the case of *equal intervals* between support values due to normalization (in fact, this is a correlation between x and y, not covariance). For example, it correctly calculates a degree assortativity coefficient for float node degrees `[0, 0.5, 1, 1.5]` or an assortativity coefficient for mixed node values `[-1, 0, 1, 2]`.  But in #4776 we have a graph with node values `[-1, 1, 2]` and then the old coefficient is incorrect. I added tests that check cases with non-equal intervals between support values — one for degree and one for node values.
issue
An error in numeric assortativity coefficient for negative integers#TITLE_END#### Environment Details  NetworkX version: 2.5.1 Python version: 3.7.10 Operating System: Google Colab web platform  ### Error Description  Calculation numeric assortativity coefficient for negative integers returns a `nan` value.  A warning description is ``` /opt/anaconda3/lib/python3.7/site-packages/networkx/algorithms/assortativity/correlation.py:287:  RuntimeWarning: invalid value encountered in double_scalars   return (xy * (M - ab)).sum() / numpy.sqrt(vara * varb) ``` ### Steps to reproduce  ```python import networkx as nx G = nx.path_graph(2) G.nodes[0]['attr'] = -2 G.nodes[1]['attr'] = -1 nx.numeric_assortativity_coefficient(G, 'attr') ```  ### Expected behavior  Assortativity coefficient is -1.  Here is my reasoning. In the original Newman's article https://arxiv.org/abs/cond-mat/0209450, the numeric assortativity coefficient is defined as  <img src=https://user-images.githubusercontent.com/12996098/119843827-9380b600-bf10-11eb-8f52-ef36719649e9.png width=200>  where `x` and `y` are nodes' attribute values, `e_{xy}` is the fraction of links that follow from nodes of value `x` to one of value `y`, `a_x` is the fraction of links that follow *to* nodes of value `x` *from* all others, `b_y` is the fraction of links that follow *from* nodes of value `y` *to* all others, `\sigma_a` and `\sigma_b` are standard deviations of distributions `a_x` and `a_y`. The distribution `a_x` here means a discrete distribution with a support is all nodes' values, and the probability is the fraction of links *to* `x`. The distribution `b_y` has the same support as `a_x`, but the probability is the fraction of links *from* `y`. In case of an undirected network, the distributions `a_x` and `b_y` are equal. In this sense, my example can be calculated as follows.  **Step 1** Make a list of pairs of nodes's values `x` and `y`: (-1, -1), (-2, -1), (-1, -2), (-2, -2) **Step 2** Calculate the fractions of edges `e_{xy}` for each pair: (-1, -1): 0, (-2, -1): 0.5, (-1, -2): 0.5, (-2, -2): 0 **Step 3** Calculate the fractions of edges `a_x` for each value `x`: (-1): 0.5, (-2): 0.5 **Step 4** The fractions of edges `b_y` for each value `y` are the same due to the undirected network. **Step 5** Calculate the standard deviation `\sigma_a`. Let us use the formula  <img src=https://user-images.githubusercontent.com/12996098/119851043-c2018f80-bf16-11eb-9483-8da8eee530db.png width=300>   First, calculate the expectation `E[X] = (-1) * 0.5 + (-2) *0.5 = -1.5 `  Next, calculate the second moment `E[X^2] = (-1)^2 * 0.5 + (-2)^2 * 0.5 = 1 * 0.5 + 4 * 0.5 = 2.5`  Thus, the standard deviation is  `\sigma_a = \sqrt{E[X^2] - E[X]^2} = \sqrt{2.5 - (-1.5)^2} = \sqrt{0.25} = 0.5`  **Step 6** The standard deviation `\sigma_b` is the same due to undirected network. **Step 7** Finally, let us compute the assorativity coefficient.   The nominator is the sum: `(-1) * (-1 ) * (0 - 0.5 * 0.5) + (-2) * (-1 ) * (0.5 - 0.5 * 0.5) + (-1) * (-2 ) * (0.5 - 0.5 * 0.5) + (-2) * (-2 ) * (0 - 0.5 * 0.5) = 1 * (-0.25) + 2 * 0.25 + 2 * 0.25 + 4 * (-0.25) = -0.25 + 0.5 + 0.5 - 1 = -0.25`  The denominator is `0.5 * 0.5 = 0.25`  Thus, the assortativity coefficient is `nomunator/denominator = -0.25 / 0.25 = -1`.  Here can be some mistakes or typos, but the obtained value is intuitively correct, since the assortativity coefficient is very close to the correlation and thereby -1 means that here are no links between equal values. Moreover, if we calculate the coefficient in the same network with positive values using NetworkX, we also get -1.
issue
Extremely slow calculation of numeric_assortativity_coefficient#TITLE_END#This simple example takes a minute  ```python import networkx as nx G = nx.path_graph(2) G.nodes[0]['attr'] = 19999 G.nodes[1]['attr'] = 20000 nx.numeric_assortativity_coefficient(G, 'attr') ```  I did not check source code, but it looks like the algorithm calculates all possible combinations of integers between 0 and 20000. An equation in corresponding Newman's article is  ![image](https://user-images.githubusercontent.com/12996098/99728876-2573b600-2acb-11eb-833a-0207c910e817.png)  and it is easy to see that only non-zero terms make sense.
issue
Fix assortativity coefficent calculation and tests#TITLE_END#This fixes some problems with assortativity coefficient calculation #3917, #4368, #4369, #4776.   Here is my explanation of fixes. The question is what do we expect the `mapping` variable to actually *map*? I have read the whole `mixing.py` module, the original Newman's article https://arxiv.org/abs/cond-mat/0209450 and decided that the most natural way to define the `mapping` variable is as follows:   *The `mapping` variable maps the unique nodes' attribute values to mixing matrix row and column indices.*  For example, if the network consists of nodes with the attribute "gender" of values "male" and "female", the `mapping` will be `{'female': 0, 'male': 1}`. In this terms, the entry [0, 1] of the normalized mixing matrix will contain the fraction of links that follow from female nodes to male nodes. Another example, nodes with the attribute "gender" contains integer values 0 (male), 1 (female). In this case, `mapping` will be `{1: 0, 0: 1}`. If the "gender" is decoded as -1 (male) and 1 (female), the `mapping` will be `{1: 0, -1: 1}`. As we see, this definition gives homogeneous and robust description of the mapping regardless of the values that decode underlying information.  Before my fixes, this definition holds only for categorical (strings) and positive integer values. After my fixes, this holds for categorical, integer, non-integer, positive, negative values (#4369, #4776). It works faster because we construct the mixing matrix that contains only non-zero rows and columns (#4368). In addition, there are no theoretical restrictions to use non-integer values for assortativity coefficient calculation. As follows from the original paper, the definition of the scalar assortativity coefficient is applicable for all scalar values, not only integers. Thereby, non-integer node degrees (in a weighted graph, #3917) are also feasible for calculation.   I have also changed the tests removing extra rows and columns containing only zeros.
issue
Incorrect link to the paper in katz_centrality documentation#TITLE_END#### Current Behavior  Link [2] in katz_centrality documentation directs to the incorrect paper: 'Universal Behavior of Load Distribution in Scale-Free Networks'  ### Expected Behavior Link [2] in katz_centrality documentation directs to the correct paper: 'A New Status Index Derived from Sociometric Index'  ### Steps to Reproduce Open the page https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.katz_centrality.html  ### Additional context I guess the correct link is https://link.springer.com/content/pdf/10.1007/BF02289026.pdf 
comment
@dschult I have taken a closer look at this issue and realized that my changes in PR #4851 do not fix it. Moreover, PR #4851 allows new cases with wrong assortativity coefficient calculation. A cause is in `numeric_ac` in [correlation.py](https://github.com/networkx/networkx/blob/main/networkx/algorithms/assortativity/correlation.py). In lines  ```python x = np.arange(nx) y = np.arange(ny) ``` we assume that node attribute values coincides with a mixing matrix indices — 0 is in the first row and first column, 1 is in the second row and second column and so on. As I see now, this method also needs `mapping` variable to correctly calculate assortativity coefficient, because we need to use actual node attribute values, not generated ones. The actual assortativity coefficient in this case is approx. 0.43 and it can be calculated using `numpy` as follows  ```python pairs = np.array(list(nx.node_attribute_xy(G, 'a'))) x, y = pairs[:, 0], pairs[:, 1] coef = np.corrcoef(x, y)[0, 1] print(round(coef, 2)) #returns 0.43 ```  At first glance, a solution can be to construct `mapping` in `numeric_assortativity_coefficient` and `degree_assortativity_coefficient` and use it in `numeric_ac` as follows  ```python x = np.array(list(mapping.keys())) y = x.copy() ```  and then it returns a correct coefficient  ```python mapping={-1: 0, 1: 1, 2: 2} mix_max = nx.numeric_mixing_matrix(G, 'a', mapping=mapping) coef = numeric_ac(mix_max, mapping) print(round(coef, 2)) #returns 0.43 ```  but it requires (1) to create `mapping` and (2) to sort node attributes values in `mapping` that can be expensive.  Much bigger problem that I realized thanks to this issue is that my changes in PR #4851 make `degree_assortativity_coefficient` and `degree_pearson_correlation_coefficient` return different values in cases where values do not coincide with mixing matrix indices, for example  ```python S1 = nx.star_graph(4) S2 = nx.star_graph(4) S = nx.disjoint_union(S1, S2) S.add_edge(4, 5) print(nx.degree_assortativity_coefficient(S, weight="weight")) # returns -0.87... print(nx.degree_pearson_correlation_coefficient(S, weight="weight")) # returns -0.93... ```  Correct one is `degree_pearson_correlation_coefficient`. Now it is obvious that PR #4851 should have contained fixes for this problem. I will try to propose a solution in separate PR.
