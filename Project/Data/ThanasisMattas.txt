issue
Fixes #3112 - Extends greedy_modularity_communities() to digraphs, multigraphs and multidigraphs#TITLE_END#This PR fixes #3112 . ```greedy_modularity_communities()``` is extended to ```DiGraph```'s, ```MultiGraph```'s and ```MultiDiGraph```'s. The formulas used can be found in the [paper](https://github.com/elplatt/Paper-CNM-Modularity/blob/master/paper.pdf) provided by @elplatt.  The bulk of the changes concerns the initialization of the data structures: - ΔQ matrix (```dq_dict```). It holds the ΔQ of the merge of every pair of communities - ```a``` dict. It contains the fraction of (total weight of the) ends of edges that are attached to vertices in each community - ```b``` dict. It is introduced when the graph is directed and contains the fraction of (total weight of the) heads (in_degree) of edges that are attached to vertices in each community. In that case, ```a``` contains the fraction of (total weight of the) tails (out_degree) of edges that are attached to vertices in each community.  One more significant change consists in ```node_for_label``` and ```label_for_node``` encoder/decoder dicts being removed. Therefore, a, b and dq_heap became dicts, accessing their entries with the true node-labels, instead of an integer encoding. This way, the code got somewhat simpler.  For multigraphs, see [this comment](https://github.com/networkx/networkx/issues/3112#issuecomment-891014425).
issue
Bugfix - use node labels with get_edge_data() at greedy_modularity_community()#TITLE_END#This patch solves the following bug:  In ```greedy_modularity_communities()``` an encoder/decoder pair is used (```node_for_label``` & ```label_for_node```), in order to encode node-labels to contiguous integers, to use them as indexes. In order to access edge data with ```G.get_edge_data(i, j)```, ```i``` and ```j``` have to be node-labels of G and NOT their integer representations.   The current tests are using ```nx.karate_club_graph()```, which already has contiguous integers (starting from 0) as labels and, thus, ```node_for_label``` is encoding to the same labels:  ```bash python -c "import networkx as nx; print(nx.karate_club_graph().nodes)" ```  ``` [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33] ```  and the case where node-labels are not contiguous integers is not covered.  ### How to reproduce:  ```python import networkx as nx from networkx.algorithms.community import greedy_modularity_communities  def main():   G = nx.Graph()   G.add_edges_from([     ('a', 'b'), ('a', 'c'), ('b', 'c'), ('a', 'd'), ('b', 'd'),     ('d', 'e'),     ('d', 'f'), ('d', 'g'), ('f', 'g'), ('d', 'e'), ('f', 'e')   ])    c = greedy_modularity_communities(G)   for i in c:     print(i)  if __name__ == "__main__":   main() ```  ``` Traceback (most recent call last):   File "/path/to/test_script.py", line 15, in <module>     main()   File "/path/to/test_script.py", line 12, in main     c = greedy_modularity_communities(G)   File "/path/to/networkx/algorithms/community/modularity_max.py", line 98, in greedy_modularity_communities     dq_dict = {   File "/path/to/networkx/algorithms/community/modularity_max.py", line 99, in <dictcomp>     i: {   File "/path/to/networkx/algorithms/community/modularity_max.py", line 100, in <dictcomp>     j: 2 * q0 * G.get_edge_data(i, j).get(weight, 1.0) AttributeError: 'NoneType' object has no attribute 'get' ```  ### Expected  ``` frozenset({'g', 'e', 'd', 'f'}) frozenset({'b', 'a', 'c'}) ``` ### Solution  This fix uses the decoder to access the real node-labels, while querying for edge data:  ```python G.get_edge_data(label_for_node[i], label_for_node[j]) ``` 
comment
@dschult Oh yes, you are absolutely right. Maybe in case of a ```multigraph``` there could be a separate calculation of ```dq_dict```, instead of calculating it and then making the correction. But yes, the correction should be applied at all edges regardless.
comment
Very nice changes by the way!
comment
Offering my 2 cents here, I would like to comment on the ```MappedQueue``` implementation. The look-up dict was mentioned at the python docs [here](https://docs.python.org/3/library/heapq.html#priority-queue-implementation-notes), suggesting that the task should be used as key, not the priority value, given that there is a hashable task-id. This way, the problem of multiple tasks having the same priority, thus the entry in the look-up dict will be overwritten, is automatically resolved. Also, it feels more natural to look-up by some unique id, rather than its priority. I recently implemented this enriched priority queue [here](https://github.com/ThanasisMattas/shortestpaths/blob/master/shortestpaths/priorityq.py), following the above suggestion, in order to use it with Dijkstra's algorithm. I think that it would be cleaner and simpler to modify the ```MappedQueue```, as suggested at this https://github.com/networkx/networkx/pull/5000#issuecomment-904314643, although the ```_ProxyHeap``` approach is a nice one.
comment
Can I help with this one? How shall we proceed?
comment
Hi all! I would like to work on this, if that is ok.   Starting from reading the pdf provided by @elplatt, I have some questions concerning the **1 + δ<sub>ij</sub>** term, which accounts for self-loop edges, in equations 18 and 19, which handle the initialization of ΔQ<sub>ij</sub>.  1. Aren't the two stubs already covered by A<sub>ij</sub> + A<sub>ji</sub>? 2. Is ΔQ<sup>0</sub></sup><sub>ij</sub> evaluated when i = j, in the first place? Can a single-node community be merged with itself? The current implementation handles that here:<https://github.com/networkx/networkx/blob/2eb274e39f712047cebf5666ee9caf2ba2e51ee4/networkx/algorithms/community/modularity_max.py#L98>  Of course, from what I can tell, when calculating modularity and m, the term (1 + δ<sub>ij</sub>) makes total sense and, having tested some examples, I think the current implementation accounts for self-loops, in all weighted and unweighted Graph's and DiGraph's.  As for MultiGraph's, I think they are not currently supported.  ```python G.get_edge_data(i, j).get(weight, 1.0) ```  always evaluates the weight of a multiedge to 1, because a key was not provided (i.e. ```(i, j, key)```).  A solution would be to add a correction like the following, after evaluating the ```dq_dict```.  ```python # dq correction for multi-edges from collections import Counter  edges_count = dict(Counter(G.edges())) multi_edges = {edge: count for edge, count in edges_count.items() if count > 1} ```  ### unweighted  ```python for edge, count in multi_edges.items():     dq_dict[edge[0]][edge[1]] += 2 * q0 * (count - 1)     dq_dict[edge[1]][edge[0]] += 2 * q0 * (count - 1) ```  ### weighted  ```python for edge in multi_edges:     total_wt = sum(wt for u, v, wt in G.edges(edge[0], data=weight) if v == edge[1])     dq_dict[edge[0]][edge[1]] += 2 * q0 * (total_wt - 1)     dq_dict[edge[1]][edge[0]] += 2 * q0 * (total_wt - 1) ```  ### both  ```python multi_edges = [edge for edge, count in edges_count.items() if count > 1] for edge in multi_edges:     total_wt = sum(v.get(weight, 1) for v in G.get_edge_data(*edge).values())     dq_dict[edge[0]][edge[1]] += 2 * q0 * (total_wt - 1)     dq_dict[edge[1]][edge[0]] += 2 * q0 * (total_wt - 1) ```  As for MultiDiGraph's, I will have a look after DiGraph's are covered.
comment
Ok, thanks! Yes, it is clear now. So, ``` if j != i ``` at dq_dict initialization holds for any occasion.
comment
Is it possible for #4965 - #4996 to be merged, in order to proceed? Thanks.
comment
I have another question, although not super important.  Can this statement be False?  <https://github.com/networkx/networkx/blob/d475ffe7b24633934b5e566974fe7e72a9400cf4/networkx/algorithms/community/modularity_max.py#L126>  If i, j merge has the best dq, is it possible for the j-row to have as its 1st item a better one? Wouldn't that be the one popped from H at that iteration, instead of i, j? From some examples I run locally, it never goes to else.
comment
Oh, I see. In the case of a tie, it probably makes sense. I will try to get back on this, when it is possible. Thanks!
