issue
Unexpected behavior when using np.int64 instead of int when creating a graph#TITLE_END#<!--- Provide a general summary of the issue in the Title above --> When trying to create a lollipop graph, I get different results depending on whether the arguments passed are `int` or `np.int64`.  ### Current Behavior Two DIFFERENT graphs are returned, even when the arguments are numerically the same.  ### Expected Behavior The two graphs should be the same.  ### Steps to Reproduce ```python >>> G = nx.lollipop_graph(3, 3) >>> H = nx.lollipop_graph(np.int64(3), np.int64(3)) >>> G.order(), G.size() # correct, expected (6, 6) >>> H.order(), H.size() # wrong, unexpected (3, 3) ```  ### Environment <!--- Please provide details about your local environment --> Python version: 3.8.10 NetworkX version: 2.5 numpy version: 1.20.2   ### Additional context This happened when trying to create multiple random lollipop graphs like thus: ```python for n1, n2 in np.random.randint(3, 20, size=(100, 2)):     G = nx.lollipop_graph(n1, n2) ``` `np.random.ranint` usually returns an `int`, but when used to generate an array instead of a single number, the type of each number is `np.int64`, as the following code shows: ```python >>> for n1, n2 in np.random.randint(3, 20, size=(100, 2)): ...     print(type(n1))  <class 'numpy.int64'> ```
issue
Clarify documentation for predecessors() and successors(). Fixes #3113.#TITLE_END#â€¦Graph.successors.
issue
change articulation_points so that it only returns every vertex once#TITLE_END#Solves #2331.
comment
Is this issue open to anyone for comment? If so, before I can contribute to this conversation, there's something I may be missing. What is the expected difference between ``` G = nx.MultiGraph().update(nx.path_graph(9)) ``` and ``` G = nx.MultiGraph(nx.path_graph(9)) ``` ?
comment
Thanks, I understand now that the main advantage of `update` is that it can be called on an already existing graph. And I understand that the point of this issue is to get rid of `create_using`. However, I still don't understand why the documentation would encourage `G = nx.MultiGraph().update(nx.path_graph(9))` over `G = nx.MultiGraph(nx.path_graph(9))`.   Apologies if I'm becoming an obstacle in the development of this issue. I just want make sure I'm up to speed in the conversation before working on a PR.
comment
I see your point. I agree that it's more easily readable to say/write "I want X graph of type Y", and the original `nx.path_graph(9, create_using=nx.MultiGraph)` achieves that. It can also be done by splitting the line into  ``` G = nx.path_graph(9) G = nx.MultiGraph(G) ```  Though that's probably a little clunky. Another option is `G = nx.path_graph(9).to_multigraph()`, mirroring the current `to_directed()`.  Yet another one is `G = nx.path_graph(9, type="multi")`. For this last option, it would be possible to implement something like `G = nx.path_graph(9, type="edges")` and return an edge generator. Using strings rather than objects (like old `create_using`) or classes (like current `create_using`) allows for this flexibility.  
comment
How are you extracting the largest component? How do you determine that it's connected? If you are using `nx.weakly_connected_component_subgraphs` or something similar that returns *weakly* connected components, not every pair of nodes is guaranteed to have a directed path joining them.
comment
@idc9 can you please post what would be the expected GML output file for your example code? IIRC, GML only supports string attributes, so the `datetime` object would have to be implicitly converted to string before writing. 
comment
See #3114.
comment
After investigating the problem, node `1` is returned twice because the algorithm identifies two different biconnected components that split from the original graph after removing `1`. This is due to the fact that the algorithm proceeds by DFS traversal. Starting at `0`, node `1` will be identified as articulation point after traversing down its child `2` (and everything that follows from `2`), and once again after traversing down node `3`.  It seems to me that this behavior is already known, since [all tests](https://github.com/networkx/networkx/blob/6e20b952a957af820990f68d9237609198088816/networkx/algorithms/components/tests/test_biconnected.py) that involve `articulation_points` call `set` over the returned list (thus deleting the duplicate values).  @malbarbo I would advice just calling `set` over the return value, as it seems that there is some valuable information in the repeated values in the returned list of `articulation_points`.  @jfinkels On the other hand, if this is not expected behavior, it should be easy to add a quick memoification step inside `articulation_points` so that the same node is not yielded more than once. I could do this if there is interest.
comment
The proposed PR should take care of this.  About this "multiplicity" information. This needs confirmation but my working hypothesis is that each articulation point appears in `list(_biconnected_dfs(G))` a number of times equal to the increase in the number of components in the network after removing that articulation point. In @malbarbo's example, `1` appeared twice because the network would break up in three components after removing `1`, thus increasing the number of components by 2.  If this is the case, then we could implement a new function, say ```python def number_of_components_articulated_at(G):     count = Counter(list(_biconnected_dfs(G)))     return {node: count[node] + 1 for node in count.keys()} ``` 
comment
Solved by #2333.  @jfinkels thoughts on the proposed `number_of_components_articulated_at`?
comment
Please post what you have tried and what went wrong so we can help better. 
comment
> `community=asyn_lpa_communities(net01[, weight])`  This is invalid python syntax. I assume you have copied this code from some documentation. When you see square brackets with a comma in the first place, like in `(net01[, weight])`, it means the function can be called in two different ways. Either by specifying only the first parameter, or both. So, either do `community=asyn_lpa_communities(net01)`, which is what you are doing and it will not consider the weights because you are not passing any, or do `community=asyn_lpa_communities(net01, weight)`, without the square brackets.  Please refer to [this](https://networkx.readthedocs.io/en/latest/reference/generated/networkx.algorithms.community.asyn_lpa.asyn_lpa_communities.html) page which determines how to use the second parameter. 
