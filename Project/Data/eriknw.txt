issue
Add autoflake and pyupgrade as manual pre-commit hooks#TITLE_END#In the community call, we considered introducing manual pre-commit hooks that can occasionally be run. This PR shows how this can work. These pre-commit hooks can be low value or mostly cosmetic, or slow, or prone to causing a nuisance if run on every commit, or experimental to consider adoption, and I think it's fine if these are _never_ called, or, more realistically, called every year or two.  `autoflake` is handy to _carefully_ remove unused imports. I find it usually does a great job and doesn't try to do too much (like ruff). #7864 ran `autoflake`.  `pyupgrade` is largely handled by ruff, but in my experience `pyupgrade` may have rules that ruff does not apply. This is the case right now.  Also, I re-added #7861 to `.git-blame-ignore-revs`. This was added in #7862, then removed in #7869. This also undoes the line moves in  `.pre-commit-config.yaml` that was done in #7869.  For a project like networkx, I think it may be nice to have some pre-commit rules that always get run, and some that are manually run (probably by the core maintainers). Things that always get run should be friendly and helpful to new contributors. So, this opens the door for other pre-commit hooks that can help the core maintainers ensure the quality of the code without being a hindrance to other contributors.
issue
Dispatch classes such as `nx.Graph(backend=...)`#TITLE_END#I was experimenting running libraries that depend on networkx, and I wanted to also dispatch classes to backends just to see. This PR dispatches e.g. `nx.Graph(...)`. When we previously discussed possibly doing this, we agreed "not yet", so let's discuss again. I think the changes to enable this are actually pretty minimal; as ever, testing would be nice to have.  CC @rlratzel. Also, @aMahanna, you may find this interesting; you could do e.g. `nx.Graph(backend="arangodb", db=db)`.
issue
`dissuade_hubs=` argument is unused in `forceatlas2_layout`#TITLE_END#`forceatlas2_layout` was added to version 3.4 by #7543, and it appears that the `dissuade_hubs=` has never actually done anything--it's not used by code nor is it tested.  What is it supposed to do? Should it be removed? Is it meant as something that can be implemented; if so, should docs say it's not implemented yet?  CC @cvanelteren and @rossbar who worked on the implementation in networkx.
issue
Ensure that backend names are valid Python identifiers#TITLE_END#In #8115, a user encountered an error when a backend name was not a valid Python identifier.  @amcandio suggested we guard against this https://github.com/networkx/networkx/issues/8115#issuecomment-3092681130.  Notably, it's possible for users to encounter this when e.g. `networkx.egg-info/entry_points.txt` file has an *old* entry for `nx-loopback` instead of `nx_loopback`, as may have happened in #8115.  This PR ignores backends that are not valid identifiers, displays a warning when this happens, and updates documentation to indicate that backends must be valid Python identifiers.  Instead of checking when creating the config as suggested in https://github.com/networkx/networkx/issues/8115#issuecomment-3094631390, this PR checks when loading the entry points for backends.  If an invalidly named backend uses both `networkx.backends` and `networkx.backend_info` entry points, two warnings will be issued.
issue
Small dispatching refactor: simple `__call__` when no backends#TITLE_END#Having a simple, short `__call__` function when no backends are installed may make for nicer tracebacks and debugging.  I decided to define the `__call__` functions outside the class, since this let us remove an indentation level instead of adding an indentation level.
issue
Add Leiden as a backend-only algorithm#TITLE_END#Note that a WIP implementation is being done in #5964. It may be nice to include documentation and authorship from there.  If we want this as a backend-only function for now, I think we should consider adding #7690.  There are different "flavors" of Leiden floating around; some have a `beta` paramter, some a `theta` paramter, others indicate the minimum number in a community, other set the maximum number in a community, some implentations have none of these, and so on. I think a deeper discussion regarding prior research and implementations should be done in a separate issue. This PR takes a minimalist approach: if backends have extra parameters, they can add them as backend-only argument. How convenient! We may want to revisit #7297 if we expect backends to have different additional arguments for Leiden.  The tests are relatively basic, but I figure something is better than nothing and may aid backend implementers.  I think we should figure out how to document backend-only functions. Perhaps an admonishment can be automatically handled as part of #7690.  We have begin to add Leiden to nx-cugraph: https://github.com/rapidsai/nx-cugraph/pull/50
issue
Clean up pygrep pre-commit for import convention checks#TITLE_END#This is a quick follow-up to #7821.  The last commit in #7821 added `"^ *"` to the regex string to avoid false-positives by only matching lines that begin with spaces (optional) and "import". Without this regex, we would get the following: ``` Check import conventions; see CONTRIBUTING.rst#guidelines.......................Failed - hook id: check-import-conventions - exit code: 1  CONTRIBUTING.rst:288:  ``import scipy.sparse.linalg as spla``. doc/release/api_0.99.rst:290:>>> import networkx # e.g. centrality functions available as networkx.fcn() doc/release/old_release_log.rst:730:     >>> import networkx doc/release/old_release_log.rst:1036: - import networkx doc/release/old_release_log.rst:1037: - import networkx as NX networkx/lazy_imports.py:117:    The workaround is to import numpy before importing from the subpackage. networkx/lazy_imports.py:151:          spla = lazy.load("scipy.linalg")  # import scipy.linalg as spla networkx/tests/test_import.py:11:        from networkx import networkx ``` In a way it's nice to have `exclude: |` section so it's clear how to use it and add to it--and there's no particular need to check these files--but excluding these files is no longer necessary.
issue
Ensure standard import conventions are used#TITLE_END#I was poking around open issues and saw #4426, which referenced #4401. So, I took a minute to explore whether these conventions are actually used. Linting tools such as flake8-import-conventions can also do something similar to the simple pre-commit pygrep hook I added.
issue
Fix `with nx.config(backend_priority=backends):`#TITLE_END#Previously, it didn't restore the original values  Thanks @rlratzel who discovered this.
issue
Fix exception for backend-only functions#TITLE_END##7690 enabled backend-only functions, and we did a small refactor of dispatch `__call__` in #7761. When #7690 was merged into #7761 from the main branch ([here](https://github.com/networkx/networkx/pull/7761/commits/f714e178af0fd5d687743d44984b61ce9ebaa0fd)), the new error message was put in the wrong call function and recreated a block of code that was deleted.  Anyway, this PR fixes things.
issue
Update dispatchable for `forceatlas2_layout`...#TITLE_END#to handle new `store_pos_as=` parameter introduced in #7571, which mutates the input graph when used.  #7571 and #7794 (which just added `@nx._dispatchable` to FA2) were merged virtually simultaneously, so there was no chance to update one with the other.
issue
Fix use of triple backticks in docstrings#TITLE_END#I noticed the docstring for `from_pandas_edgelist` was not rendering a code block correctly because it used triple backticks <code>```</code>, so I did a quick grep to fix their use in docstrings. See incorrect docs here: - https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html - https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_adjacency.html - https://networkx.org/documentation/stable/reference/algorithms/d_separation.html
issue
Update readwrite docstrings for the `path` parameter#TITLE_END#Some read functions said "write", and some didn't describe the ability to compress or decompress. Also, I prefer "decompressed" over "uncompressed".
issue
Don't use `assert` when using `pytest.raises`#TITLE_END#Using `assert` with `pytest.raises` is unnecessary.  Tiny stylistic fix to encourage better practice. Some linter may check for this (not sure), but this was trivial to search-and-replace.
issue
Fix docstring example of `nx.generate_random_paths(index_map=...)`#TITLE_END#As discovered in https://github.com/networkx/networkx/pull/7817#issuecomment-2635286426, the docstring example with using `index_map` is incorrect, because it was trying to index into a generator.  This argument is a little awkward to use since this function is a generator and `index_map` will be updated incrementally, but I believe the updated docstring example is what was intended.
issue
Remove unnecessary `dict(...)` for SSSP algos that return dicts#TITLE_END#When reviewing #7877, I noticed a call to `nx.single_source_shortest_path_length` was wrapped with `dict(...)`, which is now unnecessary (and to me was confusing/surprising). So, a quick `git grep` revealed where this pattern is occurring.  I updated tests too, which I think is helpful to ensure return types are correct for backends that implement these.
issue
Remove unused imports#TITLE_END#Some more cleanup since we're in the mood for linting.  I did this by adding ```yaml   - repo: https://github.com/PyCQA/autoflake     rev: 0544741e2b4a22b472d9d93e37d4ea9153820bb1 # frozen: v2.3.1     hooks:       - id: autoflake         args: [--in-place] ``` to `.pre-commit-config.yaml` locally.  I'll let somebody else decide whether we want to add this check to `.pre-commit-config.yaml`. Ideally, it would probably be best if `ruff` could take care of this to have it run faster and not add another tool that we need to update, but I haven't tried to do this.  Like a lot of other linting, I think it would be fine to run this every couple of years or so.
issue
Fix some typos#TITLE_END#s i m
issue
Pre commit hooks to check line endings and trailing whitespace#TITLE_END#This is a follow up to #7861 to prevent regression by adding a pre-commit to check for CRLF line endings.  While here, I took the liberty to add a few sanity checks. These typically run very fast. They're typically not high-value, so also happy to remove 'em if anybody feels strongly against them.  Also, in the second commit I added a hook to remove trailing whitespace. This has been secretly nagging me since I started contributing to NetworkX.
issue
Faster `could_be_isomorphic` and `number_of_cliques`#TITLE_END#When looking at #7852, @rossbar noticed `could_be_isomorphic` could be made much faster by counting cliques faster. Same change applies to `number_of_cliques` too, and I updated the recipe in the docstring of `find_cliques` to avoid the slow recipe.  Additional changes that could be made (preferably in other PR(s)): - Recipe in `find_cliques` could be replaced by `number_of_cliques` (or at least mention it) - `could_be_isomorphic` could also use `number_of_cliques`, but used simple one-liner for performance - Docstring of `number_of_cliques` doesn't describe parameters or return types, and incorrectly says returns a list
issue
Fix BC scaling for source nodes with k and endpoints=False#TITLE_END#This is a follow up to #7908 and specifically @dschult's question from https://github.com/networkx/networkx/pull/7908#pullrequestreview-2711295366: > The case with k < n and endpoints is False still confuses me. It seems like the number of valid (s, t) node pairs that could have a path through v where s != t should depend on whether node v was in the sample or not in the sample. The largest possible count for nodes in the sample (when endpoints is False) is (k-1)*(n-2), but for nodes not in the sample the count can be k*(n-2). Why are we using k*(n-2) for all the nodes?  After investigating this, I think source nodes and non-source nodes do indeed need to scale differently when `k` is given and `endpoints=False`.  I added a test that exercises this. I don't fully grok the test results, but I trust the scaling logic more than I did.  CC @ChuckHastings @rlratzel 
issue
Use `-n auto` from pytest-xdist for dispatch and coverage CI jobs#TITLE_END#This is mostly just an experiment to try to speed up the two slowest CI jobs. Are there any "gotchas" to be concerned about? Why wouldn't we always enable this option for all pytest runs?  I believe GitHub Action workers currently have 4 cores available https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners#standard-github-hosted-runners-for-public-repositories so let's see if we get roughly 4x performance improvement.
issue
Improve special cases in dispatch testing (paying off tech debt)#TITLE_END#These changes are intended to unblock #7902 (CC @rossbar) and to try to make dispatch tests more maintainable (see #7904).  This actually took _a lot_ of experimentation, and I suspect there's even more debt we could pay off, but I think this is a nice increment. To summarize:  We are more methodological about when we create two different arguments to run with the backend and with networkx. As before, we run with networkx and compare results when the _result_ is a graph. In this case, we check that the output graphs match _exactly_, and return the networkx graph in order to preserve iteration order (b/c some tests are sensitive). We are more careful about doing this when functions _mutate_ input graphs--we now ensure that input graphs are _different_ when calling the function with both the backend and with networkx. @rossbar, I think this is why the latest attempted "fix" for #7902 didn't work--an input graph was mutated, then used in a subsequent call.  This PR _deletes_ a lot of weird, bespoke code that I suspect nobody understands and is likely to be difficult to maintain. This code was originally added so tests would pass. Now we have a different (and less bespoke) way for tests to pass.  This also adds a feature: we compare that input graphs are (very loosely) equal for functions that mutate input graphs. This makes the tests more strict and may affect backends.  Generally, making _any_ changes to this code has a risk of affecting backends. `nx-cugraph` has a few test failures when run against this PR, but I think at least some are true failures.  This code is still more complicated than I would prefer, but we're doing something pretty complex, and I believe enabling backends to run networkx tests is worth the trouble.
issue
Fix `random_degree_sequence_graph` when input is an iterator#TITLE_END#The test `test_random_degree_sequence_large` was passing due to unintended behavior: the two generators `d1` and `d2` were both empty! So, I fixed that test (G2 _was_ empty in that test), and added a regression test for the fix so `random_degree_sequence_graph` works as intended when the degree sequence is an iterator. The docstring says the degree sequence should be a list, which is probably recommended, but we should probably handle iterators and iterables in unsurprising ways too.  @rossbar, I encountered this when trying to unblock #7902.
issue
Add `tournament_matrix` to docs#TITLE_END#Also adding to `__all__`, which doesn't have much of an effect since everything is kept within `tournament` module anyway.  It's a shame to keep such a pretty doc from the world! ![tournament_matrix](https://github.com/user-attachments/assets/356646d6-95ac-4122-9a12-c5b59cc7d039) 
issue
Fix bug when assigning list to `nx.config.backend_priority`#TITLE_END#Thanks @Schefflera-Arboricola for catching and reporting this (here: https://github.com/networkx/networkx/pull/7760#pullrequestreview-2829062783)!
issue
Avoid repeated cache conversion failures for backends#TITLE_END#When playing around with a workflow that uses NetworkX, I saw repeated failures when trying to convert to a backend. This doesn't seem ideal.  This PR saves a value to the cache (if present) to indicate that a conversion failed, which then allows us to avoid attempting this exact conversion in the future.  CC @rlratzel
issue
Faster `square_clustering`#TITLE_END#This implementation is based on my own toiling and experimentation. I don't know if this formulation is published anywhere. I named and described things as best I could, but I suspect it's still somewhat magical. I "discovered" this mostly from brute force and dumb luck--or a little intuition and a lot of perspiration--but it's still a bit mysterious to me. I believe it's solid though! The number of squares and triangles is based on https://arxiv.org/abs/2007.11111 ; the other terms in the denominator are more tricky.  Performance comparison (`*_prev` is original version, `*_new` is new version in this PR): ```python In [1]: import networkx as nx  In [2]: G = nx.gnp_random_graph(5000, 0.001) In [3]: %timeit nx.algorithms.cluster.square_clustering_prev(G) 307 ms Â± 36.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)  In [4]: %timeit nx.algorithms.cluster.square_clustering_new(G) 217 ms Â± 31.4 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)  In [5]: nx.algorithms.cluster.square_clustering_prev(G) == nx.algorithms.cluster.square_clustering_new(G) Out[5]: True  In [6]: G = nx.complete_graph(100)  In [7]: %timeit nx.algorithms.cluster.square_clustering_prev(G) 5.54 s Â± 197 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)  In [8]: %timeit nx.algorithms.cluster.square_clustering_new(G) 60.6 ms Â± 4.69 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each) ``` You can see we get a 90x speedup for the second example with the "massive" hundred node graph. I'm curious how it performs on larger, real-world graphs, which previously took _days_ when I benchmarked and compared to `graphblas_algorithms` (see the chart here: https://github.com/python-graphblas/graphblas-algorithms).  I changed the algorithm somewhat (and added a note) by ignoring self-loops (xref #7261 and #7238), which seems like the reasonable thing to do and matches other clustering algorithms.  We could probably get a factor of 2 or so performance if we cached `set(G.neighbors(v))` and perhaps more if we tried to reuse computation between iterations, but this would use a lot more memory.  CC @hagberg who first implemented `square_clustering` for NetworkX and @marcusjcrook who corrected it a few years ago (just in case y'all are interested in the fun of algorithm design!).
issue
Fix bc scale with k endpoints#TITLE_END#  Fix `betweenness_centrality` rescaling given `k` and `endpoints=False`.    Previously, normalizing could give values above 1:   ```python   >>> nx.betweenness_centrality(nx.star_graph(4), k=1, seed=1, endpoints=False)   {0: 1.25, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}   ```  Odd behavior with rescaling was reported in cugraph by @zmahoor in https://github.com/rapidsai/cugraph/issues/4941  Credit to @ChuckHastings for understanding the issue and identifying correct behavior. Are there any other tests you think should be added?  Note that `betweenness_centrality_subset` and `bipartite.betweenness_centrality` don't have `k`, so they don't have this issue. I haven't considered whether `edge_betweenness_centrality` could have a similar issue.  **Edit:** Summary of fixes: - When k is not None and endpoints is False, scale by (n - 1) instead of n - When k is not None and normalized is False and directed graph   - scale by n / k if endpoints is True   - scale by (n - 1) / k if endpoints is False - Fix edge case when k=n and endpoints is False
issue
Add `edge_attrs="weight"` to `forceatlas2_layout` dispatch decorator#TITLE_END#This is a follow up to #7794 and #7915. The `weight=` parameter wasn't documented when `@nx._dispatchable` was added to FA2, so I/we completely missed its use. Anyway, this change makes sure the edge attribute is preserved if necessary when converting to a different backend.  Also, the default weight is None, not "weight".  CC @nv-rliu @rlratzel 
issue
Dispatch `get_node_attributes` and a few more from `nx.classes.function`#TITLE_END#I think it would be useful to dispatch `{get,set}_{node,edge}_attributes` when using backends such as nx-cugraph and nx-arangodb (CC @aMahanna), and I went ahead and made a few other (but not all) functions from this file dispatchable.
issue
Enable backend-only functions where NetworkX is just an API#TITLE_END#This adds `is_stub` to `_dispatchable` as a quick way to enable backend-only functions. Is there a better name than `is_stub`?  Alternative approaches: - make "networkx" a more proper backend - add e.g. `default_backend=` to `_dispatchable` to encourage other backends or libraries to wrap functions with `@_dispatchable` to use the dispatch machinery  This will let us expose cugraph-only functions such as Leiden or node2vec. CC @rlratzel 
issue
Make `forceatlas2_layout` dispatchable#TITLE_END#This was requested as a dispatchable function: https://github.com/rapidsai/nx-cugraph/issues/63
issue
Update `shortest_path` and `single_target_shortest_path_length` for 3.5#TITLE_END#These have been deprecated and are slated to change in NetworkX 3.5  See: #6527
issue
Add more tests for `nx.lowest_common_ancestor`#TITLE_END#These may be useful to backends that implement this function, since many of the existing tests use other algorithms in `lowest_common_ancestors.py`.  I found all of the new tests helpful.
issue
Fix code formatting of some examples#TITLE_END#Some `Examples` sections in the docs aren't being displayed correctly. These are the ones I was able to catch at a quick glance: - https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.subgraph_centrality_exp.html#networkx.algorithms.centrality.subgraph_centrality_exp - https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.subgraph_centrality.html - https://networkx.org/documentation/latest/reference/generated/networkx.generators.geometric.thresholded_random_geometric_graph.html#networkx.generators.geometric.thresholded_random_geometric_graph - https://networkx.org/documentation/latest/reference/generated/networkx.generators.geometric.soft_random_geometric_graph.html - https://networkx.org/documentation/latest/reference/readwrite/generated/networkx.readwrite.leda.read_leda.html - https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.bipartite.generators.gnmk_random_graph.html#networkx.algorithms.bipartite.generators.gnmk_random_graph
issue
Update `_raise_on_directed` to work with `create_using` pos arg#TITLE_END#This decorator is only used by the "small" graph generators. We could update this to use `argmap`, but probably not worth the effort since all functions have create_using as the first positional argument.  If we were creating these functions today, we might make create_using keyword-only, but that would be a breaking change.  I came across this when running networkx tests with nx-cugraph with networkx 3.4.2. The test added in #7685 was failing for nx-cugraph, because `cubical_graph` isn't supposed to work with directed graphs and we were raising.
issue
Fix docstrings of dispatchable functions#TITLE_END#This may not fix when building the docs; let's experiment!  For backends to show up in docs, we need to load `backend_info` before we decorate functions with `_dispatchable`.  This fixes #7675 and attempts to fix #7677, and is a follow-up to #7672. Let's see if #7671 remains fixed with this PR.  @Schefflera-Arboricola will this work for nx-parallel?
issue
Always cache graph attrs for better backend cache behavior#TITLE_END#This should slightly optimize caching for little cost. It reduces the number of possible cache keys by half. Also, add a few comments for clarity.  @dschult and @rlratzel this is as we discussed today. @rlratzel, this could be superseded by your idea to have the ability to incrementally update cached graphs via new backend APIs (or maybe using existing functions?).
issue
Add config option to disable warning when using cached value#TITLE_END#The warning was updated to show how to use the config setting: ```python nx.config.warnings.discard("cache") ```  Here is a way to ignore this warning using `warnings` module: ```python import warnings  warnings.filterwarnings('ignore', 'Using cached graph', UserWarning, "networkx.utils.backends") ``` There are a lot of options for how to spell and codify this behavior. I'm not sure what would be best, so this PR is an initial proposal. It can also generalize for other warnings if desired.  CC @rlratzel
issue
Fall back to other backends on `NotImplementedError`#TITLE_END#`can_run` and `should_run` may not be able to capture everything, so might as well try the next backend.  This also improves error and log messages to mention possible future behavior, and helps set us up for handling falling back via backend-to-backend conversions. #7496 will let us fall back to networkx before we support backend-to-backend conversions.  CC @rlratzel 
issue
Add `"networkx"` backend for dispatching#TITLE_END#`backend="networkx"` is now valid when calling functions, which will automatically convert backend graphs to networkx graphs.  `"networkx"` may also be given in `nx.config.backend_priority` even though this is kind of silly right now (it's silly b/c it is equivalent to deleting everything to the right of "networkx" and "networkx" from the config). If `"networkx"` is a valid (if still special) backend name, then it's reasonable to support it in `nx.config.backend_priority` and allowing it to be used may be a useful pattern in the future.  I'm not sure whether to include `"networkx"` in `nx.config.backends`.  I also updated some error messages and variable names.  I tested this locally via <details>  ```python import networkx as nx import graphblas_algorithms as ga  G = nx.complete_graph(3) rv1 = nx.pagerank(G, backend="networkx") rv2 = nx.pagerank(G, backend="graphblas") rv3 = nx.pagerank(G) assert rv1 == rv2 == rv3  Ggb = ga.Graph.from_networkx(G) rv4 = nx.pagerank(Ggb, backend="networkx") rv5 = nx.pagerank(Ggb, backend="graphblas") rv6 = nx.pagerank(Ggb) assert rv1 == rv4 == rv5 == rv6  nx.config.backend_priority = ["networkx"] rv4 = nx.pagerank(Ggb, backend="networkx") rv5 = nx.pagerank(Ggb, backend="graphblas") rv6 = nx.pagerank(Ggb) assert rv1 == rv4 == rv5 == rv6 ```  </details>  ~but should probably add a test or two. Oops.~ *Test and doc added.*  CC @rlratzel
issue
Allow dispatch machinery to fall back to networkx#TITLE_END#Allow falling back to NetworkX by converting backend graphs to nx graphs. This is enabled by adding `"networkx"` to `nx.config.backend_priority`.  This PR builds off of #7496, #7499, #7502 (WIP), and #7568. I have done a little bit of refactoring, but I would like to do more refactoring to simplify the code after more PRs are merged. Feel free to review and merge the four other PRs separately, or to review this PR as a whole.  I am working on a notebook that exercises many of the branches and log/error messages, and I bet I/we will continue to refine the messages. Perhaps we could turn this into an example that gets run in CI. Hopefully the log/error messages can help make the dispatch code easier to follow (if one is comfortable reading all that text!).  CC @rlratzel
issue
Ensure we always raise for unknown backend in `backend=`#TITLE_END#Previously, using `backend="foo"` would silently work if there were no backends installed. We should catch e.g. typos sooner.  Note that I originally had this bugfix in #7485, but I think it's cleaner to have a separate PR with a test.
issue
Log "can/should run" and caching in dispatch machinery#TITLE_END#This adds informative logging messages for `can_run` and `should_run` to better understand behaviors of dispatching.
issue
WIP: expand `backend_priority` config to support graph generators#TITLE_END#... and individual functions.  This gives much greater control over how and when to use backends. For example, I could see it being very handy to be able to do something like this: ```python nx.config.backend_priority.algos = ["cugraph", "graphblas"] nx.config.backend_priority.generators = ["pandas"]  # or e.g. "arangodb" nx.config.backend_priority.square_clustering = ["graphblas"] ```  @rlratzel this is largely as we brainstormed last week.  I've really enjoyed playing around with this using storage backend such as `nx-pandas` and a compute backend such as `nx-graphblas`!
issue
Add `Introspection` section to backends docs#TITLE_END#This is mostly aspirational for now, but it shows what's possible today and hopefully illustrates what we want to do.  CC @rlratzel @Schefflera-Arboricola  Let's see what silly Sphinx mistakes I made this time...
issue
Fix installing nx-cugraph in deploy docs CI#TITLE_END#This is a follow-up to #7538 to install pre-release of `nx-cugraph` when building docs.  Failure was noticed https://github.com/networkx/networkx/pull/7498#issuecomment-2221133236.  Since this channel is for nightly wheels, we need `--pre`. It's curious that this worked before.  If connectivity to this repo is too flaky, we could increase the retries/timeout, and/or we could add the channel for regular releases `--extra-index-url https://pypi.nvidia.com nx-cugraph-cu11`.  CC @rlratzel 
issue
Enable caching by default#TITLE_END#Enable cache by default as discussed during the dispatch meeting yesterday.  #7497 is a companion PR that will make caching UX even nicer.  CC @rlratzel 
issue
Enable config to be used as context manager#TITLE_END#Small enhancement to config to allow it to be used with `with ...:`.  CC @rossbar, weren't you interested in using context managers? For example (and CC @Schefflera-Arboricola): ```python with nx.config.backends.parallel(n_jobs=8):     ... ```  Our config uses a simple stack to handle contexts and is unapologetically global. It does not even attempt to work well in multithreaded code via [thread locals](https://docs.python.org/3/library/threading.html#thread-local-data) or async code via [context variables](https://docs.python.org/3/library/contextvars.html) (and trying to support both is non-trivial, so applications should roll their own solutions as necessary). #7345 actually adds a note to the config docs about this: ``` This is a global configuration. Use with caution when using from multiple threads. ```
issue
Fix CI installation of nx-cugraph in docs workflow#TITLE_END#Fixes #7536 temporarily by pinning nx-cugraph to a specific commit.  @rlratzel and I will need to investigate how to fix this in a more permanent way.
issue
Fix dispatch tests when using numpy 2#TITLE_END#Fixes #7505 (hopefully ðŸ¤ž).  Thanks @Schefflera-Arboricola for raising this issue! I just took a guess at a solution.
issue
Fix `from_pandas_edgelist` for MultiGraph given edge_key#TITLE_END#In `from_pandas_edgelist`, multigraphs are not correctly supported. Previously, `edge_key=` was not used if `edge_attr` was None! This adds code to handle the `edge_key` parameter even when no `edge_attr` are requested.
issue
Fix exception for `del config[key]`#TITLE_END#Also, make `cfg.__setitem__` (a little) faster.  I forgot to update `__delitem__` when I enabled `strict=False` option for configs.
issue
Add dispatching to broadcasting.py#TITLE_END#I reviewed all changes since https://github.com/networkx/networkx/pull/7302 to look for updates to make for the dispatch decorator. My goal is to do this kind of check before each new release.
issue
ENH: Cache graphs objects when converting to a backend#TITLE_END#This builds off of #7344.  Caching backend graph conversions can provide a huge performance (and usability) benefit to users. It comes at the cost of increased memory, so it would be nice to be able to control caching via config (#7225).  CC @rlratzel
issue
Minimal PR to add cache dict to graphs and clear them#TITLE_END#An even simpler start to caching than #7283, this PR creates a `__networkx_cache__` dict on graph objects and clears them when appropriate.  This takes a conservative approach to clear the cache in functions and methods whenever any graph data changes.  I'm pretty confident that all graph methods and dispatched functions clear the cache appropriately. There may be some non-dispatched functions that mutate the graph that aren't captured here.  This PR is minimal in that it doesn't do anything with the cache. By creating the cache, though, backends, users, and specific functions may begin experimenting with using the cache.
issue
Make `is_negatively_weighted` dispatchable#TITLE_END#This function may be useful for backends (and _is_ useful for `nx-cugraph`).  We may want to dispatch more functions in `nx.classes.function` after version 3.3 is released. `is_negatively_weighted` and other functions in this file are often plenty fast with the NetworkX implementation, but I think making these dispatchable becomes much more feasible and desirable once we have `should_run` (already in) and caching (coming soon ðŸ¤ž).  CC @rlratzel
issue
Fix pydot tests when testing backends#TITLE_END#This at least partially addresses the errors in #7354. In particular, this fixes the pydot errors.  I don't know how to fix the `agraph` segfaults you see in #7354 @rossbar. You can work around them by removing `pygraphviz` from your environment.  Also, I don't think `pytest-xdist` has anything to do with these errors, but I like the idea of running the dispatch tests with `pytest-xdist` if it makes them faster.
issue
Add `nx.config` dict for configuring dispatching and backends#TITLE_END#This adds a global config dict for dispatching and backends. Is this what we discussed in the last networkx dispatching meeting? It allows backends to provide default configuration in `"default_config"` in the dict returned by `networkx.backend_info` entry-point. It saves this object to `nx.backend_config[backend_name]`. This config is initialized using environment variables if they are defined.  I think we should consider the fields of this config and whether we like the names, because this is now becoming public. Do we like `fallback_to_nx: bool` and `automatic_backends: list`?  Also, how should we document this? Should we subclass `dict` just to provide a docstring, such as: ```python class BackendConfigDict(dict):     """blah blah blah""" ```  CC @MridulS @rlratzel @Schefflera-Arboricola @jim22k
issue
Fix #7339. `shortest_path` inconsisitent with warning#TITLE_END#The warning says the return type will change from dict to iterator in version 3.5. This PR changes the return type to dict, since we are not yet on version 3.5.  Please see #7339 for details. I think this will make main branch consistent and resolve the inconsistencies introduced in #6584 and #7161.
issue
Inconsistent `shortest_path` warning and return type on main#TITLE_END#  ### Current Behavior  #7161 updated the warning for `shortest_path` to indicate the return type (from dict to iterator) will occur in NetworkX 3.5.  #6584 changed the return type from dict to iterator, but #7161 didn't change the return type back to dict.  ### Expected Behavior  I expect `shortest_path` with no source or target to return an iterator over node, path pairs on main branch to be consistent with the warning.  ### Steps to Reproduce  ``` >>> import networkx as nx >>> assert isinstance(nx.shortest_path(nx.complete_graph(4)), dict)  # raises AssertionError ```  ### Environment  Python version: 3.10 NetworkX version: main branch  ### Additional context  This is similar to issue #7315. I haven't fully compared #6584, #7161, and main branch to ensure consistency.
issue
Add eriknw as contributor#TITLE_END#'cause I've made a couple small commits ;)  https://github.com/networkx/networkx/commits?author=eriknw
issue
`single_target_shortest_path_length` on main returns dict, not iterator#TITLE_END#There seem to be inconsistencies introduced in #6584 and #7161. For example, for `single_target_shortest_path_length`, the warning says that it will return dict (not iterator) starting in version 3.5, but it returns a dict _today_.
issue
`strategy_saturation_largest_first` endless generator#TITLE_END#<!-- If you have a general question about NetworkX, please use the discussions tab to create a new discussion -->  <!--- Provide a general summary of the issue in the Title above -->  ### Current Behavior  `strategy_saturation_largest_first` generator does not terminate. See the stopping condition here: https://github.com/networkx/networkx/blob/9cc8b422a512e7e7819238d597fd6815ec9c1c8e/networkx/algorithms/coloring/greedy_coloring.py#L243  but neither `G` nor `colors` is updated within the loop! The result is the same `node` is yielded repeatedly.  ### Expected Behavior  I would expect the generator to terminate. I don't grok this function, but endless generator doesn't seem right.  ### Steps to Reproduce  ```python import networkx as nx  G = nx.empty_graph() G.add_node(1) list(nx.algorithms.coloring.greedy_coloring.strategy_saturation_largest_first(G, {})) ```  ### Environment  Python version: 3.10 NetworkX version: dev  ### Additional context  I (of course) encountered this while tinkering with dispatching machinery!
issue
Allow backends to implement `should_run`#TITLE_END#As discussed in the weekly dispatching call (and first proposed by @rlratzel I believe), this PR adds `should_run` that is like `can_run`, but answers whether the backend _should_ be called (converting if necessary).  Right now, this only applies to when networkx graphs would be converted to backend graphs before running the networkx algorithm, so it would be accurate to call it `should_convert_and_run`, but that's wordy, and we'll probably add more sophisticated things soon such as caching and backend-to-backend conversions, so `should_run` is more generically accurate and useful.  `should_run` does not get used... - when testing backends - when `backend=...` is given - when an input graph is a backend graph
issue
Avoid creating results with numpy scalars (re: NEP 51)#TITLE_END#NEP 51 coming in NumPy 2..0 changes the repr of numpy scalar, and this helps reveal usage of numpy scalars where Python scalars ought to be used. This PR aims to allow the workaround in #6856 to be reverted.  This uses dispatching machinery to perform rigorous inspection of return values. Hence, the blind spots are functions that are not dispatchable. We probably shouldn't keep this code when we merge. Should we look into a more flexible callback machinery to allow this check (and other checks) to be optionally done? Inspecting return values has proven quite useful.
issue
Add explicit targets of missing modules for intersphinx#TITLE_END#This covers all the missing modules that I could find. `sphinxobjinv` is a useful tool: - https://sphobjinv.readthedocs.io/en/stable/  For starters, it can convert the binary `objects.inv` into text: ```bash $ sphobjinv convert plain objects.inv objects.txt ``` Closes #7278. This is a simple solution, but I don't know if better solutions exist. At the very least, this PR shows what's missing. This may look like a lot of changes, but the vast majority of modules already have targets.
issue
Intersphinx objects missing references to submodules of centrality and component#TITLE_END#### Current Behavior  Intersphinx is missing names for submodules of `networkx.algorithms.centrality` and `networkx.algorithms.component`. For example, it doesn't know how to map the modules: ``` networkx.algorithms.centrality.betweenness (see: algorithms/centrality.html#shortest-path-betweenness) networkx.algorithms.centrality.degree_alg (see: algorithms/centrality.html#degree) networkx.algorithms.centrality.eigenvector (see: algorithms/centrality.html#eigenvector) networkx.algorithms.centrality.katz (see: algorithms/centrality.html#eigenvector) networkx.algorithms.components.connected (see: algorithms/component.html#connectivity) networkx.algorithms.components.weakly_connected (see: algorithms/component.html#weak-connectivity) ```  ### Expected Behavior  I expect `objects.inv` to be able to map e.g. `networkx.algorithms.centrality.betweenness` _or_ `reference/algorithms/centrality/betweenness` _or maybe_ `reference/algorithms/centrality.betweenness` (or whatever) to the appropriate place in the documentation. For another example, _no_ object name contains `degrees_alg`, which is a module in NetworkX.  ### Steps to Reproduce  Intersphinx knowledge ;)  ### Environment  No environment, this is from the webpage bruh!  Python version: wat? NetworkX version: 3.2.1 and latest dev  ### Additional context  I'm making docs for a backend automatically link back to the appropriate NetworkX doc, so we want to use Intersphinx data. Here's an example:  <pre> <a href="https://networkx.org/documentation/latest/reference/algorithms/bipartite.html#module-networkx.algorithms.bipartite">bipartite</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/bipartite.html#module-networkx.algorithms.bipartite.basic">basic</a>  â”‚   â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.bipartite.basic.is_bipartite.html#networkx.algorithms.bipartite.basic.is_bipartite">is_bipartite</a>  â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/bipartite.html#module-networkx.algorithms.bipartite.generators">generators</a>      â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.bipartite.generators.complete_bipartite_graph.html#networkx.algorithms.bipartite.generators.complete_bipartite_graph">complete_bipartite_graph</a> <a href="https://networkx.org/documentation/latest/reference/algorithms/centrality.html#module-networkx.algorithms.centrality">centrality</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/centrality.html#shortest-path-betweenness">betweenness</a>  â”‚   â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html#networkx.algorithms.centrality.betweenness_centrality">betweenness_centrality</a>  â”‚   â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.edge_betweenness_centrality.html#networkx.algorithms.centrality.edge_betweenness_centrality">edge_betweenness_centrality</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/centrality.html#degree">degree_alg</a>  â”‚   â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html#networkx.algorithms.centrality.degree_centrality">degree_centrality</a>  â”‚   â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.in_degree_centrality.html#networkx.algorithms.centrality.in_degree_centrality">in_degree_centrality</a>  â”‚   â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.out_degree_centrality.html#networkx.algorithms.centrality.out_degree_centrality">out_degree_centrality</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/centrality.html#eigenvector">eigenvector</a>  â”‚   â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.eigenvector_centrality.html#networkx.algorithms.centrality.eigenvector_centrality">eigenvector_centrality</a>  â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/centrality.html#eigenvector">katz</a>      â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.centrality.katz_centrality.html#networkx.algorithms.centrality.katz_centrality">katz_centrality</a> <a href="https://networkx.org/documentation/latest/reference/algorithms/clustering.html#module-networkx.algorithms.cluster">cluster</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.cluster.average_clustering.html#networkx.algorithms.cluster.average_clustering">average_clustering</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html#networkx.algorithms.cluster.clustering">clustering</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.cluster.transitivity.html#networkx.algorithms.cluster.transitivity">transitivity</a>  â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.cluster.triangles.html#networkx.algorithms.cluster.triangles">triangles</a> <a href="https://networkx.org/documentation/latest/reference/algorithms/community.html#module-networkx.algorithms.community">community</a>  â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/community.html#module-networkx.algorithms.community.louvain">louvain</a>      â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html#networkx.algorithms.community.louvain.louvain_communities">louvain_communities</a> <a href="https://networkx.org/documentation/latest/reference/algorithms/component.html#module-networkx.algorithms.components">components</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/component.html#connectivity">connected</a>  â”‚   â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.connected_components.html#networkx.algorithms.components.connected_components">connected_components</a>  â”‚   â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.is_connected.html#networkx.algorithms.components.is_connected">is_connected</a>  â”‚   â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.node_connected_component.html#networkx.algorithms.components.node_connected_component">node_connected_component</a>  â”‚   â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.number_connected_components.html#networkx.algorithms.components.number_connected_components">number_connected_components</a>  â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/component.html#weak-connectivity">weakly_connected</a>      â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.is_weakly_connected.html#networkx.algorithms.components.is_weakly_connected">is_weakly_connected</a>      â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.number_weakly_connected_components.html#networkx.algorithms.components.number_weakly_connected_components">number_weakly_connected_components</a>      â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.components.weakly_connected_components.html#networkx.algorithms.components.weakly_connected_components">weakly_connected_components</a> <a href="https://networkx.org/documentation/latest/reference/algorithms/core.html#module-networkx.algorithms.core">core</a>  â”œâ”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number">core_number</a>  â””â”€ <a href="https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.core.k_truss.html#networkx.algorithms.core.k_truss">k_truss</a> </pre>  I'm pretty terrible at non-trivial Sphinx things, but maybe `centrality.rst` and `component.rst` ought to define `automodule` in subsections.
issue
Add `mutates_input=` and `returns_graph=` to `_dispatchable`#TITLE_END#Knowing which functions mutate input graphs may be helpful when implementing (or testing) caching.  This changes a behavior: if a function is known to mutate an input graph, then this _does not_ automatically convert an input graph to a backend graph. Conversion can still happen by using `backend=` keyword.  _Some_ of the algorithms that now have `mutates_input=True` may be good candidates to add `copy=` arguments.  Adding `mutates_input=` to dispatch decorator is "best effort". It's possible (even likely) that some were missed, especially functions that add data to `.graph`. I think this is okay--we can fix them when found by backend implementers--but please share if you know of any other functions that mutate input graphs.  I noticed that `negative_edge_cycle` and `held_karp_ascent` _temporarily_ mutate input graphs. I was surprised by this, and it means these are not thread-safe (and who knows if they may be permanently modified if there's an exception).  I also noticed that `lukes_partitioning`, `is_kl_connected`, and `kl_connected_subgraph` use `deepcopy` to copy the graph before mutating it. This is different than what is done elsewhere, and does not work if the input graphs have been frozen (side thought: why isn't there an `unfreeze` function?).  `reverse` function has `copy=` argument, but it does not mutate the graph. If `copy=False`, then a read-only view is returned.  Finally, I don't know what to do with `minimum_cut`. It can mutate `residual` if `residual=` was passed in via `**kwargs`. The dispatch machinery does not handle graphs passed in via `**kwargs`. We can punt on this until a backend wants to implement it.  CC @rlratzel
issue
Have dispatched functions appear as normal Python functions when type-checking#TITLE_END#This is an effort to make type-checkers happy. Without this, dispatch functions are of type `_dispatch`, which may complicate typing.  For now, the attributes, methods, and type of `_dispatch` objects are implementation details and may be treated as regular Python functions, which this PR makes explicit.
issue
Transmogrify `_dispatchable` objects into functions#TITLE_END#`_dispatchable` objects don't look good in REPRs and they make it really awkward for type checkers. This PR uses `argmap` to transmogrify `_dispatchable` objects into functions. I hope to someday understand `argmap`.  @rossbar, this is as discussed in #7185 and the meeting today. Everything looks good in REPRs to me. This PR supercedes #7185.  CC @rlratzel
issue
Review and update `@nx._dispatchable` usage since 3.2.1#TITLE_END#This adds (and updates) `@nx._dispatchable` decorator to some new functions. I reviewed the diff since version 3.2.1.  There are now three algorithms I know that implicitly use `"weight"` weight (no `weight` argument): `hits`, `tournament_matrix`, and `is_regular_expander`.  The only other functional change I made in this PR is to add `seed` to `random_regular_expander_graph`.
issue
Add `max_level=` argument to `louvain_communities` to limit macro-iterations#TITLE_END#Louvain in cugraph allows `max_level` to be specified, which sets the upper limit of "macro iterations" of the Louvain algorithms (and other algorithms such as Leiden), so I thought it would be nice to upstream back to networkx.  Also, I changed the variable name of the iterator from `d` to `it`. `d` sounds like a dict to me.  TODO: - [x] add to docstring  CC @rlratzel
issue
Docstring of `nonisomorphic_trees` should use `Yields`, not `Returns`#TITLE_END#In NetworkX 3.2.1, `nonisomorphic_trees` yields graphs or adjacency matrices, so the docstring should use a `Yields` section, but it uses `Returns`.
issue
Return type of `general_k_edge_subgraphs` is incorrect in docstring#TITLE_END#In networkx 3.2.1, `general_k_edge_subgraphs` return type in docstring says this: ```     k_edge_subgraphs : a generator of nx.Graphs that are k-edge-subgraphs         Each k-edge-subgraph is a maximal set of nodes that defines a subgraph         of G that is k-edge-connected. ``` However, it actually _yields_ (not returns) _graphs_, not sets of nodes.
issue
Rename `_dispatch` to `_dispatchable`#TITLE_END#How do people like the name `_dispatchable`? Once there is better documentation for it (for users, backend developers, and networkx developers), then I think we should consider changing the name one last time to `dispatchable`.
issue
Fix warnings when building docs#TITLE_END#I found these when working on #7194
issue
Remove `"networkx.plugins"` and `"networkx.plugin_info"` entry-points#TITLE_END#Use `"networkx.backends"` and `"networkx.backend_info"` instead. Version 3.2 supports both options. The next release can drop "plugin".  I forgot to do this in #7157, which made a similar change.
issue
Fix online docs for `_dispatch`#TITLE_END#I had to move the class docstring to the docstring of the `__new__` method, because we define `__doc__` property later in the class.
issue
Remove usage of `__networkx_plugin__` (use `__networkx_backend__` instead)#TITLE_END#Backends should have had enough time to update by now.
issue
Compare graphs for generator functions when running tests with backend#TITLE_END#This is an alternative to #7063 and is much more general.  The backend testing infrastructure can call backend graph generator functions such as `circular_ladder_graph`, and it converts the backend Graph to a networkx Graph. This is a great way to test backend generators! However, sometimes iteration order is different when using the converted backend graph. So, our solution here is to *also* call the original networkx function when the return type is a Graph, compare results, then use the result from networkx to allow tests to pass. We use a series of assertions to help backend implementers identify differences.
issue
Be forgiving of iteration order in `test_write_network_text_circular_ladder_graph`#TITLE_END#This is helpful for backends that implement `circular_ladder_graph`. Currently, the backend testing infrastructure in NetworkX can call backend graph generators such as `circular_ladder_graph`, and it converts the backend Graph to a networkx Graph. This is a great way to test backend generators, but sometimes iteration order is different.  Alternatively, the testing infrastructure could call *both* the original generator and the backend generator, check that the graphs are equal, then use the original graph. This approach would avoid other test failures that result from difference in iteration order.
issue
Make HITS raise exceptions consistent with power iterations#TITLE_END#Specifically, instead of raising `ValueError` or `sp.sparse.linalg.ArpackNoConvergence`, change `nx.hits` to raise `nx.PowerIterationFailedConvergence` just like other algorithms that have power iterations. This makes it easier for backends to raise consistent exceptions (`ArpackNoConvergence` is particularly awkward to match).
issue
Update dispatch decorator for `hits` to use `"weight"` edge weight#TITLE_END#`"weight"` edge weight is currently fixed.
issue
Fix annoying split strings on same line#TITLE_END#I keep seeing these, and I've behaved myself the last couple months by not doing pushing a silly formatting PR, but I'm annoyed by these so here you go.  Ideally a linter would automatically fix these.
issue
Add `@not_implemented_for("directed")` to `number_connected_components`#TITLE_END#Previously, it was relying on a call to `connected_components` to check the graph type, but this doesn't work well when dispatching to a backend. Also, fix an exception message.
issue
Disallow negative number of nodes in `complete_multipartite_graph`#TITLE_END#I doubt the current behavior with negative integer inputs to `complete_multipartite_graph` is intended or used anywhere, so let's raise instead.  Adding this check makes my life (and the job of other backend developers) easier, b/c I don't want to reproduce this behavior, nor do I want to handle this as a special case in my otherwise nice test fixture.
issue
Fix names of small graphs#TITLE_END#I noticed the  names of these small graphs aren't like all the other small graph names--one is a tuple, and one uses "graph" instead of "Graph".
issue
Fix error message for `nx.mycielski_graph(0)`#TITLE_END#There was an "off-by-one" error.
issue
pip install nx-cugraph from git, not nightly wheels, for docs#TITLE_END#This should be more reliable.  CC @rlratzel
issue
Add GraphBLAS backend to online docs#TITLE_END#Making a PR is the easiest way to see if this works :)  I would still like to make a few changes to the networkx docs for graphblas backend. We can also release `graphblas-algorithms` so we don't need to install from git.
issue
Prefer "backend" instead of "plugin"#TITLE_END#CC @rlratzel, who recently raised the issue of using the term "backend" instead of "plugin".  I think it's reasonable to have a release where we support both "plugin" and "backend" to give backends the most flexibility (we use "plugin" as the attribute we look at and the entry point names).
issue
Allow graph generators and conversion functions to be dispatched#TITLE_END#For now, the `backend` argument *must* be used to dispatch to a backend. Global config for automatic conversions to backends *does not* work on graph generators, readers, converters, or any function that does not have any graph inputs. For example: ```python G = nx.from_pandas_edgelist(df, backend="cugraph") ``` However, the backend function _will_ be used when testing with a backend. The backend graph will be converted to a networkx graph automatically in `_convert_and_call_for_tests`.  This follows up on #6840.  CC @aaronzo @MridulS @jim22k @rlratzel 
issue
Add "networkx.plugin_info" entry point and update docstring#TITLE_END#We use a new entry point so it can be imported really fast by not needing to import the backend.  Companion PR for `nx-cugraph` is here: https://github.com/rapidsai/cugraph/pull/3848  Needs documented, discussed, etc. I don't know how well the updated docstrings look like yet or how well they will render online.  CC @rlratzel @betochimas
issue
Fix sphinx docs rendering of dispatched functions#TITLE_END#@MridulS noticed the online docs no longer render properly for dispatched functions now that `_dispatch` is a class: https://github.com/networkx/networkx/pull/6840#issuecomment-1700779731  I'm not a Sphinx expert, but here is one way to fix the problem. It also allows the dispatch machinery to update the docstring. The signature of dispatched functions is unchanged in the online docs--that is, `backend=None, **backend_kwargs` is not shown.
issue
Change `_dispatch` to a class instead of a closure#TITLE_END#This PR supersedes #6828 and #6829, and it implements one of the "future" items from #6804: - change `_dispatch` to be a class instead of a closure - fallback to original networkx function when testing if `fallback_to_nx` is set when backend raises `NotImplementedError` (also done in #6828) - don't dispatch to backend when testing until tests are set up (also done in #6828) - add `--backend=whatever` option to `pytest` to choose backend w/o environment variable (also done in #6829) - add `--fallback-to-nx` option to `pytest` to run test with networkx graph is backend does not implement it - rename `NETWORKX_GRAPH_CONVERT` environment variable to `NETWORKX_TEST_BACKEND` - rename `NETWORKX_BACKEND_TEST_EXHAUSTIVE` environment variable to `NETWORKX_FALLBACK_TO_NX` - add `**backend_kwargs` to signature to allow backends to have additional keyword arguments - ~add `is_testing=` argument to `convert_from_nx`, which I would find useful for my plugins~ (removed) - add `_dispatch._convert_and_call` method, which gets us one step closer to automatic conversions - Newly added on 2023-08-18:   - `NETWORKX_AUTOMATIC_BACKENDS` to enable automatic conversions to backends   - add `backend=` keyword-only parameter to allow the backend to be explicitly chosen at call-time   - add `_can_backend_run` and `_convert_arguments` methods to `_dispatch`; should we make these public?  The backend can still be indicated with `NETWORKX_TEST_BACKEND` environment variable, which allows us to run networkx tests with backends when networkx is installed in site-packages (b/c `pytest --backend` doesn't work in this case).  The testing environment variables are only handled when `pytest` is invoked. Previously, we checked the environment variables at import time. This is one reason I thought it appropriate to change the names of the environment variables.  Behavior of dispatching (such as changing plugin name) can be easily modified at any time by changing class attributes on `_dispatch`.  I exposed a lot of attributes of `_dispatch` objects. I would appreciate scrutiny on choice of names. We can make some/most of these private if people prefer. Keep in mind that we will likely add more attributes and methods later when we add e.g. configuration, discovering and choosing backends, etc. Having `_dispatch` as a class sets us up for more future goodness.  I have not measured performance impact of these changes. If it's significant, an easy optimization would be to compute `__signature__` on demand when needed.  Unlike #6828 and #6829, this PR has a lot more to review--sorry! I figure it would be better to make breaking changes before 3.2 is released if at all possible.  CC @jim22k @aaronzo
issue
Move random_state decorators before `@nx._dispatch`#TITLE_END#When I first tried to have `@py_random_state` and `@np_random_state` come before `@nx._dispatch` in #6688, I encountered an error. I don't recall what, but @dschult expected it to "just work" and was surprised there was an error (and it's possible I did something wrong). Anyway, I thought I would check to see if this would work now after #6840... and it does!
issue
Improve testing of backends: let tests get setup up, and fallback#TITLE_END#We add `is_pytest_running()` that is True once tests begin running to allow NetworkX to set up it's own tests. Otherwise, some functions go through dispatching before tests are run, which requires backends to implement them, and then the resulting graphs are the backend graph and not networkx graphs.  Also, allow algorithms to raise `NotImplementedError` to allow incremental implementation by backends. When testing, this will fallback to running the original networkx algorithm if `NETWORKX_BACKEND_TEST_EXHAUSTIVE` environment variable is set, or else the test will xfail.  This is to help with both `graphblas_algorithms` and `cugraph_nx` backends.
issue
Add @nx._dispatch to {single_source,all_pairs}_all_shortest_paths, cd_index#TITLE_END#These are the new functions that I know about that didn't yet dispatch.
issue
Relax threshold in test of `betweenness_centrality`#TITLE_END#This allows backends such as `cugraph_nx` to implement `betweenness_centrality` with float32.
issue
Functions with assumed edge or node attributes#TITLE_END#<!-- If you have a general question about NetworkX, please use the discussions tab to create a new discussion -->  <!--- Provide a general summary of the issue in the Title above -->  ### Current Behavior  As part of #6688, I believe I found a few functions that assume specific attributes for edges or nodes, which means they don't provide a way to specify a different attribute to use.  These functions assume an edge attribute `"weight"` with a default value of 1: - [x] `second_order_centrality` - [x] `quotient_graph` - [x] `panther_similarity` - [x] `generate_random_paths` - [x] `number_of_walks`  And this functions assumes a node attribute `"pos"`: - [x] `geometric_edges`  ### Expected Behavior  I expect these functions to follow the networkx convention of allowing users to specify which attribute to use (such as having `weight="weight"` argument).  ### Steps to Reproduce  Use the above functions with and w/o the assumed attributes.  ### Environment  <!--- Please provide details about your local environment -->  NetworkX version: main branch (as of 2023-06-20)  ### Additional context  There could be more functions with assumed attributes that I didn't find. Also, I didn't include "flow" algorithms, which often assume `"capacity"`, `"flow"`, or `"id"` attributes in the auxiliary or residual graphs.  We can check-mark functions above as their API are updated to include attribute name.
issue
Add `@nx._dispatch` decorator to most algorithms#TITLE_END#This adds dispatching to most algorithms (only functions in `algorithms`, `generators`, and `linalg`). This raises a few questions that we need to solve or postpone. I will raise these questions below.  CC @jim22k @MridulS
issue
Docstring of `intersection_all` incorrect (graph attrs are copied)#TITLE_END#<!-- If you have a general question about NetworkX, please use the discussions tab to create a new discussion -->  <!--- Provide a general summary of the issue in the Title above -->  ### Current Behavior  Currently, `intersection_all` copies the `.graph` attributes to the result, and attributes from the later graphs have higher precedense. However, the docstring says: ``` Attributes from the graph, nodes, and edges are not copied to the new graph. ``` ### Expected Behavior  For the docstring to match behavior or behavior to match docstring.  ### Steps to Reproduce  ```python In [1]: import networkx as nx  In [2]: G = nx.Graph()  In [3]: H = nx.Graph()  In [4]: G.graph[1] = 1  In [5]: G.graph[2] = 2  In [6]: H.graph[2] = 20  In [7]: H.graph[3] = 30  In [8]: R = nx.intersection_all([G, H])  In [9]: R.graph Out[9]: {1: 1, 2: 20, 3: 30} ```  ### Environment  Python version: 3.11 NetworkX version: 3.1
issue
Docstring of `johnson` algorithm handling of weight incorrect#TITLE_END#<!-- If you have a general question about NetworkX, please use the discussions tab to create a new discussion -->  <!--- Provide a general summary of the issue in the Title above -->  ### Current Behavior  The documentation says: ``` If no such edge attribute exists, the weight of the edge is assumed to be one. ``` ### Expected Behavior  The behavior to match the docstring or the docstring to match the behavior.  ### Steps to Reproduce  ```python In [1]: import networkx as nx  In [2]: G = nx.Graph()  In [3]: G.add_edge(0, 1, weight=2)  In [4]: G.add_edge(0, 2)  In [5]: nx.johnson(G) --------------------------------------------------------------------------- NetworkXError                             Traceback (most recent call last) Cell In[5], line 1 ----> 1 nx.johnson(G)  File ~/miniconda3/envs/gb8/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/weighted.py:2469, in johnson(G, weight)    2402 r"""Uses Johnson's Algorithm to compute shortest paths.    2403    2404 Johnson's Algorithm finds a shortest path between each pair of    (...)    2466    2467 """    2468 if not nx.is_weighted(G, weight=weight): -> 2469     raise nx.NetworkXError("Graph is not weighted.")    2471 dist = {v: 0 for v in G}    2472 pred = {v: [] for v in G}  NetworkXError: Graph is not weighted. ```  ### Environment  <!--- Please provide details about your local environment -->  Python version: 3.11 NetworkX version: 3.1  ### Additional context  It uses `nx.is_weighted`, which requires that _all_ edges have the attribute to be considered weighted.
issue
Handle weights as `distance=` in testing dispatch#TITLE_END#This handles `ego_graph`, which I just implemented in `graphblas-algorithms` here: https://github.com/python-graphblas/graphblas-algorithms/pull/61  This `dispatch` function is only used when testing, and it automatically converts graph inputs to the backend specified in an environment variable (it also converts Graph outputs back to networkx graphs). To convert correctly, it needs to know which weight to use for each algorithm. To date, this has worked fairly well by using a small set of rules. As done in this PR, these rules will likely need to be updated as more and more algorithms support dispatch. Some thoughts: - Perhaps we don't need to do this; instead, can we rely on every backend to properly handle networkx Graphs as inputs? - Or, instead, perhaps we add e.g. `weight_argument="distance"` to the `@dispatch` decorator to indicate which argument should be used as the weight argument. Sooner or later, we probably ought to make `@dispatch` return an instance of a class instead of relying on closures.  CC @jim22k @MridulS 
issue
Remove an instance of random.sample from a set (deprecated in Python 3.9)#TITLE_END#I encountered this DeprecationWarning today. This change was missed in #4602  <!-- Please run black to format your code. See https://networkx.org/documentation/latest/developer/contribute.html for details. --> 
issue
Update release_3.0 authors (add Jim and Erik)#TITLE_END#@jim22k and I both contributed code via #6000. I'm guessing squash merges hid our contributions.
issue
Add dispatching to more shortest path algorithms#TITLE_END#We've added Floyd-Warshall algorithms to `graphblas-algorithms`, and Bellman-Ford and some other shortest path algorithms are next.
issue
tweak `test_override_dispatch` to allow G keyword#TITLE_END#This is a simple follow-up to #6471, and, as in that PR, this fix is short term. We would like to find a more elegant, robust solution (probably after nx 3.1).  I sometimes forget there are two versions of `_dispatch`, and this PR fixes the one that gets used when `NETWORKX_GRAPH_CONVERT` environment variable is set. NetworkX does not yet test `test_override_dispatch`, so it's not easy to add a test, but it gets used by external backends such as `graphblas_algorithms`. Ideally, we should test this in NetworkX, which will require calling subprocess in a test with an environment variable set.  CC @MridulS @jim22k 
issue
Dispatch more BFS-based algorithms#TITLE_END#I've already implemented the majority of these in `graphblas_algorithms` and hope to implement the rest soon.
issue
Ignore weakrefs when testing for memory leak#TITLE_END#I started to encounter an error with this when testing `graphblas_algorithms`, b/c it was trying to operate on weakly-reference objects that no longer exist. I have no other context about this, but this change seems "safe" to me.
issue
`negative_edge_cycle` unexpectedly raises for empty graph input#TITLE_END#<!-- If you have a general question about NetworkX, please use the discussions tab to create a new discussion -->  <!--- Provide a general summary of the issue in the Title above -->  ### Current Behavior  ```python-traceback >>> import networkx as nx >>> G = nx.Graph() >>> nx.negative_edge_cycle(G) Traceback (most recent call last):   File "/home/erik/graphblas_workspace/networkx/networkx/algorithms/shortest_paths/weighted.py", line 2138, in negative_edge_cycle     bellman_ford_predecessor_and_distance(   File "/home/erik/graphblas_workspace/networkx/networkx/classes/backends.py", line 143, in wrapper     return func(*args, **kwds)   File "/home/erik/graphblas_workspace/networkx/networkx/algorithms/shortest_paths/weighted.py", line 1221, in bellman_ford_predecessor_and_distance     raise nx.NodeNotFound(f"Node {source} is not found in the graph") networkx.exception.NodeNotFound: Node -1 is not found in the graph  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File "/home/erik/graphblas_workspace/networkx/networkx/classes/graph.py", line 672, in remove_node     nbrs = list(adj[n])  # list handles self-loops (allows mutation) KeyError: -1  The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File "<stdin>", line 1, in <module>   File "/home/erik/graphblas_workspace/networkx/networkx/classes/backends.py", line 143, in wrapper     return func(*args, **kwds)   File "/home/erik/graphblas_workspace/networkx/networkx/algorithms/shortest_paths/weighted.py", line 2144, in negative_edge_cycle     G.remove_node(newnode)   File "/home/erik/graphblas_workspace/networkx/networkx/classes/graph.py", line 675, in remove_node     raise NetworkXError(f"The node {n} is not in the graph.") from err networkx.exception.NetworkXError: The node -1 is not in the graph. ```  ### Expected Behavior ```python >>> import networkx as nx >>> G = nx.Graph() >>> nx.negative_edge_cycle(G) False ```  ### Steps to Reproduce  See above.  ### Environment  Python version: 3.10.9 NetworkX version: main branch ``` commit 4a6f2f43508d26d0eb9884a24cba28721d5fb875 (HEAD -> main, origin/main, origin/HEAD) Author: Ross Barnowski <rossbar@berkeley.edu> Date:   Thu Mar 2 06:40:41 2023 -0800 ``` ### Additional context  Dispatching coming soon... ðŸ˜‰ 
issue
More tests for clustering (upstreaming from graphblas-algorithms)#TITLE_END#These improve coverage of `graphblas-algorithms`.  CC @MridulS   Also, some floating point comparisons were relaxed to use `np.testing.assert_allclose`, which are needed for https://github.com/python-graphblas/graphblas-algorithms/pull/11.  I take a narrow approach with this: I only relax the comparisons needed to allow `graphblas-algorithms` to pass tests.  (btw, I found that a few tests fail when `pytest-randomly` is installed, which runs tests randomly)
comment
> One problem is that 3.2 now introduced a new code pattern that makes type annotating much more verbose and complicated [python/typeshed#10544 (comment)](https://github.com/python/typeshed/pull/10544#issuecomment-1776036652)  I created #7185 as a possible way to address this to allow typeshed to continue using standard Python function definitions. Is there an easy way (such as with a decorator) in typeshed to add types for function attributes?  Does anybody here want to learn what `_dispatch` is all about?
comment
> There is one signicant downside though to not having inline annotations at all. You cannot do this: >  > ```python > g = nx.Graph[str]() > ``` To support that syntax, the `Graph` class only needs to define `__class_getitem__` method. Inline annotations is irrelevant. Declaring a graph with a node type in this way seems reasonable to me at first glance.
comment
> I am also interested in learning about _dispatch.  Great! `_dispatch` is related to a new, experimental feature in NetworkX that allows for additional backend implementations of graph data structures and algorithms. It is strictly opt-in for now. This is meant to address one of the biggest pain points of NetworkX users: performance! The goal is to make it easy for users to accelerate and scale their code if NetworkX is too slow.  I know of three NetworkX backends that are being worked on: - `nx-cugraph`: run super-fast on GPU   - https://github.com/rapidsai/cugraph/tree/branch-24.02/python/nx-cugraph - `graphblas-algorithms`: run in parallel on the CPU with OpenMP   - https://github.com/python-graphblas/graphblas-algorithms - `nx-parallel`: https://github.com/networkx/nx-parallel (in progress)  The cuGraph and GraphBLAS backends in particular often have state-of-the-art performance (or close to it) for algorithms they implement, and efficient binary data structures as long as the graphs aren't frequently mutating.  We want to make life easier for backend implementers: - backends can run NetworkX tests - backends can show up in NetworkX online documentation   - for example, scroll to bottom of:     - https://networkx.org/documentation/latest/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html - backends can be explicitly used from NetworkX:   - when calling an algorithm, explicitly choose a backend; graph `G` will be converted     - `nx.pagerank(G, backend="graphblas")`   - when _creating_ a graph, choose a backend:     - `G = nx.from_pandas_edgelist(df, backend="cugraph")`   - automatically (with configuration--and we plan to make this better) - plus some other TLC to make the experience more pleasant  There's still a lot we plan to do (especially better documentation!), hence why dispatching is still experimental. For example, I want "data structure"-only backends to be easy to create and generally useful. For example, it may be nice to use dict-of-arrays using COO or CSR or DCSR to store edge indices (similar to what `nx-cugraph` does), or maybe use scipy sparse arrays, or maybe pandas DataFrames, or maybe igraph graphs, or rustworkx graphs, etc., and then have backend-to-backend conversions.  Adding dispatching to networkx algorithms has the added benefit of indicating what edge, node, or graph data is used by the function, and what the default values are For example: - `pagerank`, uses "weight" edge data (with default value of 1, which is the default): https://github.com/networkx/networkx/blob/b7d0b0cc8f7395dc9668d25379f3615752112c20/networkx/algorithms/link_analysis/pagerank_alg.py#L9-L10 - `connected_components` doesn't use any edge or node data--only graph structure: https://github.com/networkx/networkx/blob/b7d0b0cc8f7395dc9668d25379f3615752112c20/networkx/algorithms/components/connected.py#L16-L17 - `min_cost_flow_cost` uses "demand" node data and two edge attributes with different default values: https://github.com/networkx/networkx/blob/b7d0b0cc8f7395dc9668d25379f3615752112c20/networkx/algorithms/flow/mincost.py#L10-L11 - `k_truss` uses _all_ attributes (node, edge, and graph): https://github.com/networkx/networkx/blob/b7d0b0cc8f7395dc9668d25379f3615752112c20/networkx/algorithms/core.py#L471-L472  Hence, I think this is in the same vein as typing in that it's declaring how a graph will be used and what attributes it needs. This effort has uncovered a number of (minor) bugs in NetworkX. As we implement more algorithms in backends, I'm curious whether we'll find some awkward functions that are also awkward for typing.  That's the gist of it. NetworkX is evolving to better support binary data structures and alternative implementations, and will keep its current data structures. I'm happy to answer any questions.
comment
> > To support that syntax, the `Graph` class only needs to define `__class_getitem__` method. Inline annotations is irrelevant. >  > Right, exactly. That's why I was suggesting inheriting from `Generic[Node]` to provide that. (I'm not suggesting annotating any methods or functions.) Would such a PR be likely to be accepted?  I'm not a core dev, so I'm not in a position to say or guess. I'm not an expert on typing, but there don't appear to be any usability or performance penalties that I can find by adding this. Are there any caveats that we should be aware of?
comment
> Just that we would be fixing the number of generic parameters to one: the `Node` type. It seems very unlikely to change that though.  This does seem to be the most natural way to begin. One could imagine using [`pandera`-like](https://pandera.readthedocs.io/en/stable/index.html) typing with a schema for edge, node, and graph attributes and their types, which may become more appealing once backends with binary data structures become more commonplace.
comment
Nice! I like how function-specific notes are still included in the docstring and also having a link for more details.  Some of the additional docstrings are rendered oddly. Note that networkx doesn't use dedent or any sort of cleaning of these inputs (maybe we should?): https://github.com/networkx/networkx/blob/2f56b65c83ae75c23eb67a59219e028e3fbeaae1/networkx/utils/backends.py#L1886-L1891  See how `asyn_lpa_communities` is quoted b/c it's indented: https://output.circle-artifacts.com/output/job/9f31fd5a-3461-42e6-a769-a4252139f93d/artifacts/0/doc/build/html/reference/algorithms/generated/networkx.algorithms.community.label_propagation.asyn_lpa_communities.html#networkx.algorithms.community.label_propagation.asyn_lpa_communities  And see how `pagerank` makes the first line bold: https://output.circle-artifacts.com/output/job/9f31fd5a-3461-42e6-a769-a4252139f93d/artifacts/0/doc/build/html/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html#networkx.algorithms.link_analysis.pagerank_alg.pagerank  The additional docstrings are defined here: https://github.com/awslabs/nx-neptune/blob/main/nx_plugin/__init__.py  Maybe we should try to have NetworkX clean up these strings to be more accommodating. This isn't something I've put much effort into.  Oh, and my two cents are having tests--especially running networkx tests--is best practice even if only run locally, but I understand this may be more difficult, inconvenient, or costly for some backends. As long as backends are striving to do well and making an honest effort--and respond to user feedback--I'm okay with including them.
comment
Thanks for jumping on this @rossbar and @Peiffap! LGTM.  If CI is passing for 3.14, why not also add Python 3.14 to INSTALL.rst and pyproject.toml?
comment
> Also on an unrelated note - I see the old normalization factor (see L119) - pinging @eriknw for an extra set of eyes given the work to fix bc in https://github.com/networkx/networkx/pull/7908 . There's no endpoints in this case, but there is k!  Oh boy! I'll need to read up on this algorithm to have any degree of confidence. But, if this is similar to regular BC, the normalization might be something like `(k - 1) * (n - 2)` instead of `(n - 1) * (n - 2)`.  Also, there may be nuance when `normalized=False`. What is expected to be calculated: an estimate of the "full" nonnormalized centrality, or the partial "k" centrality? For the former, the results may need to be scaled by e.g. `N / (k - 1)` (depending on the definition of the centrality and what exactly is being estimated).
comment
Thanks for this! I'm sorry for being slow to the party--I've been afk.  I think separating out docs as is currently done in this PR makes a lot of sense. It has gotten quite long.  Regarding moving to `nx.backends`, we avoided using this previously because it's unclear what `nx.backends` is expected to be and whether it should be a top-level, user-facing namespace. I want to support exploring packages via tab-completion, and `backends` is alphabetically low, so it would always appear in `nx.<TAB>` even though it may not be useful or what is expected. So, do we expect users to interact or get anything from `nx.backends`? If not, or if not _yet_, then perhaps `nx.utils.backends` or `nx._backends` may make more sense for now, but I'm open to `nx.backends` if we believe this is the direction we want to go (after all, this would give more signal to users that backends are a thing).  I think we can break up `backends.py` into a `backends/` subpackage even if some of the files are short. There is handling of the entry points, handling of the environment variables for configs, helper functions for using caches, a couple other utilities, and #7765 adds plugin hooks, and these could all be separate files. It's not clear to me whether `_dispatchable` class can or should be split up, but I do support efforts of trying to make it more clear. IMHO, the value of #7761 isn't that it separates out the `__call__` method and uses one less indent; it's that it defines a _simple_ `__call__` method when there are no networkx backends. I do think perhaps #7761 should define `_call_backends_installed` and `_call_no_backends_installed` in the class body.
comment
Aha! Equation 2 actually computes a coefficient for a node (`i` in the paper, `v` in networkx ) and two neighbors (`m` and `n` in the paper, `u` and `w` in networkx). So, when you do `(4 * (1/3) + 2 * 0) / 6 = 2 / 9`, I'm guessing you are taking the average of the coefficients `mean(square_coeff(G, v, u, w) for u, w in uw_pairs)`. Instead, to compute the coefficient `square_clustering(G, v)`, do e.g. `sum(squares(G, v, u, w) for u, w in uw_pairs) / sum(potential_squares(G, v, u, w) for u, w in uw_pairs)`.  I'm glad you're able to count the squares and potential! I still find it tricky, but am slowly improving.
comment
I fixed the tests by updating some of the dispatch testing code. There is a bit of technical debt here, so there ought to be a better way to address issues like this if I'm not around.
comment
> I thought the backtick/single quote difference was a mistake and not intentional. Was it intentional? It looks like single quote starts only one of the two '%s'. My question is whether there is a meaning for backticks that I don't understand in the formatted string?  @rlratzel introduced using backtick/single quote for the name of the dispatchable function in #7300. I don't know if there's a particular meaning other than an alternative way to read "left quote - right quote". Changing it to `'%s'` also seems fine and probably more normal.  > - Perhaps I do have a inclination against the walrus opertor -- I recall thinking that Guido "finally backed down" when it was introduced. So I'll re-evaluate my stance. To help me with that: how do you mentally read the following code? [stripped for x in string.strip().split(",") if (stripped := x.strip())] >  > I end up with something like "if stripped is equal to x.strip()"... which is totally not correct. So then I stop and go back to parse the whole sentence again in backwards order. It would help me to know how someone who likes the walrus reads that code. So you read it left to right? Do you scan for walruses first and then rescan for meaning?  Great questions and fun topic! I'm not sure if I have an auditory equivalent for how I comprehend using the walrus operator. I think maybe the simplest is to read `:=` as "defined as", so it would be like "stripped for x in ... if stripped defined as ...". For reading more backwards by finding the walrus operator first, I think maybe something like "given stripped defined as ..., stripped for x in ... if stripped".
comment
Yay, more sane linting! Thanks @dschult.  pre-commit linting should probably take care of this, which can be done by adding the following to `.pre-commit-config.yaml`: ```yaml   - repo: https://github.com/pre-commit/pre-commit-hooks     rev: v5.0.0     hooks:       - id: mixed-line-ending         args: [--fix=lf] ```
comment
Thanks @rossbar and @jarrodmillman!
comment
Thanks @rossbar! These changes look good to me, and I'm +1 for adding more _sane_ linting to ensure code quality. I agree some rules are rather nitpicky and subjective, but I also think there's a lot more that we could reasonably add (and clean up).  For E722, we should at least change it from `except:` to `except Exception:`.  While we're linting and if you're up for it, I did a quick scan of other rules for you to consider (this isn't exhaustive), listed alphabetically: ``` B015 Pointless comparison at end of function scope. Did you mean to return the expression result? B028 No explicit `stacklevel` keyword argument found B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling  E101 Indentation contains mixed spaces and tabs     - ignore in tests  F541 (f-string-missing-placeholders) (but I don't like this as auto-fix, b/c maybe there's a mistake)  FLY002 Consider `f" ..."` instead of string join (I'm skeptical when a rule begins with "Consider...")  INP001 File ... is part of an implicit namespace package. Add an `__init__.py`.     - ignore everything not `networkx/` (tools, examples, doc)  ISC003 Explicitly concatenated string should be implicitly concatenated  N804 First argument of a class method should be named `cls`  PERF101 When using only the values of a dict use the `values()` method PERF102 When using only the values of a dict use the `values()` method PERF401 Use `list.extend` to create a transformed list PERF402 Use `list` or `list.copy` to create a copy of a list PERF403 Use a dictionary comprehension instead of a for-loop  PLE0704 Bare `raise` statement is not inside an exception handler  PLW3301 Nested `max` calls can be flattened  PT018 Assertion should be broken down into multiple parts  RUF001 String contains ambiguous `â€“` (EN DASH). Did you mean `-` (HYPHEN-MINUS)? RUF002 Docstring contains ambiguous `â€“` (EN DASH). Did you mean `-` (HYPHEN-MINUS)? RUF003 Comment contains ambiguous `âˆ¨` (LOGICAL OR). Did you mean `v` (LATIN SMALL LETTER V)? RUF007 Prefer `itertools.pairwise()` over `zip()` when iterating over successive pairs RUF024 Do not pass mutable objects as values to `dict.fromkeys`  SIM103 Return the (negated) condition ... directly  TRY002 Create your own exception TRY203 Remove exception handler; error is immediately re-raised  W291 Trailing whitespace     - ignore in tests ``` where you can add `"networkx/**/tests/*.py" = []` to skip rules in tests.
comment
This seems like a good idea to me! Note that `"dense"` and `"array"` are already valid values for `format=` even though they're not documented: `A.asformat("dense")` returns a numpy array.  @michaelweinold I'm curious--what's the performance difference between your code for creating a numpy array vs using the original code with `format="dense"`? If the latter is not noticeably worse, then the code could remain the same and the only thing that would need updated is the docstring.  `to_scipy_sparse_array` is another function that returns a scipy sparse array and has the `format=` argument, so it also currently supports `"dense"` format (but this isn't documented).  The other functions I found that return scipy sparse arrays but don't have a way to specify the format are `adjacency_matrix`, `attr_sparse_matrix`, `bethe_hessian_matrix`, `incidence_matrix`, `laplacian_matrix`, `normalized_laplacian_matrix`, and `tournament_matrix`. I don't recommend adding `format=` to these functions in this PR, but if anybody thinks doing so is a good idea then please make a new issue or PR to continue exploring this option.
comment
The idea makes sense, but the behavior is not quite equivalent, because the kwarg splatting `**ddd` only works when the keys of `ddd` are strings. For example: ```python MG = nx.MultiGraph() MG.add_edges_from([(0, 1, 0, {10: 20})])  # This works MG.add_edge(0, 1, 0, **{10: 20})  # TypeError: keywords must be strings ``` This is kind of a weird edge case though, and is responsible for most (but not all) test failures (I haven't looked closely).
comment
The dispatch CI test is failing because `apply_matplotlib_colors` creates tuples of numpy scalars, which gets checked (and raised) downstream by `get_edge_attributes`.  **edit:** to fix this, update so that functions don't create outputs with numpy scalars.
comment
Okay, I fixed it by changing `apply_matplotlib_colors` to not create tuples of numpy scalars.
comment
#7902 was fixed by making a small change to `_convert_and_call_for_tests` in the dispatch code so it would return the original graph after verifying the backend graph and input graphs are identical. This touches some technical debt that would be nice to clean up or at least make it easier to work around.  #7589 was fixed by updating `apply_matplotlib_colors` to not add tuples of numpy scalars to the graph. In this case, the dispatch tests were catching something we want to catch, but `apply_matplotlib_colors` isn't dispatched yet, so the issue was caught in subsequent calls that _are_ dispatched, so it wasn't as clear as it could have been.
comment
Yeah, we've addressed the issue in #7589, and 1 of 2 issues in #7902 (fixed the original one, but now there's a new one where the same fix doesn't work).  > If there is something I missed here, make a comment, or start a new issue.  Even better: a PR! #7982 pays off some debt and should completely unblock #7902.
comment
> I'm going to merge this PR about could_be_isomorphic soon unless someone else posts something. We have 3 core devs who have taken a look at it. And I think 2 of us have taken a fairly deep dive in. :)  Sounds good. I'll take one more close look today.
comment
Good catch, and my bad (and hooray for randomization)!
comment
Here is a command to disable this warning: ```python warnings.filterwarnings("ignore", "Using cached graph", UserWarning, "networkx.utils.backends") ```
comment
Completed in #7497. Closing.
comment
This looks like a reasonable approach. The latest dev version of `np.linalg.inv` [says this](https://numpy.org/devdocs/reference/generated/numpy.linalg.inv.html): > If a is detected to be singular, a [LinAlgError](https://numpy.org/devdocs/reference/generated/numpy.linalg.LinAlgError.html#numpy.linalg.LinAlgError) is raised. If a is ill-conditioned, a [LinAlgError](https://numpy.org/devdocs/reference/generated/numpy.linalg.LinAlgError.html#numpy.linalg.LinAlgError) may or may not be raised, and results may be inaccurate due to floating-point errors.  Should a more clear error message be given for the null graph? `nx.trophic_levels(nx.DiGraph())` currently raises `NetworkXError: Graph has no nodes or edges`
comment
Also here: https://github.com/networkx/networkx/blob/09ad115d8c1bdbe201aac6c3a5b4794cc7fb84c6/benchmarks/asv.conf.json#L16
comment
Some prose:  > NetworkX backends can be used explicitly (requires changing code) or implicitly (requires setting configuration or environment variables). The best way to use a backend depends on the backend, your use case, and whether you want to automatically convert to or from backend graphs. Automatic conversions of graphs is always opt-in. >  > To explicitly use a backend, use `backend=...` keyword argument in a dispatchable function. This will convert (and cached by default) input NetworkX graphs to backend graphs and call the backend implementation. Another explicit way to use a backend is to create a backend graph directly--for example, perhaps the backend has its own functions for loading data and creating graphs--and pass that graph to a dispatchable function, > which will then call the backend implementation without converting. >  > Using backends implicitly requires setting configuration options. Every NetworkX configuration may also be set from an environment variable and are processed at the time networkx is imported. >  > `nx.config.backend_priority.algos` (`NETWORKX_BACKEND_PRIORITY_ALGOS` env var), a list of backends, controls dispatchable functions that don't return graphs such as `nx.pagerank`. When one of these functions is called with NetworkX graphs as input, the dispatcher iterates over the backends listed in this `backend_priority` config and will use the first backend that implements this function. The input NetworkX graphs are converted (and cached by default) to backend graphs. Using this configuration can allow you to use the full flexibility of NetworkX graphs and the performance of backend implementations, but possible downsides are that creating NetworkX graphs, converting to backend graphs, and caching backend graphs may all be expensive. >  > `nx.config.backend_priority.generators` (`NETWORKX_BACKEND_PRIORITY_GENERATORS` env var), a list of backends, controls dispatchable functions that return graphs such as `nx.from_pandas_edgelist` and `nx.empty_graph`. When one of these functions is called, the first backend listed in this `backend_priority` config that implements this function will be used and will return a backend graph. When this backend graph is passed to other dispatchable NetworkX functions, it will use the backend implementation if it exists or raise by default unless `nx.config.fallback_to_nx` is True (default is False). Using this configuration avoids creating NetworkX graphs, which subsequently avoids the need to convert to and cache backend graphs as when using `nx.config.backend_priority.algos`, but possible downsides are that the backend graph may not behave the same as a NetworkX graph and the backend may not implement all algorithms that you use, which may break your workflow. >  > `nx.config.fallback_to_nx` (`NETWORKX_FALLBACK_TO_NX` env var), a boolean (default False), controls what happens when a backend graph is passed to a dispatchable function that is not implemented by that backend. The default behavior when False is to raise. If True, then the backend graph will be converted (and cached by default) to a NetworkX graph and will run with the default NetworkX implementation. Enabling this configuration can allow workflows to complete if the backend does not implement all algorithms used by the workflow, but a possible downside is that it may require converting the input backend graph to a NetworkX graph, which may be expensive. If a backend graph is duck-type compatible as a NetworkX graph, then it may choose not to convert to a NetworkX graph since it already is one. >  > `nx.config.cache_converted_graphs` (`NETWORKX_CACHE_CONVERTED_GRAPHS` env var), a boolean (default True), controls whether graph conversions are cached to `G.__networkx_cache__` or not. Caching can improve performance by avoiding repeated conversions, but it uses more memory. >  > Backends are encouraged to document how they recommend to be used and whether their graph types are duck-type compatible as NetworkX graphs. If backend graphs are NetworkX-compatible and you want your workflow to automatically "just work" with a backend--performing conversions and caching if necessary--then use all of the above configurations. Automatically converting graphs is opt-in, and configuration gives you the user control. > 
comment
FYI: somewhat related, we have, and are, exploring caching results of functions (see #7283). For example, this can allow us to compute connectedness of a graph only once, which may help mitigate the performance penalty of checking connectedness (and other such properties) here and elsewhere.  At PyConUS @dschult, @rlratzel, @MridulS, and I discussed that caching of function results should be added _narrowly_, _incrementally_, and _as use cases arise_, unlike what was done in #7283. Hence maybe caching could begin with e.g. `is_connected`, `is_strongly_connected`, `is_weakly_connected`, `number_connected_components`, `number_strongly_connected_components`, `number_weakly_connected_components`, or just some of these.  This doesn't change anything that needs done in this PR.  It seems like a good idea to me to check for properties such as connectedness to ensure that an algorithm is well-defined for the input graph.
comment
Quick question: what is meant by rules that are in both `extend-select` and `ignore`? For example, `ICN`, `PD`, and `PYI`.  I'm -1 on adding PD, pandas-vet, which I think is more appropriate for scripts that use pandas heavily.
comment
Uh oh. Probably related to these changes: https://github.com/rapidsai/cugraph/pull/4393/files#diff-da408c35bbbee9057f3230c2fc2ddfcff64e160bc1dcf5059df0293036636379 Looking now.
comment
> Is there a reason you approved it but haven't merged it @eriknw? @dschult already approved it, so it has 2 approvals. Do you want it to be reviewed by more people?  Thanks for the gentle nudge! The main reason is that I'm still getting used to merging in this org :joy: . @rlratzel and I were also discussing this PR last week, and I wanted to give him a chance to review one last time (he did, and he approved).
comment
Interesting. Thanks for making an issue for this. Do all the failures occur with NumPy 2? Are there any failures seen with NumPy 1.26? Are all the failures related to using random numbers with numpy?  I don't think we ran dispatch tests on numpy 2 pre-releases.
comment
I just saw this issue.  The loopback graph classes use the dispatching metadata that indicate what data is used. For example, if only `"weight"` edge attribute is used, then only it will be copied. See `convert_from_nx` here: https://github.com/networkx/networkx/blob/main/networkx/classes/tests/dispatch_interface.py  This file should probably be moved, as it's pretty hard to find.  Note that there is an "ignore" list at the top of this function that skips the usual conversion for a handful of functions. For example, `dfs_labeled_edges` is skipped due to sensitive tests. If there are other sensitive tests and there is no other reasonable workaround, I think it's okay to add more functions to the "ignore" list.
comment
Thanks for taking a close look and asking good questions. `G1` here is not a backend graph--it is a networkx graph having been converted via `convert_to_nx`--so we can safely assume it has attributes like `_adj`. The graph that `G1` is converted from is the backend graph that was the input to the function, so this is able to test that the function correctly mutates the input (backend) graph.  Much of the code here is pragmatic and often regarded as technical debt. Typically, a good way to see why code like this exists is to delete some of it and see what tests break. It's very possible we should be more careful when updating the original graph attributes (such as `_pred`), but doing so has not been necessary to pass tests.
comment
LGTM :+1:
comment
Food for thought: "Structural Pattern Matching is _not_ a `switch` statement!" - [Brand Bucher, PyCon US 2022](https://www.youtube.com/watch?v=XpxTrDDcpPE&t=373s) ("...and I feel that you are doing yourself a disservice if you try to use it like a switch statement")
comment
wow, nice sleuthing!
comment
`zip(x, y, strict=True)` is pretty handy ([see here](https://docs.python.org/3.10/library/functions.html#zip)).
comment
I'm unable to reproduce. @jim22k added this test back in #6628. I expect the following error: ```python-traceback TypeError: Unable to convert inputs and run intersection. intersection() has networkx and nx-loopback graphs, but NetworkX is not configured to automatically convert graphs from networkx to nx-loopback. ``` I'd probably recommend setting a breakpoint and stepping through a debugger to see what's happening.
comment
It should find `rtoml` in the conda-forge channel. Did you forget to add `-c conda-forge`? I don't see `changelist` available from conda-forge, so maybe the directions using conda don't currently work.
comment
> The dispatching tests are failing but I'm not sure why... @eriknw any ideas?  Thanks for the ping! You can expect me to be around to help with issues like this. This is a good data point, and I suppose we should make the assertion message more informative.  _**EDIT: this is not the best solution. See my next reply**_  I debugged this locally, and the solution is to change the `_dispatchable` decorator of `steiner_tree` to: ```python @nx._dispatchable(edge_attrs={"weight": None}, returns_graph=True) ``` The issue is that `"weight"` edge attribute was being filled to `1` (the default value according to the docstring) in the converted backend graph, but the correct behavior is to not add edge values if they don't exist. Using `edge_attrs={"weight": None}` will preserve the weight edge attribute _if_ it exists, but won't add new ones.
comment
Correction--use this `_dispatchble`: ```python @nx._dispatchable(preserve_all_attrs=True, returns_graph=True) ``` The returned graph preserves edge, node, and graphs attributes from the original graph.
comment
I hadn't considered the connotation difference between "extra" and "additional", but, yeah, let's go with "additional".  Regarding the new names, I think having `"backend_func_*"` is redundant. It is _already_ defined within function information for a backend--specifically, `nx.utils.backends.backend_info[backend_name]["functions"][function_name][key]`. - So instead of `"backend_func_url"` as `key`, it could simply be `"url"`   - I like adding this! - Similarly, `"backend_func_docs"` could be `"doc"` or `"additional_doc"` (`doc`, `docs`, `docstring`?)   - `"additional_doc*"` matches naming style of `"additional_parameters"`
comment
> 1292: Maybe `node in G._adj` is faster than `node in G`?  This changes behavior. `Graph.__contains__` has a try/except statement, so using `node in G._adj` may raise where code does not currently. This may not be a bad thing, but it's different.
comment
Yeah, this is indeed an abstraction collision, and providing kwargs to e.g. the flow func is chosen over providing backend kwargs. I'm impressed you spotted this!  This is apparent when looking at the generated signature (one branch adds `**backend_kwargs`, the other doesn't): https://github.com/networkx/networkx/blob/1c5272054f71f9484347f7e4246ae3d5da367f7b/networkx/utils/backends.py#L370-L401  > A potential solution could include passing flow_func kwargs not as actual kwargs, but as an explicit dictionary.  Yeah, here are potential solutions that I see: - Pass kwargs to flow_func as a dict argument (as you proposed). - Pass a dict for the backend kwargs as e.g. `backend_kwargs={...}`, thereby making `backend_kwargs` another reserved argument. - Don't support kwargs for flow_func and direct users to curry argument (such as with `functools.partial`) instead - Provide a convenient way to get a function from a backend, such as `nx.pagerank.funcs["graphblas"]` or whatever
comment
I think type stubs today should only have `**kwargs` for these functions and not `**backend_kwargs` (which also matches the generated signatures). If networkx changes, then naturally type stubs should also change to match.
comment
I like the idea of being able to use arguments to pytest. However, due to https://github.com/pytest-dev/pytest/issues/1596, I think it's awkward right now to use pytest when working on a backend. Ideally, I would like to be able to do: ```bash pytest --pyargs networkx --backend graphblas ``` from `graphblas-algorithms` project directory, but this doesn't work. One option is to pass the absolute location of networkx to pytest ```bash pytest `python -c 'import networkx as nx ; print(nx.__file__[:-11])'` --backend cugraph ``` but I find this even uglier than using environment variables.  One workaround [here](https://stackoverflow.com/questions/41270604/using-command-line-parameters-with-pytest-pyargs/43747114#43747114) would let us run networkx tests as: ```bash python -m networkx.test --backend parallel ``` I would be fine with this approach, but it would need to be developed.  Relying on environment variables at import time as we do today probably isn't ideal, so I support trying to clean up this technical debt.  btw, when I run this PR locally, I get: ```python-traceback NameError: name 'fallback_to_nx' is not defined ``` b/c `fallback_to_nx` is currently only defined when `NETWORKX_GRAPH_CONVERT` environment variable is set.
comment
Yeah, I think the scoping thing will be better if we made `_dispatch` a class instead of using closures.  LGTM!
comment
CC @jim22k
comment
@MridulS @jim22k and I discussed this today, and our near-term plan is: - Have `graphblas-algorithms` implement the algorithms and the base classes   - Algorithms within `graphblas-algorithms` return GraphBLAS-specific objects, not dicts or NetworkX graphs   - User-facing functions should _include_ the NetworkX API, but are free to add additional keyword-only arguments (so far we don't need any, but it's nice to have the option)   - Hence, if users want to avoid the conversion cost to/from NetworkX and GraphBLAS, they can use `graphblas-algorithms` directly to stay within GraphBLAS.   - For now, the majority of development, maintenance, testing, etc. of GraphBLAS algorithms will take place in `graphblas-algorithms` repo. - `networkx.graphblas` can be structured as in this PR   - Instead of having implementations, it should have simple wrappers that convert results  For example, a simple wrapper in `networkx.graphblas` may be like: ```python def triangles(G, nodes=None):     result = ga.triangles(G, nodes)     return result.to_dict() ``` I believe this gives us the most flexibility going forward with the added bonus of adding `networkx.graphblas`, which will allow users to discover a way to accelerate some algorithms.
comment
@MridulS, is there anything @jim22k or I can help with to push this forward?
