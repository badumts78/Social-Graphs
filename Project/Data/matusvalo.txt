issue
equitable_coloring: Get lazily first item instead of creating whole list#TITLE_END#This PR adjusts equitable_coloring to compute first value lazily using iterator instead of computing whole list of values. This yields not negligible performance increase:  ```bash # main branch $ python -m timeit -s 'import networkx as nx; G = nx.circular_ladder_graph(5000)' -- 'd = nx.coloring.equitable_color(G, num_colors=4)' 1 loop, best of 5: 939 msec per loop  # PR $ python -m timeit -s 'import networkx as nx; G = nx.circular_ladder_graph(5000)' -- 'd = nx.coloring.equitable_color(G, num_colors=4)' 2 loops, best of 5: 142 msec per loop ``` 
issue
Compute `is_weakly_connected` lazily#TITLE_END#<!-- Please run black to format your code. See https://networkx.org/documentation/latest/developer/contribute.html for details. -->  This PR computes `is_weakly_connected` lazily. This can yield significant performance increase. E.g. for case of discrete graph:  <img width="640" alt="image" src="https://user-images.githubusercontent.com/827060/174406999-1ce3f32f-b8c7-458a-bb20-ecfd155aa799.png">  ```python import timeit vertices = [1, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 50000] times = [] for i in vertices:     times_patched.append(timeit.timeit(stmt='nx.is_weakly_connected(G)', setup=f'import networkx as nx; G = nx.DiGraph(); G.add_nodes_from(range({i}))', number=100)) ```   
issue
Compute `is_strongly_connected` lazily#TITLE_END#The PR computes strongly connected components lazily. This approach avoids the need of computing all strongly connected components and yields performance increase of graphs having more strongly connected components. The following example is based on directed path graph:  <img width="642" alt="image" src="https://user-images.githubusercontent.com/827060/174404452-c986092a-7799-40ee-ba93-609b556b21c0.png">   ```python import timeit vertices = [1, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 50000] times = [] for i in vertices:     times.append(timeit.timeit(stmt='nx.is_strongly_connected(G)', setup=f'import networkx as nx; G = nx.path_graph({i}, create_using=nx.DiGraph)', number=100)) ````
issue
Dont compute all biconnected components in `is_biconnected()`#TITLE_END#This PR uses lazy approach for iterating over biconnected components in `is_biconnected()` function. This approach yields some performance improvements:  ```bash # master branch  $ python -m timeit -n 5 -s ' import networkx as nx G1 = nx.cycle_graph(range(0,     40001)) G2 = nx.cycle_graph(range(40000,  80001)) G3 = nx.cycle_graph(range(80000,  120001)) G4 = nx.cycle_graph(range(120000, 160001)) G5 = nx.cycle_graph(range(160000, 200001)) G6 = nx.cycle_graph(range(200000, 240001))  G1.add_nodes_from(G2) G1.add_edges_from(G2.edges) G1.add_nodes_from(G3) G1.add_edges_from(G3.edges) G1.add_nodes_from(G4) G1.add_edges_from(G4.edges) G1.add_nodes_from(G5) G1.add_edges_from(G5.edges) G1.add_nodes_from(G6) G1.add_edges_from(G6.edges) ' -- 'nx.is_biconnected(G1)' 5 loops, best of 5: 607 msec per loop  # PR  $ python -m timeit -n 5 -s ' import networkx as nx G1 = nx.cycle_graph(range(0,     40001)) G2 = nx.cycle_graph(range(40000,  80001)) G3 = nx.cycle_graph(range(80000,  120001)) G4 = nx.cycle_graph(range(120000, 160001)) G5 = nx.cycle_graph(range(160000, 200001)) G6 = nx.cycle_graph(range(200000, 240001))  G1.add_nodes_from(G2) G1.add_edges_from(G2.edges) G1.add_nodes_from(G3) G1.add_edges_from(G3.edges) G1.add_nodes_from(G4) G1.add_edges_from(G4.edges) G1.add_nodes_from(G5) G1.add_edges_from(G5.edges) G1.add_nodes_from(G6) G1.add_edges_from(G6.edges) ' -- 'nx.is_biconnected(G1)' 5 loops, best of 5: 457 msec per loop ``` 
issue
Added basic cythonized code#TITLE_END#This PR adds cythonization to networkx as Proof of Concept.  This PR focuses on improvement of loading/dumping graphs and one algorithm is picked. As data set is graph with 334863 vertices and 925872 edges. Performance improvements:  * `python -m timeit -n 10 -r 3 -s 'import networkx as nx' 'nx.read_adjlist("data/out.com-amazon")'` (**28.87%** improvement): cython: 10 loops, best of 3: 3.67 sec per loop python: 10 loops, best of 3: 5.16 sec per loop  * `python -m timeit -n 10 -r 3 -s 'import networkx as nx; G = nx.read_adjlist("data/out.com-amazon")' 'nx.write_adjlist(G, "data/out.com-amazon_deleteme")'` (**30.34%** improvement): cython: 10 loops, best of 3: 1.01 sec per loop python: 10 loops, best of 3: 1.45 sec per loop  * `python -m timeit -n 10 -r 3 -s 'import networkx as nx' 'nx.read_edgelist("data/out.com-amazon.edgelist")'` (**8.87%** improvement): cython: 10 loops, best of 3: 11.3 sec per loop python: 10 loops, best of 3: 12.4 sec per loop  * `python -m timeit -n 10 -r 3 -s 'import networkx as nx; G = nx.read_adjlist("data/out.com-amazon")' 'nx.write_edgelist(G, "data/out.com-amazon.edgelist")'` (**20.84%** improvement): cython: 10 loops, best of 3: 2.05 sec per loop python: 10 loops, best of 3: 2.59 sec per loop  * `python -m timeit -n 10 -r 3 -s 'import networkx as nx; G = nx.read_adjlist("data/out.com-amazon")' 'nx.biconnected_components(G)'` (**8.80%** improvement): cython: 10 loops, best of 3: 2.59 usec per loop python: 10 loops, best of 3: 2.84 usec per loop  ### Installation Code is written in pure python mode hence it is able to run in pure python with current performance or can be compiled to have performance gains. Hence **the code can be installed and used without no change**. To cythonize and build code the user needs to have cython installed and full build dependencies (GCC, python headers etc). Building is enabled by exporting `NETWORKX_ENABLE_SPEEDUPS` variable - for building and installing networkx with speedups run the following command: ``` NETWORKX_ENABLE_SPEEDUPS=1 python setup.py install ``` For installing networkx code in pure python installation is same as now: ``` python setup.py install ```  In future there is possibility to publish binary wheels with prebuilt cythonized code where users can install the library without execution build.  ### Modifications to networkx library 1. The cythonization was done using pure python mode [1] via annotations.  2. In order to cythonize read/write code there was need of removing dependency to decorator library and manually create decorators.  ### Future improvements Current code is just proof of concept which goal was to introduce smallest possible changes to code base. Further improvements can be introduced which will yield better performance. All of changes will support running as pure python code, but some of them will need more invasive changes to code base: 1. Implementing graph classes as extension classes [2]. This change will boost mainly code calling API of classes. E.g. https://github.com/networkx/networkx/blob/938063c9011a4ecd4f3632a7a59ed63334d821ee/networkx/readwrite/adjlist.py#L213 is calling `add_edges_from` method for each line in input file. This is bottleneck since calling python methods is slow. This migration has unfortunatelly several blockers:    * static class attributes are not supported by cython    * `**kwargs` are not supported by cython    * not all classes can be migrated - e.g. `MultiDiGraph` cannot be migrated since it has 2 parents 2. gml loading/dumping cannot be cythonized since cython does not support typed namedtuples. This can be fixed via migrating to basic namedtuple 3. Introducing separate speedups. Hot paths can be improved by reimplementing them directly in cython with more low level code - e.g. using C++ constructs [3]. Unfortunately this will add maintenance burden to keep 2 versions of the same logic. 4. distribution can be improved by distributing via pre-compiled wheel packages.  But even following simple cythonization seems to have major performance impact as showed before. Is there a will to have this kind of speedups present in the networkx? If yes, how we can start?  [1] https://cython.readthedocs.io/en/latest/src/tutorial/pure.html [2] https://cython.readthedocs.io/en/latest/src/tutorial/cdef_classes.html [3] https://cython.readthedocs.io/en/latest/src/userguide/wrapping_CPlusPlus.html
