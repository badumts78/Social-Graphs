comment
Can confirm what @gjulianm said. Most of [fmagin/networkx-stubs](https://github.com/fmagin/networkx-stubs/) is just auto generated with [mypy's stubgen](https://mypy.readthedocs.io/en/stable/stubgen.html), but I have been adding annotations to Graph/DiGraph as far as I needed them for the specific codebases I am working with. Because the discussion around type annotations was basically nonexistent before this PR except for https://github.com/networkx/networkx/issues/2183 which had no activity since 2016, I assumed that there wasn't much interest and only focused on what I needed for myself. @gjulianm then recently added annotations for MultiGraph.  The major advantage with auto generating all the stubs is that IDEs (at least PyCharm) will provide a shortcut to jump from the definition in `foo/bar/baz.py` to the type signature in the stub file `foo-stubs/bar/baz.py`. So if an annotation is missing you can simply jump to the definition, jump to the stub, add the annotation and PyCharm will immediately use it if the `-stubs` package is installed with `--editable`. Otherwise you would need to create the actual stub file every time you want to annotate something in a new file and also copy paste the classnames, methodnames, attributes, etc. https://www.jetbrains.com/help/pycharm/stubs.html#quick-navigation demonstrates this.  @NeilGirdhar  Does this change your view on combining efforts or choosing the `-stubs` package approach in general? As far as I read your annotations for Graph/DiGraph they are indeed better and more extensive than mine and they might even be a drop in replacement for DiGraph related files.   @dschult Concerning the readability: I understand your point that this complicates the readability. It doesn't necessarily _reduce_ it overall, because moving the information to the actual function signature instead of the docstring seems like the more intuitive approach. But I am not sure how this will balance out for someone who is new to Python. I think that especially people not familiar with Python or the specific code will benefit a lot from their IDE knowing the types without them having to do the type inference in their head.  It should also be taken into account is that type annotations actually changes the semantics of the Python file as well in some cases. I.e. if you want to use a class as a return type this class needs to actually be imported before the use of it as an annotation. In some cases this can lead to import cycles, which can then be handled by putting the type on the bottom of the file and quoting the type (so the runtime just treats it as a string) or with conditional imports via `if typing.TYPE_CHECKING`. In most cases this should not be relevant and maybe this is a sign of messy code in the first place, but one advantage of the `-stubs` package approach would be that this is not an issue then. The `-stubs` package will only ever be read by MyPy, the IDE, etc, never the runtime interpreter.    One major thing that must not be forgotten is that there are **_three_** official approaches to distributing type information according to [PEP 561](https://www.python.org/dev/peps/pep-0561/#specification) and so far only **_two_** have been discussed here. Specifically:  > There are several motivations and methods of supporting typing in a package. This PEP recognizes three types of packages that users of typing wish to create: > 1. The package maintainer would like to add type information inline. > 1. The package maintainer would like to add type information via stubs. > 1. A third party or package maintainer would like to share stub files for a package, but the maintainer does not want to include them in the source of the package.  This PR tries to implement  the first approach by adding the type information inline. This has some disadvantages like the readability concerns brought up by @dschult and import issues I discussed above.  My `networkx-stubs` package implements the third approach. This has issues that the package needs to properly track the releases and is at risk of getting out of sync with the actual package.  The second approach means adding the `.pyi` files (like in the `networkx-stubs` package) right next to the actual `.py` source files. This allows the CI to ensure that they are in sync with the actual code and type check the code itself and IDEs can use it without requiring a second package to be installed. This would also solve the readability and import issues. I consider this approach strictly superior to the `-stubs` package approach. 
comment
@jarrodmillman I am quickly going to jump in here, because I think I can also answer your question to @gjulianm, at least as far as my DiGraph annotations are concerned.   I have been working on a codebase at my job that both uses `networkx` itself directly and another library ([angr](https://github.com/angr)) that also uses `networkx` for graphs. The general context is program analysis.  One very basic example is the following code pattern:  ```python def some_example_function(graph)     result = []     for node in graph:         result.append(node.foo()) ```  I could annotate this (in my code) as:  ```python def some_example_function(graph: networkx.DiGraph) -> List[str]:     result = []     for node in graph:         result.append(node.bar())     return result ```  but this is nearly useless and adds no further information than that the graph is expected to be a DiGraph.  With my networkx annotations I can instead to this:  ```python def some_example_function(graph: networkx.DiGraph[Block]) -> List[str]:     result = []     for node in graph:         result.append(node.bar())     return result ```  the DiGraph object is now generic over a certain type, in this case `Block` (which for the sake of this example is some class specific to our codebase). This already conveys the information that this function expects a DiGraph of certain objects. A DiGraph of integers would not be valid. This already massively improves the readability of our code, which has different kinds of graphs with completely different uses.  But the real benefit is if `networkx.DiGraph.__iter__` is properly annotated, the type of `node` can now also be inferred as `Block` by the IDE. Which means that the IDE can now also check that the `Block` objects has a method called `bar` that returns a string. The fairly few annotations in my `-stubs` package led me to finding various bugs, type issues, etc in our code because mypy or PyCharm could now simply tell me that the `Block` type doesn't have a method `bar` or that the method doesn't return a string. This would have been impossible without annotating networkx itself.  This also is quite useful for writing new code, because the IDE can infer the type of `node` and provide appropriate tab completions.  For a realworld example, consider this snippet ```python         while defs:             definition = defs.pop()             in_edges = graph.in_edges(definition, data=True)             for src, _, data in in_edges:                 if 'type' in data and data['type'] == 'kill':                     continue                 if isinstance(src.variable, SimTemporaryVariable):                     if src not in traversed:                         defs.append(src)                         traversed.add(src)                 else:                     if src not in sources:                         sources.append(src) ``` from https://github.com/angr/angr/blob/master/angr/analyses/ddg.py#L1644-L1656  I am assuming you are not familiar with this codebase. If even just the generic type of the graph is annotated this makes a ton of inference possible. 1. type of `in_edges` 2. type of `src` 3. type of `src.variable` and what other types besides `SimTemporaryVariable` it could be 4. type of `traversed` (or the fact that it might be an accidental bug because `traversed` is actually supposed to be collection of a different type) 5. type of `defs` 6. type of `sources`  This means that you would only need to annotate the type of graph manually and the IDE could infer the rest (and even add the annotations itself automatically!). Without annotations for networkx `graph.in_edges` would return `Any`. You could annotate the `src` variable itself, but that would now be required _every time_ this graph is used somewhere else in the code, instead of simply annotating the type of `graph` once.
comment
@NeilGirdhar  > There are no "import issues". As of 3.7, you can import from __future__ import annotations. As I was informed, the next release of networkx will require Python 3.7.  Both these points are great to know! I still had to support Python 3.5 when I started using type annotations, so I wasn't aware of this.  @stefanv  > I wonder if a good solution here could be for the stubs to move under the networkx github org. The networkx team could make a commitment to release the stubs along with every nx release, to keep things in sync. We could potentially even build it into networkx, but through a mechanism such as a submodule or a dependency. >  > That would be a "soft" option 3 @fmagin.  That would technically be an option, and I had considered this at some point, but I am not sure if this would actually be better than putting  the `.pyi` files in the same repo as the actual source files. I don't quite see how that violates your argument of: > It can live and be developed separately, potentially with much faster turnaround  It would allow you to give people contributor access to the `networkx-stubs` repo that you don't want to give this access to the actual repo, but because `.pyi` stubs shouldn't be that hard to review in PRs and should be quite easily checkable via CI I think PRs to `networkx` itself should still be the preferred approach. I agree with @NeilGirdhar here, the best way is to annotate the source files directly. If that for some reason is truly not possible, the next best approach are separate `.pyi` files in the main repo.   Consider that the inline annotations can be added incrementally. So any user that adds annotations for code that they happened to need can submit a PR that adds only annotations for their specific need. Like I did for DiGraph and @gjulianm did for MultiGraph. The only thing needed to get this going is the CI setup itself.    
comment
> IYO what specifically makes numpy more complicated and why you would expect to NetworkX to be simpler?  numpy is complicated to type annotate that they actually need their [own mypy plugin](https://numpy.org/devdocs/reference/typing.html#mypy-plugin) and an [extra typing PEP](https://www.python.org/dev/peps/pep-0646/).  NetworkX doesn't really need this kind of complicated logic, though there are still same cases where Python's typing logic will not suffice to properly type it. E.g. a `compose` takes two Graphs and returns a Graph, or two DiGraphs and returns a DiGraph, or two MultiGraphs and returns a MultiGraph, etc. But Python (IIRC) doesn't support a TypeVar for the Graph that is generic over some TypeVar again, [otherwise I probably would have properly annotated that in my stubs](https://github.com/fmagin/networkx-stubs/blob/master/networkx-stubs/algorithms/operators/binary.pyi#L19-L25). I can't remember the official issue about this or the PEP that might support this in the future.  [numpy explicitly states](https://numpy.org/devdocs/reference/typing.html#differences-from-the-runtime-numpy-api) that their typed API is stricter than the true runtime API, so that approach might be good for networkx to adapt too, and then separate `.pyi` files would probably make it less confusing.  I agree with @NeilGirdhar that inline type annotations are nicer, but I think that if the strain on experienced reviewer is indeed such a concern that will be alleviated by `.pyi` stub files then they could be the better option for now. It should be stressed though that @NeilGirdhar is right about untyped Python Code occasionally requiring some minor changes so it can be properly annotated so there will most likely be type annotations PRs that will involve code changes.  I think most of the usefulness of networkx annotations comes from the basic hints for the really basic methods like iterating over a graph, and having this will hopefully convince others that type annotations are indeed a useful thing to have. So IMO we should just merge those basic annotations as soon as possible, and if `.pyi` files are the solution that is more comfortable for the core networkx team for now, then so be it[0]. Ultimately you are the people who will have to work with it for much more time than I will have to.   [0] I would even go so far that merging the really basic annotations as `.pyi` stubs can be done before adding automated mypy checks to the CI, if the changes are carefully reviewed by a human reviewer (who runs mypy on them!) before.
comment
> Do you mind explaining this last sentence, and why that is necessary?  Just looked this up again, this feature is called "Higher Kinded Types" and is discussed as a type system feature for mypy in https://github.com/python/typing/issues/548  Roughly: The "true" type signature of `compose` as far as I understand it is: ```python def compose(G: GT1[X], H: GT2[Y]) -> SharedParent[GT1, GT2][Union[X,Y]]: ... ```  where `GT1`, `GT2` are `TypeVar('', bound=Graph)` i.e. they are some generic type that is guaranteed to be a subclass of Graph. `X` and `Y` are each a TypeVar for the nodes of the graph.  But there is no Python type annotation feature for "SharedParent" yet (e.g. that a DiGraph and a Graph have the shared Parent `Graph`). That is a different issue and not related to Higher Kinded Types. IIRC this would be covered by a potential `Intersection` (as the opposite of `Union`) operator.  So the best we could hope to do next would be only allowing the same type that is a subclass of Graph to be passed in there: ```python def compose(G: GT[X], H: GT[Y]) -> GT[Union[X,Y]]: ... ```  `GT` would be `TypeVar('GT', bound=Graph)`. But `GT` would be a Higher Kinded Type in this case, which isn't (yet) supported.  For most cases (i.e. the Graph subclasses provided by networkx) this can be worked around with a few overloads, one for Graph, one for DiGraph, for MultiGraph, etc:  ```python @overload def compose(G: DiGraph[X], H: DiGraph[Y]) -> DiGraph[Union[X,Y]]: ... @overload def compose(G: Graph[X], H: Graph[Y]) -> Graph[Union[X,Y]]: ... ``` they probably would need to be sorted with topological sort based on the type hierarchy of the `Graph` subclasses, otherwise mypy just takes the first signature that matches, and passing two DiGraphs and returning a DiGraph can be considered to have the (too broad) signature of `(G: Graph[X], H: Graph[Y]) -> Graph[Union[X,Y]]`. This doesn't type the cases where two different graph types are passed, or where a user has a custom subclass of `Graph` that would work fine with networkx runtime when passed to compose and return that type of graph again. But I think those cases are rare enough that they can fall under the caveat of "the runtime is a bit more flexible than the type annotations"
comment
> Convincing the networkx team that inline type annotations are a good idea  What is the current state regarding this? I created my stubs package nearly 3 years ago under the assumption that it would be a temporary workaround for me (and others) and a proof of concept to show that type annotations are useful. After all this time I am not even sure if the type stubs are still compatible with the current networkx API or if that drifted apart and I don't even know if there is tooling to check for that.  I still think that inline annotations are the only reasonable way for networkx annotations, but it's harder to muster up motivation to help out with this PR if it isn't clear that it will actually be merged.  @dschult You were so far the most vocal skeptic of the inline approach, but some of this has been over two years ago. Has this changed since? If you still have concerns, what specifically are they? 
comment
> I believe the most complete stub files are currently [here](https://github.com/fmagin/networkx-stubs).  @charmoniumQ  This isn't necessarily the case, most of this was simply generated with `stubgen` and it might be better to rerun `stubgen` on this PR to get stubfiles. IIRC `stubgen` allows extracting type annotations from inline annotations to stub files. Though with your recent PR to the stub files repo they might contain more than this networkx PR.   @dschult As far as I understood you actually have direct contact with undergrads with basic prior Python experience that are then reading the networkx code?  > the biggest difficulty is readability. One of the nice things about Python is that is was designed for people learning to program. The code is simple and elegant -- hiding many of the details about types and memory allocation and pointers that other languages focus on   This doesn't directly apply to networkx (because it doesn't have that many different classes), but I think it's really important for anyone writing code nowadays to understand the basic idea of types.    For me there are roughly two driving factors for investing effort into the networkx type annotations: 1. I believe that type annotations are an important part of any Python codebase (compared to Python Scripts) and I believe in the spirit of the FOSS ecosystem and want to contribute. 2. I want my IDE and type checker at work to know that iterating over a `DiGraph[T]` in the code means that each object is of type `T`.   > Stubs give the advantages of automatic IDE type checking while minimizing impacts on code readability.   > As far as reluctance for inline typing annotations, the biggest difficulty is readability. One of the nice things about Python is that is was designed for people learning to program. The code is simple and elegant -- hiding many of the details about types and memory allocation and pointers that other languages focus on. I think the notation and syntax are improving -- more importantly, people are learning how to make the annotations better. >  > But I think the reluctance is also deeper than that. For many years a selling point and design choice for python packages has been "duck-typing", where you don't check types. You try to make it quack and if it does, then you treat it like a duck. If Python code starts to look like C or Java code then we might as well be programming in C or Java -- which are often faster anyway because they are compiled. So there is a long history of phrases like "use hasattr, not isinstance". And the goal of writing code to accept any reasonable input is a reasonable goal.  These are personal anecdotes, but I have a few of them: Academic Python codebases written by people who don't think about type systems or aren't using properly configured IDEs tends to be pretty weirdly designed and hard to maintain. So I think there is a lot of value in getting people to actually think in terms of types more.  I have experienced this when porting https://github.com/seemoo-lab/internalblue to Python 3 (originally written as a master thesis project in Python 2), which was mostly passing around dicts instead of classes, using the infamous `from pwn import *`, and had type errors so obvious that PyCharm managed to find them even in the original code (like accidentally using the string `"false"` as a default argument for something that was supposed to be a bool, and was later checked with `if var`)  I have experienced this at work where, for example, someone wrote a larger analysis as part of a master thesis and just monkey patched new instance variables to an existing objects, then littered `hasattrs` all over the place.  I have seen this in a milder form with https://github.com/angr/angr which used some Python codepatterns that were basically impossible for an IDE to follow, because it was accessed via `AnalysesHub.AnalysisName` where the `AnalysesHub` has custom `__getattr__` implementation, that checked a dict of registered analyses. This meant that it was both impossible for an IDE to typecheck the arguments to an Analysis when it was used, and impossible for an IDE to find out where in the Code an Analysis was used, and I had to use regular text based search.  I think networkx itself isn't that prone to those failures specifically, but as far as I have understood there were a couple of changes to the code itself resulting from this PR because the code was weird in a way that made it impossible to type annotate, and that is often a bad sign for the code quality and readability itself.  Hence I think getting to people to think more about types is fairly beneficial for both people and codebases in the long term.    > The code I have seen with inline annotations requires a novice to learn a huge amount -- or else just try to ignore all the annotations at first. I'm hopeful that Python can find a way to ease the learning curve required to read code with annotations. But it also seems straight-forward, practical and much less dangerous than it used to be to keep the typing in stubs files.  Do you have specific experience with novices struggling with type annotations, or are you extrapolating from your experience with them? I am currently writing experiments in Python with Cognitive Science undergrads, and type annotations don't seem to be much of a problem. Especially for networkx where the type annotations are probably mostly "this is a Graph", "this is mapping between nodes". In my experience with networkx functions I wasn't familiar with before, most of the effort was figuring out the type signature for myself, so it became clear what the function needs, i.e. the whole "types as documentation" argument.   > I'd love to see this kind of energy around writing more network analysis functions. But there seem to be many people who feel more comfortable contributing type annotations rather than writing new code.  I have at least 2 graph algorithms in my codebase at work that I want to upstream at some point, but in my code I at least got to type annotate them as I saw fit. The two I can remember are a general postdominator graph algorithm and [this algorithm that is supposedly "kind of a special case of Tarjan’s path expression algorithm" ](https://math.stackexchange.com/questions/3584244/what-is-the-name-of-algorithm-that-generates-a-subgraph-given-a-subset-of-nodes). I genuinely think that getting type annotations going in networkx is more important, hence me investing my energy here, instead of graph algorithms directly.    > * it would be good to add a stub files version of typing as a PR. People can make suggestions and improvements similar to the work in this PR. We can try it out.  I agree with @charmoniumQ here, stub files are better than nothing and there are low hanging fruit like mypy knowing that iterating over a `Graph[T]` yields elements of type `T` and I am tired of manually annotating that in code that is using networkx.  > * We have been including type information in our doc-strings for a long time. It would be good to have tools that can check the doc_string type information against the inline or stub annotations.  A good place for this code is likely to be mypy. But other avenues for contribution are available or can be created. > * it would be good to improve the tools like mypy and others which work with code and annotations to allow people to see the code they want with annotations as they want. This includes: >    >   * merging stub files with code to get inline annotations. >   * splitting inline annotations into stub files and code files. >   * pulling type annotations out of numpy-style documentation and creating inline annotations (or stub files) >   * taking inline type annotations and putting that information into doc_strings. >   I agree with @danieleades concerning those points
comment
There was also a previous discussion about this in https://github.com/networkx/networkx/issues/2183 which I haven't seen mentioned yet.  I am also quite interested in type annotations for networkx and would be willing to work on this too. I started a `networkx-stub` package at https://github.com/fmagin/networkx-stubs/ which at least one person has already started extending with the intent to cover MultiGraphs. I can also vouch for the usefulness of type annotations in complex code that uses `networkx`, mostly in the context of program analysis. My main question is where the effort should be focused, i.e. is the sentiment still that the annotations belong in a separate `networkx-stubs` package like discussed in the previous issue, or is supporting Python 2 no longer a concern anymore, i.e. inline annotations are welcome? If the latter is the case there is still a decision to be made what Python version should at least be supported. The newer versions bring quite some useful features e.g. literal types [PEP 586](https://www.python.org/dev/peps/pep-0586/) requiring 3.8, class and instance variable annotations [PEP 526](https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations) requiring 3.6. My experience has been that 3.6 is a reasonable tradeoff between supporting older version and leveraging useful newer features, but networkx is a far larger project than others I have worked on so the requirements here might very well be different.  Concerning the questions above: > I can imagine this ballooning into a huge maintenance headache. Can you help me to understand the costs of such a change? Are there automated ways (like Travis-CI) to check what is annotated and are there automated ways to manage the collection of types we use?  With the right mypy parameters you could also only check for inconsistent annotations. Code that is added after the initial annotations and typing support could still be untyped as long as it doesn't violate any existing annotations. This would either imply an issue with the new code or the existing annotations, both something that should be caught by the CI. 
comment
According to https://stackoverflow.com/a/38078003/13220684 there is [typing.Hashable](https://docs.python.org/3/library/typing.html#typing.Hashable). `None` is only ever allowed if using `Optional`. So just `typing.Hashable` should be enough as far as I understand.
comment
> src and tests are not separated.  I think with a bit more complicated mypy config this could be worked around, you can specify different levels of strictness for different modules https://mypy.readthedocs.io/en/stable/config_file.html#examples Would be somewhat annoying, but not that painful I think.
comment
Thanks to @rhelmot my stubs have now been polished and [merged into typeshed](https://github.com/python/typeshed/pull/10544) and I will direct my future efforts there, until I get a very clear signal from the networkx team that they are willing to integrate in-line annotations.  One problem is that 3.2 now introduced a new code pattern that makes type annotating much more verbose and complicated https://github.com/python/typeshed/pull/10544#issuecomment-1776036652 I haven't looked into this, but this seems like a general pattern with networkx code: It is often written in a way that makes it fairly complicated to annotate with correct types. This basically always means that the exact behavior of the code is hard to reason about too, which is IMO a bad sign if it is widespread in a codebase that doesn't have very good reasons for this. But I haven't looked into this new change enough to form an opinion on the benefits of the change though.  I think the overall direction is starting to become clear: There is currently enough demand for and value in at least basic type annotations such that the wider community will create and maintain them, even without the cooperation of the networkx team itself. This demand is only growing, and I expect that more and more people will start to see the benefits.  I think this topic and discussion hinges on what networkx is trying to be: Should networkx be a library for mathematicians and researchers for graphs as the mathematical objects and their study? Or a library for computer scientists, software engineers and programmers that concerns itself with graphs as the widely useful data-structure as part of larger projects? Ideally it could be both, but currently it seems that it is focusing more on the former use-case (or a different one I am missing?), but due to ecosystem inertia, it is still widely used for the software use-case. But I'm personally starting to become motivated to switch to a library that has better support for type integrity checks and better runtime and memory performance.   
comment
> Even if we disagree, I think it's important to respect that NetworkX is "someone else's baby". We should be careful about pushing too hard—even if that pressure comes from our love for this project. We are, after all, guests here.  This is a really important point, and I think my previous comments didn't make it clear enough that I'm agreeing with this and they were written with this in mind. My enthusiasm is mostly for the general Python ecosystem, and less for specific projects, and for a long time networkx was the the obvious choice for a mature graph library in the Python ecosystem. Also projects like typeshed hadn't gained that much traction 3 years ago, so there was no good Schelling point where to put stubs besides the networkx project itself.  There is a genuine trade-off here, because if we put the stub files into the networkx repository as separate files, this still puts the burden of reviewing PRs on the networkx team itself. It also requires the networkx CI to support it, which is an even higher burden to setup and review, especially if the type annotations aren't in-line. I'm not putting my future efforts into the typeshed stubs because I think networkx doesn't want them, I'm doing this because I have the gut feeling that this is the better distribution of effort across the ecosystem, as long as the networkx project would only accept stubs.    > I feel like the best outcome would be a small, highly-performant, and fully-annotated graph structure library, and then a larger, separate library implementing a rich collection of algorithms on top of that. Basically I would propose that networkx split out the core graph data structures into a separate library for general use, and then continue tinkering away in a separate library that imports it as a dependency.  I don't think that's a good proposition, as I think it misunderstands what networkx and its core developers are focusing an. As per the README: "NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks."   This is a very different focus than e.g. "[rustworkx is] a high performance general purpose graph library for any Python application"!  Type annotations aren't really a big concern for the stated purpose of networkx. They are dealing with graphs as the abstract data structure, where the node types don't matter, and in that regard the types inside networkx are fairly simpel, and something that IDEs can probably infer well enough already.  Type annotations that cover the types inside the graphs are only big deal for a general purpose graph library. For a long time networkx has been effectively this in the Python ecosystem, but that has changed.  Nowadays, of the 4 libraries listed as [graph libraries on the Python wiki](https://wiki.python.org/moin/PythonGraphLibraries), networkx is the only one that _doesn't_ mention efficiency.  I think some of us were pushing for types in networkx in a bit too strong way, and I think it comes down to this conceptual mixup between a graph library and a  software project built for research on graphs. The use case of "small, highly-performant, and fully-annotated graph structure library" is something that other libraries like rustworkx try to achieve, networkx never had it as their stated goal to be a general purpose graph library, they just happened to end up in that position due to lack of a different option. But now with type annotations, I started to run into this conflict between these goals, and this means that I might have to migrate to new libraries like rustworkx. I always treated networkx as the go-to graph library in Python before, but this doesn't mean that it actually should be or wants to be. And we can't expect the core devs to help with that goal, if it comes as the detriment to their _actual_ goal.  
comment
Well, I just found this issue after an hour of confusing debugging why some package that requires networkx didn't properly install in PyPy. It required a `git blame` on the `requirements/default.txt` to find this issue and in that commit I found the instructions to just install it with `pip install decorator networkx --nodeps`  So there are definitely people affected by this, though I guess not much? Some clearer error that networkx doesn't fully support PyPy by default would really be nice for anyone else running into this, the errors that appear are really confusing
comment
Sometimes the GitHub search is just surprisingly horrible, but I hope that at least this post will make it easier to find.  The actual thing that fails is building scipy, specifically it fails with: `LookupError: https://files.pythonhosted.org/packages/bb/bb/944f559d554df6c9adf037aa9fc982a9706ee0e96c0d5beac701cb158900/scipy-1.7.0.tar.gz#sha256=998c5e6ea649489302de2c0bc026ed34284f531df89d2bdc8df3a0d44d165739`  This was weird und unspecific enough that we tried reproducing this on other machines first, which took some time. Tried finding out why scipy wasn't working with PyPy (because it should), but didn't find anything obvious. Then we started wondering why exactly scipy was even needed, realized that networkx was pulling it in, and I checked what changed with the networkx dependencies and ended up here.  The package I am using really just needs a solid graph data structure for Python, and I assume that there are various other projects that use networkx in this way. I don't see a clearly correct solution to this situation either, explicitly specifying `networkx[minimal]` as a dependency seems like the most elegant solution, but if that isn't working I am not sure what the better way would be.
comment
I do see a dilemma between "networkx as a pure python graph library" (which had nearly no dependencies previously) vs "networkx as a cutting edge library for graph analysis algorithms". One idea that comes to mind could be separating those concerns into separate packages, one for the basic data structure and algorithms that can be implemented in pure python with no further dependencies, and another one for research/scientific level analysis algorithms, that can pull in the typical ecosystem of scientific libraries. But that might be a non trivial amount of work and will need serious discussions about what the `networkx` package aims to provide.
comment
I am currently working on an (internal) codebase that strongly benefits from static typing which requires that at least the externally used interfaces for networkx(which we use a lot) are annotated.  This already proved fairly useful for development because it allows PyCharm to infer the types in expressions like `[ n for node in graph]`, immediately warns in cases of `graph.add_edge("foo", "bar")` when `graph` is a graph over integers, etc.  In my opinion the goal should not be that networkx is internally statically typed but that at least the common interfaces are annotated, so that IDEs and mypy can use it for projects that use networkx and type annotations.  I did not find any other public effort to create a -stub package for networkx, which is the only option if neither inline annotations nor separate .`pyi` files in the networkx package are acceptable, and started working on my own at https://github.com/fmagin/networkx-stubs . This is still heavily WIP and only covers external interfaces we use (and I have annotated so far). Furthermore I won't even guarantee that some annotations aren't outright wrong for some use cases other than mine, the networkx code style does not easily allow typing. Some of them are annotated, others I might have missed.  I hope this will serve as an example that this is in fact useful and saves others the work I already did. This _should_ also work for Python2, but I haven't tested this so far.  I would suggest to add this package to the networkx project at some point, mark it as WIP/experimental and encourage PRs from anyone with real world projects. I'd rather not have it published on PyPI or Typeshed until it I have gotten feedback from others using it. This allows anyone requiring this to still easily find it, installing as a Python package is still simple (and is enough to be picked up by mypy and PyCharm), but does not raise expectations that networkx is fully typed.  
comment
I'd argue that this issue is the more appropriate place for discussion and should be reopened or recreated so any further discussion happens here. Searching for "PEP 484" in the issues is the way that I'd expect most people interested in type annotation will use to find the relevant issue/discussion. Or we could open a new dedicated issue referencing the previous discussion and detailing the next actions that are needed.  The discussion in the PR #4014 concluded, if I understand your last comment correctly @stefanv , that inline annotations are the way to go forward, but the CI setup for basic type checking would probably be required before such PRs will be merged.  So my question is: Do we want a dedicated issue now that PEP 484 type annotations are a tractable issue that PRs are welcome for or do we want to reuse this issue? If you find a new issue reasonable I'll reread the discussion in the PR and the issue and summarize it so it is easier for new contributors to understand the general approach and goals. 
