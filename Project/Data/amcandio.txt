issue
Adding @amcandio as contributor#TITLE_END#https://github.com/networkx/networkx/commits?author=amcandio
issue
Adding Dijkstra's algo specific doc#TITLE_END#Dijkstra’s algorithm was only mentioned within the general shortest paths documentation. This PR provides a more detailed reference page for Dijkstra's  under `doc/reference/algorithms/`. We update the shortest path documentation section to refer to link to this new page so it can be discovered.   
issue
Adding floating point considerations to tutorial#TITLE_END### Floating Point Considerations  As discussed in previous issues and PRs (e.g., #4972, #4592, #8316), users sometimes face unexpected results when using floating point values such as edge weights or capacities. These issues are often caused by rounding errors, not bugs in the algorithms.  The moment floating point numbers are used, all results become approximate. So to avoid confusion, we update tutorial to clarify these considerations.
issue
Improving shortest paths docs when there is no path between source and target#TITLE_END#Improving shortest paths docs when there is no path between specified source and target  Fixes https://github.com/networkx/networkx/issues/8326 
issue
Improving connected module docs#TITLE_END#Improving docus for connected module. I focused on including definition, corner cases and time-complexity of implementation.
issue
Add benchmark suite for shortest path algorithms on weighted graphs#TITLE_END#This PR introduces a new benchmarking suite for evaluating shortest path algorithms on weighted graphs. This benchmark was used to evaluate https://github.com/networkx/networkx/pull/8023. It includes the following changes:  ### Graphs added  - **`WeightedGraphBenchmark` class**:   - Benchmarks `networkx.single_source_dijkstra` on various weighted graphs.   - Supports both `path_graph` (sizes: 1,000–20,000) and `erdos_renyi_graph` (sizes: 10, 100, 1000; probabilities: 0.1, 0.5, 0.9).   - Graphs are generated with consistent edge weights using a fixed random seed for reproducibility.  ### Utilities added  - **Graph utility functions in `benchmarks/utils.py`**:   - `weighted_graph`: Utility to assign random integer weights to edges.   - `benchmark_name_from_func_call`: Generates human-readable graph names from function calls for better benchmark output labeling.  ### Example  ``` (networkx-dev) bash-3.2$ asv compare 092f50e5 a1575792 Couldn't load asv.plugins._mamba_helpers because No module named 'libmambapy'  All benchmarks:  | Change   | Before [092f50e5]             | After [a1575792]           |   Ratio | Benchmark (Parameter)                                                                                                                        | |----------|-------------------------------|----------------------------|---------|----------------------------------------------------------------------------------------------------------------------------------------------| | -        | 124±2μs                       | 107±0.5μs                  |    0.87 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(100)')                      | | -        | 2.50±0.1ms                    | 1.26±0ms                   |    0.5  | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(1000)')                     | | -        | 306±8ms                       | 15.0±0.02ms                |    0.05 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(10000)')                    | | -        | 1.19±0.01s                    | 31.6±0.3ms                 |    0.03 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(20000)')                    | |          | 3.51±0.01μs                   | 3.58±0.02μs                |    1.02 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 10, 0.1, seed=42)')   | |          | 8.17±0.1μs                    | 7.94±0.01μs                |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 10, 0.5, seed=42)')   | |          | 9.36±0.09μs                   | 8.74±0.01μs                |    0.93 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 10, 0.9, seed=42)')   | |          | 162±0.3μs                     | 156±0.4μs                  |    0.96 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 100, 0.1, seed=42)')  | |          | 574±4μs                       | 549±0.2μs                  |    0.96 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 100, 0.5, seed=42)')  | |          | 546±30μs                      | 503±10μs                   |    0.92 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 100, 0.9, seed=42)')  | |          | 12.0±0.06ms                   | 11.6±0.4ms                 |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 1000, 0.1, seed=42)') | |          | 82.4±1ms                      | 83.7±2ms                   |    1.02 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 1000, 0.5, seed=42)') | |          | 53.8±4ms                      | 52.2±3ms                   |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 1000, 0.9, seed=42)') | | -        | 58.0±1μs                      | 50.4±0.2μs                 |    0.87 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 100)')                      | | -        | 1.22±0.06ms                   | 484±5μs                    |    0.4  | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 1000)')                     | | -        | 144±8ms                       | 4.91±0.05ms                |    0.03 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 10000)')                    | | -        | 527±8ms                       | 9.82±0.04ms                |    0.02 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 20000)')                    | ```
issue
Making weakly connected logic consistent with connected logic#TITLE_END#This is just a follow up from https://github.com/networkx/networkx/pull/8266 to make weakly connected code consistent. Same as https://github.com/networkx/networkx/pull/6346 suggested.  There is something to be said about code duplication. We could add a private helper function that we call from both weakly connected and connected functions. If people would like that I can address in a follow up PR.
issue
Optimizing Dijkstra: reducing dict lookups (up to 10% faster)#TITLE_END### Optimize `single_source_dijkstra_path_length` by reducing redundant dictionary lookups  ### Summary This PR refactors Dijkstra loops to avoid redundant dictionary lookups when checking distances and visited nodes.   Instead of accessing `dist[u]` or `seen[u]` multiple times it stores the result of `dict.get()` in a local variable and reuses it.   This potentially saves hash computations and  equality checks, especially when: - **Nodes are strings**: Python caches string hashes, so hashing is cheap, but equality checks on long strings are avoided. - **Nodes are objects with custom, uncached hashes**: both hash computation and equality checks can be expensive, so avoiding duplicate lookups saves time. - **Nodes are integers**: hashes are trivial, so gains are minimal here.  ### Benchmark Results Benchmarks were run using the suite from [#8059](https://github.com/networkx/networkx/pull/8059), both with integer nodes and with artificially long string node labels. Benchmark was extended to call `nx.single_source_dijkstra_path_length` and to test with long strings following transformation was used:  ``` self.G = nx.relabel_nodes(self.G, {x: f"{'node-prefix_' * 10}{x}" for x in self.G}) ```  Even though Ratio is higher than 1 in some benchmarks, there is no conclusive increase after looking at variability of measurements.   #### Integer Nodes Performance is essentially unchanged or slightly improved (within noise), as expected for cheap hashes and equality checks.  | Change   | Before [a25405fc]    | After [8a2cb3a8]   | Ratio   | Benchmark (Parameter)                                                                                                                               | |----------|-----------------------------------------------|-------------------------------------------------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------| |          | 127±0.3μs                                     | 124±0.3μs                                       | 0.98    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(100)')                      | |          | 1.50±0.01ms                                   | 1.50±0.01ms                                     | 1.00    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(1000)')                     | |          | 17.9±0.04ms                                   | 17.7±0.08ms                                     | 0.99    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(10000)')                    | |          | 40.2±0.2ms                                    | 39.0±0.7ms                                      | 0.97    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(20000)')                    | |          | 5.60±0.1μs                                    | 5.40±0.01μs                                     | 0.96    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 10, 0.1, seed=42)')   | |          | 10.2±0.08μs                                   | 9.82±0.02μs                                     | 0.96    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 10, 0.5, seed=42)')   | |          | 15.9±0.02μs                                   | 15.0±0.03μs                                     | 0.94    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 10, 0.9, seed=42)')   | |          | 184±0.3μs                                     | 175±0.3μs                                       | 0.95    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 100, 0.1, seed=42)')  | |          | 683±6μs                                       | 677±40μs                                        | 0.99    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 100, 0.5, seed=42)')  | |          | 1.16±0ms                                      | 1.08±0ms                                        | 0.94    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 100, 0.9, seed=42)')  | |          | 19.6±2ms                                      | 15.2±0.08ms                                     | ~0.77   | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 1000, 0.1, seed=42)') | |          | 110±4ms                                       | 105±5ms                                         | 0.95    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 1000, 0.5, seed=42)') | |          | 215±10ms                                      | 198±3ms                                         | 0.92    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 1000, 0.9, seed=42)') | |          | 44.6±0.2μs                                    | 43.8±0.1μs                                      | 0.98    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 100)')                      | |          | 430±10μs                                      | 436±3μs                                         | 1.01    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 1000)')                     | |          | 4.26±0.07ms                                   | 4.16±0.04ms                                     | 0.98    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 10000)')                    | |          | 8.56±0.1ms                                    | 8.41±0.07ms                                     | 0.98    | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 20000)')                    |   #### Long String Nodes When node labels are long strings, hashing is still cached, but avoiding duplicate lookups saves equality comparisons. This leads to more noticeable improvements.   | Change   | Before [a25405fc]    | After [8a2cb3a8]   | Ratio   | Benchmark (Parameter)                                                                                                                               | |----------|-----------------------------------------------|-------------------------------------------------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------| |          | 132±1μs                                       | 128±0.7μs                                       |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(100)')                      | |          | 1.61±0.01ms                                   | 1.53±0ms                                        |    0.95 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(1000)')                     | |          | 19.1±0.09ms                                   | 18.5±0.05ms                                     |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(10000)')                    | |          | 41.1±2ms                                      | 39.6±0.2ms                                      |    0.96 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('dijkstra_relaxation_worst_case(20000)')                    | |          | 5.52±0.04μs                                   | 5.37±0.06μs                                     |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 10, 0.1, seed=42)')   | |          | 10.7±0.05μs                                   | 9.90±0.08μs                                     |    0.93 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 10, 0.5, seed=42)')   | | -        | 16.7±0.4μs                                    | 15.2±0.02μs                                     |    0.91 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 10, 0.9, seed=42)')   | |          | 202±6μs                                       | 184±0.5μs                                       |    0.91 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 100, 0.1, seed=42)')  | |          | 759±30μs                                      | 694±20μs                                        |    0.92 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 100, 0.5, seed=42)')  | | -        | 1.29±0.07ms                                   | 1.14±0ms                                        |    0.89 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 100, 0.9, seed=42)')  | |          | 18.2±0.4ms                                    | 17.8±0.4ms                                      |    0.98 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 1000, 0.1, seed=42)') | |          | 111±4ms                                       | 107±2ms                                         |    0.96 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 1000, 0.5, seed=42)') | |          | 227±5ms                                       | 244±20ms                                        |    1.08 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, gnp_random_graph, 1000, 0.9, seed=42)') | |          | 49.8±0.6μs                                    | 46.6±0.6μs                                      |    0.93 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 100)')                      | |          | 490±3μs                                       | 447±2μs                                         |    0.91 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 1000)')                     | |          | 5.08±0.07ms                                   | 4.72±0.08ms                                     |    0.93 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 10000)')                    | |          | 10.3±0.05ms                                   | 9.49±0.07ms                                     |    0.92 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra_length('weighted_graph(42, path_graph, 20000)')                    | 
issue
Optimizing is_connected#TITLE_END### The change  `is_reachable` implementation relies on counting amount of elements of the connected component returned by `_plain_bfs(G, n, arbitrary_element(G)`. Since `_plain_bfs` already returns a set, we can just call `len` which is faster.  ``` -    return sum(1 for node in _plain_bfs(G, n, arbitrary_element(G))) == len(G) +    return len(_plain_bfs(G, n, arbitrary_element(G))) == n ```  Extra: a nit renaming unused variable `cc` to `_`.  ### Quick benchmarking:  ```python import networkx as nx import timeit  n = 30_000 G = nx.path_graph(n)  def check_connected():     nx.is_connected(G)  number_of_runs = 100 total_time = timeit.timeit(check_connected, number=number_of_runs) print(f"Average time over {number_of_runs} runs: {total_time / number_of_runs:.6f} seconds") ```  #### Before: ``` Average time over 100 runs: 0.006738 seconds ``` #### After: ``` Average time over 100 runs: 0.005971 seconds ```   Which is 11% faster on graphs with multiple nodes.
issue
Optimizing Dijkstra's path construction for all targets case#TITLE_END#Same approach of https://github.com/networkx/networkx/pull/8023, now for all target case, result from benchmark of https://github.com/networkx/networkx/pull/8059.  We can see noticeable improvements for adversarial graphs at the expense of extra overhead on small and "simple" graphs.  ### Results: | Change   | Before [069be4c5] <weighted_benchmarks2~1>   | After [3438a8a2] <weighted_benchmarks>   | Ratio   | Benchmark (Parameter)                                                                                                             | |----------|----------------------------------------------|------------------------------------------|---------|-----------------------------------------------------------------------------------------------------------------------------------| | -        | 30.0±0.9μs                                   | 27.0±0.05μs                              | 0.90    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('dijkstra_relaxation_worst_case(10)')                       | | -        | 3.93±0ms                                     | 3.37±0.04ms                              | 0.86    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('dijkstra_relaxation_worst_case(100)')                      | | -        | 1.11±0.08s                                   | 758±20ms                                 | 0.69    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('dijkstra_relaxation_worst_case(1000)')                     | |          | 6.97±0.02μs                                  | 7.43±0.08μs                              | 1.07    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 10, 0.1, seed=42)')   | |          | 12.0±0.03μs                                  | 12.2±0.2μs                               | 1.02    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 10, 0.5, seed=42)')   | |          | 17.9±0.02μs                                  | 17.6±0.4μs                               | 0.98    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 10, 0.9, seed=42)')   | |          | 200±0.5μs                                    | 193±0.8μs                                | 0.96    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 100, 0.1, seed=42)')  | | -        | 740±20μs                                     | 672±10μs                                 | 0.91    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 100, 0.5, seed=42)')  | |          | 1.18±0ms                                     | 1.12±0.02ms                              | 0.95    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 100, 0.9, seed=42)')  | |          | 16.5±0.3ms                                   | 16.2±2ms                                 | 0.98    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 1000, 0.1, seed=42)') | |          | 118±3ms                                      | 96.5±0.9ms                               | ~0.82   | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 1000, 0.5, seed=42)') | |          | 211±10ms                                     | 212±10ms                                 | 1.00    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, gnp_random_graph, 1000, 0.9, seed=42)') | |          | 62.7±0.7μs                                   | 66.7±1μs                                 | 1.06    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, path_graph, 100)')                      | |          | 1.22±0.02ms                                  | 1.26±0.01ms                              | 1.03    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, path_graph, 1000)')                     | |          | 145±4ms                                      | 136±4ms                                  | 0.94    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, path_graph, 10000)')                    | |          | 603±80ms                                     | 528±5ms                                  | ~0.88   | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path_source('weighted_graph(42, path_graph, 20000)')                    |
issue
Adding shortest-paths documentation#TITLE_END#After working on https://github.com/networkx/networkx/pull/8169 I realized that the whole Shortest Path section lacked some introduction and context.  In this PR I extend the docs with some definitions, examples and time-complexity of the different supported algorithms.  Follow-up sections I was thinking we can add: - Notes on negative weights and cylces - Translating path from list of nodes into list of edges  ### Render  <img width="1123" height="1316" alt="image" src="https://github.com/user-attachments/assets/0273505b-f406-4c91-8376-0599234474f5" /> <img width="1140" height="934" alt="image" src="https://github.com/user-attachments/assets/afa1245b-7675-459c-b05e-23e96a00bc5a" />  
issue
Bidirectional dijkstra optimization: from 1.1x to 25x faster#TITLE_END#This PR improves the bi-directional Dijkstra algorithm used for point-to-point shortest-path queries in NetworkX. This algorithm sits at the core of NetworkX [shortest-path simplified interface](https://networkx.org/documentation/stable/reference/algorithms/shortest_paths.html). Every calls to `nx.shortest_path` method specifying both source, target and weight relies on this algorithm.   Currently, this implementation does not benefit from optimizations introduced in https://github.com/networkx/networkx/pull/8191 and https://github.com/networkx/networkx/pull/8023 for regular Dijkstra (unidirectional).  In this PR, I introduce a **Path-construction optimization:** which prevents the algorithm from constructing paths to all visited nodes, computing only the path to the target.  ### Results  Benchmarks from https://github.com/networkx/networkx/pull/8059 show improvements ranging from ~10% faster to up to 25× faster in corner cases where the shortest path spans multiple nodes.  | Change   | Before [50d0e03e] <main>   | After [55fb31db] <bidirectional_dijkstra_optimization>   | Ratio   | Benchmark (Parameter)                                                                                                      | |----------|----------------------------|----------------------------------------------------------|---------|----------------------------------------------------------------------------------------------------------------------------| | -        | 186±0.2μs                  | 146±0.4μs                                                | 0.78    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('dijkstra_relaxation_worst_case(100)')                      | | -        | 2.83±0.09ms                | 1.71±0.02ms                                              | 0.60    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('dijkstra_relaxation_worst_case(1000)')                     | | -        | 192±4ms                    | 21.4±0.6ms                                               | 0.11    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('dijkstra_relaxation_worst_case(10000)')                    | | -        | 760±4ms                    | 45.8±0.3ms                                               | 0.06    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('dijkstra_relaxation_worst_case(20000)')                    | |          | 4.25±0.01μs                | 4.02±0.01μs                                              | 0.95    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 10, 0.1, seed=42)')   | | -        | 10.8±0.09μs                | 9.31±0.3μs                                               | 0.86    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 10, 0.5, seed=42)')   | | -        | 10.9±0.01μs                | 9.31±0.03μs                                              | 0.85    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 10, 0.9, seed=42)')   | | -        | 129±0.5μs                  | 106±2μs                                                  | 0.83    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 100, 0.1, seed=42)')  | | -        | 403±4μs                    | 335±6μs                                                  | 0.83    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 100, 0.5, seed=42)')  | | -        | 373±0.4μs                  | 306±1μs                                                  | 0.82    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 100, 0.9, seed=42)')  | | -        | 3.07±0.01ms                | 2.40±0ms                                                 | 0.78    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 1000, 0.1, seed=42)') | | -        | 20.6±0.3ms                 | 18.0±0.8ms                                               | 0.87    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 1000, 0.5, seed=42)') | |          | 17.2±1ms                   | 15.2±0.3ms                                               | ~0.88   | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, gnp_random_graph, 1000, 0.9, seed=42)') | | -        | 69.1±2μs                   | 58.9±1μs                                                 | 0.85    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, path_graph, 100)')                      | | -        | 965±10μs                   | 537±4μs                                                  | 0.56    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, path_graph, 1000)')                     | | -        | 82.0±2ms                   | 5.43±0.2ms                                               | 0.07    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, path_graph, 10000)')                    | | -        | 297±6ms                    | 11.5±0.5ms                                               | 0.04    | benchmark_algorithms.WeightedGraphBenchmark.time_shortest_path('weighted_graph(42, path_graph, 20000)')                    | 
issue
minimum_node_cut not handling complete graphs correctly#TITLE_END#As a follow up of https://github.com/networkx/networkx/issues/7994 I put up a quick property-based test based on in-the-works framework https://github.com/networkx/networkx/pull/7981.  ``` import networkx as nx from hypothesis import strategies as st from networkx.hypothesis import graph_st from hypothesis import given  flow_funcs = [     flow.boykov_kolmogorov,     flow.dinitz,     flow.edmonds_karp,     flow.preflow_push,     flow.shortest_augmenting_path, ]  def _random_connected_graph(n, prob, seed):     return nx.compose(         nx.random_labeled_tree(n, seed=seed),         nx.erdos_renyi_graph(n, prob, seed=seed),     )  @given(     graph_st(         _random_connected_graph,         n=st.integers(4, 10),         prob=st.floats(0, 1)     ),     st.one_of([st.just(f) for f in flow_funcs]), ) def test_random_connected_graph(G, flow_func):     node_cut = nx.minimum_node_cut(G, flow_func=flow_func)     H = G.copy()     H.remove_nodes_from(node_cut)     assert len(node_cut) == len(G) or not nx.is_connected(H) ```  Which fails with the following error: ``` _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  G = <networkx.classes.graph.Graph object at 0x7f0bd13a5e50>, flow_func = <function boykov_kolmogorov at 0x7f0c1cb49620>      @given(         graph_st(             _random_connected_graph,             n=st.integers(4, 10),             prob=st.floats(0, 1)         ),         st.one_of([st.just(f) for f in flow_funcs]),     )     def test_random_connected_graph(G, flow_func):         node_cut = nx.minimum_node_cut(G, flow_func=flow_func)         H = G.copy()         H.remove_nodes_from(node_cut) >       assert len(node_cut) == len(G) or not nx.is_connected(H) E       assert (3 == 4 or not True) E        +  where 3 = len({1, 2, 3}) E        +  and   4 = len(<networkx.classes.graph.Graph object at 0x7f0bd13a5e50>) E        +  and   True = <function is_connected at 0x7f0c1cd13ba0>(<networkx.classes.graph.Graph object at 0x7f0bd13e0a50>) E        +    where <function is_connected at 0x7f0c1cd13ba0> = nx.is_connected E       Falsifying example: test_random_connected_graph( E           G=nx.from_edgelist([(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]), E           flow_func=boykov_kolmogorov, E       ) ```  ### Current Behavior  All node cuts is considering n-1 nodes of a K_n as a valid cut.  ### Expected Behavior  In a complete graph there are no node cuts, so it should either return all nodes or fail  ### Steps to Reproduce  See description
issue
Testing sentinel-node trick#TITLE_END#Follow up from https://github.com/networkx/networkx/pull/8169 to test sentinel node trick works for all shortest paths algorithms supported by NetworkX
issue
Adding Notes on Multi-Target Shortest Path Queries#TITLE_END#### Summary  This is a follow up from discussion on https://github.com/networkx/networkx/issues/703. It adds documentation notes to the `shortest_paths.rst` file explaining how to perform **multi-target shortest path queries** in NetworkX using a sentinel node trick. While NetworkX does not currently provide a built-in method for computing the shortest path from a source to the *nearest* of several targets, the documented technique enables users to efficiently perform such queries using existing shortest path algorithms.  ### Motivation  Multi-target queries—such as finding the nearest facility, emergency center, or pickup point—are common in real-world applications. This note provides guidance on how to implement these queries in NetworkX using an elegant and general approach.  ### Rendering  <img width="797" height="348" alt="image" src="https://github.com/user-attachments/assets/be8c1bfa-b984-4f9a-8558-781084f56d76" /> <img width="789" height="600" alt="image" src="https://github.com/user-attachments/assets/57238d44-019e-40e3-8a4d-e491d859df78" /> <img width="596" height="753" alt="image" src="https://github.com/user-attachments/assets/f11f0a70-7a73-40b4-be40-2a89dca3a0e5" />   ### Validations  This test-case is passing and I can send in a separate PR to ease reviewing:  ```python      def test_sentinel_trick_all_algorithms(self):          def reconstruct_path(pred, source, target):             path = [target]             while path[-1] != source:                 path.append(pred[path[-1]])             return list(reversed(path))          # Build the test graph inline         G = nx.Graph()         G.add_edge("A", "B", weight=1)         G.add_edge("B", "C", weight=1)         G.add_edge("C", "D", weight=1)         G.add_edge("D", "E", weight=1)          source = "A"         targets = {"C", "D", "E"}         expected_target = "C"  # A-B-C is closest          sentinel = "_sentinel_"         G.add_node(sentinel)         for t in targets:             G.add_edge(t, sentinel, weight=0)          # shortest_path: Dijkstra (default)         path = nx.shortest_path(G, source=source, target=sentinel, weight="weight")         assert path[-2] == expected_target          # shortest_path: Bellman-Ford         path = nx.shortest_path(G, source=source, target=sentinel, weight="weight", method="bellman-ford")         assert path[-2] == expected_target          # shortest_path: Unweighted (BFS)         path = nx.shortest_path(G, source=source, target=sentinel, weight=None)         assert path[-2] == expected_target          # bidirectional_dijkstra         _, path = nx.bidirectional_dijkstra(G, source, sentinel, weight="weight")         assert path[-2] == expected_target          # goldberg_radzik         pred, _ = nx.goldberg_radzik(G, source, weight="weight")         path = reconstruct_path(pred, source, sentinel)         assert path[-2] == expected_target          # astar_path with zero heuristic         path = nx.astar_path(G, source, sentinel, heuristic=lambda u, v: 0, weight="weight")         assert path[-2] == expected_target          # johnson (all-pairs shortest paths)         paths = nx.johnson(G, weight="weight")         assert paths[source][sentinel][-2] == expected_target          # floyd_warshall_predecessor_and_distance         pred, _ = nx.floyd_warshall_predecessor_and_distance(G, weight="weight")         path = reconstruct_path(pred[source], source, sentinel)         assert path[-2] == expected_target ``` 
issue
Optimizing Dijkstra's paths to target (~50x faster for graphs with multiple-hops shortest path)#TITLE_END#### Summary  Optimize Dijkstra's algorithm when a single `target` is specified by avoiding full path reconstruction for all nodes.  ### Motivation  In the current implementation of `_dijkstra_multisource`, when the `paths` argument is provided, paths are computed and stored for all reachable nodes. However, if only a specific `target` node is of interest, this can be wastefully expensive.  This change avoids storing all paths when only a `target` is specified, and instead reconstructs the path to the `target` at the end using the `pred` dictionary, which is much cheaper to maintain.  ### Changes  - Skip path storage during the main loop if only a specific `target` is requested. - Use `pred` (predecessor map) to reconstruct the path to `target` at the end. - Add a lightweight reconstruction loop to build `paths[target]` from `pred`.  ### Performance  This change reduces memory usage and computation time when: - A `target` is specified. - `paths` is requested. - There is no need to compute all paths from the source(s) to every reachable node.  When a specific `target` node is provided, the original implementation constructs full paths to **all** reachable nodes using `paths[v] + [u]` on each edge relaxation. This adds an extra cost of `O(n * L)`, where `n` is the number of reachable nodes and `L` is the average path length, due to repeated list copying. By skipping full path construction during the main loop and reconstructing only the path to `target` at the end , we reduce the path-building cost to just `O(L)`. This optimization is particularly noticeable in graphs where the shortest path to the `target` has many hops (especially in the worst case where `L = n`).   ### Notes  - The `pred` dictionary is now always initialized when `target` and `paths` are specified (if not already provided), as it's required for final path reconstruction. - This change preserves existing behavior and output structure.  No public API changes are introduced.  ### Results  Optimization adds the most value when the shortest paths to the target has many hops. In the case of the line graph of length 10_000, computing the source from node 0 to node 999 gets ~27x faster.  ```python import networkx as nx import timeit   REPEATS = 100   def generate_graphs():     return {"line_10000": nx.path_graph(10_000)}  def time_dijkstra(G):     return min(timeit.timeit(lambda: nx.single_source_dijkstra(G, 0, target=len(G)-1), number=1) for _ in range(REPEATS))  for name, G in generate_graphs().items():     print(f"{name}: min time over {REPEATS} runs = {time_dijkstra(G):.6f} sec")    ```  #### Without optimization ``` line_10000: min time over 100 runs = 0.408241 sec ```  #### With optimization ``` line_10000: min time over 100 runs = 0.014789 sec ```  ### Benchmarking results  Run used it `asv` command with a custom benchmark. Benchmarking for shortest-paths is added in https://github.com/networkx/networkx/pull/8059 to not increase the scope of this one too much.  Results showed that performance doesn't significantly change for most graphs in benchmark but significantly improve s for paths with long shortest path (such as the path graph). In line graphs of 20000 nodes, new implementation is 50 times faster.  ``` (networkx-dev) bash-3.2$ asv compare 092f50e5 a1575792 Couldn't load asv.plugins._mamba_helpers because No module named 'libmambapy'  All benchmarks:  | Change   | Before [092f50e5]             | After [a1575792]           |   Ratio | Benchmark (Parameter)                                                                                                                        | |----------|-------------------------------|----------------------------|---------|----------------------------------------------------------------------------------------------------------------------------------------------| | -        | 124±2μs                       | 107±0.5μs                  |    0.87 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(100)')                      | | -        | 2.50±0.1ms                    | 1.26±0ms                   |    0.5  | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(1000)')                     | | -        | 306±8ms                       | 15.0±0.02ms                |    0.05 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(10000)')                    | | -        | 1.19±0.01s                    | 31.6±0.3ms                 |    0.03 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('dijkstra_relaxation_worst_case(20000)')                    | |          | 3.51±0.01μs                   | 3.58±0.02μs                |    1.02 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 10, 0.1, seed=42)')   | |          | 8.17±0.1μs                    | 7.94±0.01μs                |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 10, 0.5, seed=42)')   | |          | 9.36±0.09μs                   | 8.74±0.01μs                |    0.93 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 10, 0.9, seed=42)')   | |          | 162±0.3μs                     | 156±0.4μs                  |    0.96 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 100, 0.1, seed=42)')  | |          | 574±4μs                       | 549±0.2μs                  |    0.96 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 100, 0.5, seed=42)')  | |          | 546±30μs                      | 503±10μs                   |    0.92 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 100, 0.9, seed=42)')  | |          | 12.0±0.06ms                   | 11.6±0.4ms                 |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 1000, 0.1, seed=42)') | |          | 82.4±1ms                      | 83.7±2ms                   |    1.02 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 1000, 0.5, seed=42)') | |          | 53.8±4ms                      | 52.2±3ms                   |    0.97 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, gnp_random_graph, 1000, 0.9, seed=42)') | | -        | 58.0±1μs                      | 50.4±0.2μs                 |    0.87 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 100)')                      | | -        | 1.22±0.06ms                   | 484±5μs                    |    0.4  | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 1000)')                     | | -        | 144±8ms                       | 4.91±0.05ms                |    0.03 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 10000)')                    | | -        | 527±8ms                       | 9.82±0.04ms                |    0.02 | benchmark_algorithms.WeightedGraphBenchmark.time_weighted_single_source_dijkstra('weighted_graph(42, path_graph, 20000)')                    | ```
issue
Add function bfs_labeled_edges to docs#TITLE_END#Was looking for this method on a Google search and struggled a bit because it was missing in the docs.  Should we have a mechanism to prevent this? Unless some of them are hidden on purpose and I'm missing some historical context.
issue
Adding an example on how to extend NetworkX with sorted graphs#TITLE_END#This PR introduces a minimal example showing how to extend NetworkX’s `Graph` class to achieve sorted iteration order over nodes and edges by overriding the underlying dictionary factories with a simple `SortedDict` implementation.  It clarifies in the docs that base NetworkX graphs do **not** guarantee ordering by node value, but extensions like this can provide predictable sorted iteration if nodes are comparable.  This example is a simple, not performance-optimized approach; for more efficient sorted data structures, users are encouraged to explore the [sortedcontainers](https://pypi.org/project/sortedcontainers) library.  This PR aims to provide users a straightforward pattern for customizing NetworkX graph data structures to support sorted iteration. 
issue
Girvan newman optimization#TITLE_END#### Summary  This PR optimizes the `girvan_newman` community detection algorithm in NetworkX.  The Girvan-Newman method is known to be computationally expensive, and users have reported performance concerns: - [StackOverflow: Why is the Girvan-Newman algorithm in NetworkX so slow?](https://stackoverflow.com/questions/62951320/why-is-the-girvan-newman-algorithm-in-networkx-so-slow) - [Issue #7992: Improve runtime of `girvan_newman()` function](https://github.com/networkx/networkx/issues/7992)  In [#7992](https://github.com/networkx/networkx/issues/7992), two optimization opportunities were identified: 1. **Cache the number of edges** and update it incrementally after every edge removal. 2. **Operate on one graph per connected component** to allow better caching of edge betweenness centrality.  This PR implements the **first optimization**: the number of edges is now cached and updated incrementally.   The **second optimization** is not implemented here because it would require a deeper refactoring: the current method accepts a `most_valuable_edge` function that operates on the **full graph**, making per-component caching of betweenness centrality non-trivial.  ### Performance  Benchmarks comparing current and optimized versions (averaged over 100 runs):  | Graph Type                   | Current Time/Call (s) | Optimized Time/Call (s) | Speedup | |-------------------------------|-----------------------|-------------------------|---------| | Complete Graph (n=10)         | 0.016050               | 0.015241                 | 1.05×   | | Complete Graph (n=20)         | 0.170338               | 0.149063                 | 1.14×   | | G(n=50, p=0.1)                | 1.068046               | 1.092481                 | 0.98×   | | G(n=50, p=0.2)                | 4.944922               | 4.612656                 | 1.07×   |   Performance improvements are clear for larger or denser graphs, and small changes for easier graphs are inconclusive and likely due to normal benchmark variability. Speedups range between ~0–14% depending on the graph structure.  ### Benchmarking Code  The following code was used to measure runtimes:  ```python import timeit  setup = "import networkx as nx"  benchmarks = [     ("Complete Graph (n=10)", "list(nx.community.girvan_newman(nx.complete_graph(10)))", 1000),     ("Complete Graph (n=20)", "list(nx.community.girvan_newman(nx.complete_graph(20)))", 100),     ("G(n=50, p=0.1)", "list(nx.community.girvan_newman(nx.fast_gnp_random_graph(50, p=0.2, seed=1)))", 100),     ("G(n=50, p=0.2)", "list(nx.community.girvan_newman(nx.fast_gnp_random_graph(50, p=0.5, seed=1)))", 100), ]  for label, stmt, c in benchmarks:     duration = timeit.timeit(stmt, setup=setup, number=c)     per_call = duration / c     print(f"{label:<30} | Total time: {duration:.4f}s | Time per call: {per_call:.6f}s") 
issue
Improve Performance of Tree Isomorphism and Center Calculation #TITLE_END#### Improve Performance of Tree Isomorphism and Center Calculation    When working with https://github.com/networkx/networkx/pull/7945 I tried running tree_isomorphism for big (over 1000 nodes) path graphs and realized method was pretty slow even though docs claimed time complexity of ``O(n*log(n))``. After diving deep I realized center calculation was not leveraging the fact input graph was a tree, where we can use specialized algorithm with better time complexity.  ## Summary   This PR optimizes the time complexity of two key algorithms in NetworkX:    1. **Tree Center Calculation** (`_tree_center`):      - Replaces the previous approach (which involved all-pairs shortest path computations) with an iterative leaf-removal method.      - **Time complexity improvement**: **O(N² log N) → O(N)**.      - Updates the `center` function to use `_tree_center` when applicable.    2. **Tree Isomorphism** (`tree_isomorphism`):      - Fixes an incorrect claim in the documentation. The current implementation previously stated:        > "This runs in ``O(n*log(n))`` time for trees with ``n`` nodes."      - However, the actual time complexity was higher due to the expensive center computation.      - Now, with the optimized `_tree_center`, the overall complexity is reduced to **O(N log N)**.     ## Performance Benchmark   We measured the performance improvement using `nx.center(nx.path_graph(5000))`:    - **Without optimization**: `Average execution time: 7.418421 seconds`   - **With optimization**: `Average execution time: 0.007979 seconds`   - **Speedup**: ~1000× faster 🚀    ```python import timeit import networkx as nx  def run_center():     return nx.center(nx.path_graph(5000))  execution_time = timeit.timeit(run_center, number=10) / 10  # Average over 10 runs print(f"Average execution time: {execution_time:.6f} seconds")  ```  ## Additional Changes   - Updates the test suite to validate the correctness of the new `_tree_center` approach.   - Fixes minor formatting inconsistencies in `tree_isomorphism.py`.    ## Impact   - **Performance boost** for large tree graphs.   - **More accurate documentation** regarding tree isomorphism complexity.    ## Testing    - **Unit Tests**:     The updated implementation of `_tree_center` has been tested with various types of tree graphs, including simple trees, balanced trees, and path graphs. The tests validate that the center calculation is correct and efficient.  - **Test Cases**:     - **Simple Tree**:       ```python     G = nx.Graph([(1, 2), (1, 3), (2, 4), (2, 5)])     assert nx.center(G) == [1, 2]     ```   - **Balanced Tree**:       For balanced trees, such as binary trees, the center should always be the root node:     ```python     for r in range(2, 5):         for h in range(1, 5):             G = nx.balanced_tree(r, h)             assert nx.center(G) == [0]     ```   - **Path Graphs**:       For path graphs of various sizes, the center is expected to be at or near the middle of the graph:     ```python     for n in range(1, 100):         G = nx.path_graph(n)         expected = {(n - 1) // 2, math.ceil((n - 1) / 2)}         assert set(nx.center(G)) == expected     ```
issue
Improving rooted_tree_isomorphism for deep trees#TITLE_END## Convert `generate_isomorphism` to an Iterative Implementation   I was looking at tree isomorphism logic when reviewing https://github.com/networkx/networkx/pull/7929 and realized implementation was using a recursive approach to compute the node mapping. This can be problematic with deep trees because it can lead to `RecursionError` exceptions.  @rossbar since you are already working on this module please let me know if you are already working on this particular improvement. Happy to drop this PR!  ## Summary    This PR refactors the `generate_isomorphism` function to replace its recursive implementation with an iterative approach using an explicit stack. The change is intended to prevent potential stack overflow issues when dealing with deeply nested trees (e.g., long path graphs).    ## Changes Made    - Converted `generate_isomorphism` from a recursive function to an iterative one using a stack.   - Ensured that child nodes are pushed onto the stack in reverse order to maintain the original left-to-right processing order.   - Removed the previous recursive implementation.    ## Reason for Change    The recursive implementation could cause a `RecursionError` for deep trees, such as long path graphs. This issue was observed in test cases with large trees (e.g., `test_long_paths_graphs`). By converting the function to an iterative version, we avoid excessive recursion depth and improve performance for large inputs.    ## Implementation Details    Previous recursive version:    ```python   def generate_isomorphism(v, w, M, ordered_children):       assert v < w       M.append((v, w))       for x, y in zip(ordered_children[v], ordered_children[w]):           generate_isomorphism(x, y, M, ordered_children)  ```   New iterative version:  ```python def generate_isomorphism(v, w, M, ordered_children):       stack = [(v, w)]       while stack:           curr_v, curr_w = stack.pop()           assert curr_v < curr_w           M.append((curr_v, curr_w))           stack.extend(               zip(reversed(ordered_children[curr_v]), reversed(ordered_children[curr_w]))           )   ```  ## Testing - Verified that all existing test cases pass - Added a new test test_long_paths_graphs to validate two long path graphs - Ensured that tree traversal order remains unchanged.  
issue
Speed up `connected_components` and `weakly_connected_components`#TITLE_END### Speed up `connected_components` and `weakly_connected_components`  This PR introduces lightweight optimizations to several connectivity-checking functions by adding early returns based on simple graph invariants. These heuristics help short-circuit computation in cases where connectivity can be ruled out without traversing the graph.  ### Summary of changes: - Adjusted BFS calls in `connected_components` and `weakly_connected_components` to reduce traversal overhead when many nodes have already been seen.  These changes preserve correctness while reducing unnecessary work, especially on dense graphs.  ### Performance improvements results  The optimization shows the most significant gains on disconnected graphs with large components, achieving up to a 367× speed-up for n=1000. This case is artificially generated to make current version need to visit the same nodes in a connected component multiple times. These are the types of cases where optimization works best.  For connected and random graphs, performance changes are generally smaller, often within a ±10% range. In a few low-n random graph cases, the optimized version was marginally slower, likely due to overhead not offset by structural gains.   Overall, the optimization is highly effective in worst-case disconnected scenarios while maintaining neutral or slightly improved performance elsewhere.  #### Single Node + Complete Component (Disconnected, 100 runs)  | n    | Without Optimization (s) | With Optimization (s) | Speed-up | |------|---------------------------|------------------------|----------| | 10   | 0.000008                  | 0.000004               | 2.00× (faster) | | 100  | 0.000552                  | 0.000017               | 32.47× (faster) | | 1000 | 0.049941                  | 0.000136               | 367.21× (faster) |   #### Random Graphs (p=0.01, 10000 runs each)  | n    | Seed | Without Optimization (s) | With Optimization (s) | Speed-up | |------|------|---------------------------|------------------------|----------| | 10   | 42   | 0.000008                  | 0.000015               | 0.53× (slower) | | 10   | 99   | 0.000007                  | 0.000008               | 0.88× (slower) | | 10   | 123  | 0.000007                  | 0.000009               | 0.78× (slower) | | 100  | 42   | 0.000048                  | 0.000047               | 1.02× (faster) | | 100  | 99   | 0.000047                  | 0.000053               | 0.89× (slower) | | 100  | 123  | 0.000051                  | 0.000049               | 1.04× (faster) | | 1000 | 42   | 0.000597                  | 0.000577               | 1.03× (faster) | | 1000 | 99   | 0.000785                  | 0.000733               | 1.07× (faster) | | 1000 | 123  | 0.000688                  | 0.000614               | 1.12× (faster) |  #### Connected Graphs (Complete Graphs, 10000 runs)  | n    | Without Optimization (s) | With Optimization (s) | Speed-up | |------|---------------------------|------------------------|----------| | 10   | 0.000003                  | 0.000003               | 1.00× (same) | | 100  | 0.000018                  | 0.000016               | 1.13× (faster) | | 1000 | 0.000149                  | 0.000142               | 1.05× (faster) |  #### Benchmark code  ```python  import networkx as nx import timeit  def measure_runtime(func, runs=100):     """Measure average runtime over multiple runs."""     timer = timeit.Timer(func)     times = timer.repeat(repeat=1, number=runs)     return times[0] / runs  def random_graph_test(ns, p, seeds, runs=100):     print(f"\n=== Random Graphs (p={p}, {runs} runs each) ===")     for n in ns:         for seed in seeds:             G = nx.erdos_renyi_graph(n, p, seed=seed)             def run():                 list(nx.connected_components(G))             t = measure_runtime(run, runs)             print(f"n={n}, seed={seed}: {t:.6f} seconds")  def connected_graph_test(ns, runs=100):     print(f"\n=== Connected Graphs (Complete Graphs, {runs} runs) ===")     for n in ns:         G = nx.complete_graph(n)         def run():             list(nx.connected_components(G))         t = measure_runtime(run, runs)         print(f"n={n}: {t:.6f} seconds")  def single_and_complete_component_test(ns, runs=100):     print(f"\n=== Single Node + Complete Component (Disconnected, {runs} runs) ===")     for n in ns:         G = nx.Graph()         G.add_node(0)         G.add_edges_from((i, j) for i in range(1, n) for j in range(i + 1, n))         def run():             list(nx.connected_components(G))         t = measure_runtime(run, runs)         print(f"n={n}: {t:.6f} seconds")  if __name__ == "__main__":     Ns = [10, 100, 1000]     P = 0.01     SEEDS = [42, 99, 123]      random_graph_test(Ns, P, SEEDS, runs=10_000)     connected_graph_test(Ns, runs=10_000)     single_and_complete_component_test(Ns, runs=100) ```
issue
Fixing nx.diameter inconsistent results with usebounds=True#TITLE_END# Did a random sample comparison of the output of `nx.diameter` function when passing `usebounds=True` and I ended up finding instances where both algorithms don't match when they are expected to compute the same result (See https://github.com/networkx/networkx/issues/7948)  ```python     def test_ale(self):         import numpy as np         seed = 1         rng = np.random.RandomState(seed=seed)         G = nx.erdos_renyi_graph(10, 0.25, seed=seed)         for u, v in G.edges():             G[u][v]['w'] = rng.randint(0, 1000)         assert nx.diameter(G, weight='w') == nx.diameter(G, usebounds=True, weight='w') ```  Besides this issue, we should incorporate these types of randomized tests for certain algorithms/optimizations where they apply.  ### Current Behavior  ```     def test_ale(self):         import numpy as np         seed = 1         rng = np.random.RandomState(seed=seed)         G = nx.erdos_renyi_graph(10, 0.25, seed=seed)         for u, v in G.edges():             G[u][v]['w'] = rng.randint(0, 1000) >       assert nx.diameter(G, weight='w') == nx.diameter(G, usebounds=True, weight='w') E       AssertionError: assert 1972 == 1257 E        +  where 1972 = <function diameter at 0x103aa1a80>(<networkx.classes.graph.Graph object at 0x128636350>, weight='w') E        +    where <function diameter at 0x103aa1a80> = nx.diameter E        +  and   1257 = <function diameter at 0x103aa1a80>(<networkx.classes.graph.Graph object at 0x128636350>, usebounds=True, weight='w') E        +    where <function diameter at 0x103aa1a80> = nx.diameter ```  ## Root cause  Old code was initializing upper bounds based on the unweighted case where `N` is always higher than any shortest path in the network.  ```python     # status variables     ecc_lower = dict.fromkeys(G, 0)     ecc_upper = dict.fromkeys(G, N)     candidates = set(G)      # (re)set bound extremes     minlower = N     maxlower = 0     minupper = N     maxupper = 0 ```  We can easily fix this replacing `N` by `math.inf`.  ```python     # status variables     ecc_lower = dict.fromkeys(G, 0)     ecc_upper = dict.fromkeys(G, math.inf)     candidates = set(G)      # (re)set bound extremes     minlower = math.inf     maxlower = 0     minupper = math.inf     maxupper = 0 ```  ## Testing  We formalize method used to find bug in the first place:  ```python     def test_use_bounds_on_off_consistency(self):         """Test for consistency of distance metrics when using usebounds=True.          We validate consistency for `networkx.diameter`, `networkx.radius`, `networkx.periphery`         and `networkx.center` when passing `usebounds=True`. Expectation is that method         returns the same result whether we pass usebounds=True or not.          For this we generate random connected graphs and validate method returns the same.         """         seeds = list(range(10))         ns = list(range(10, 20))         probs = [x / 10 for x in range(0, 10, 2)]         methods = [nx.diameter, nx.radius, nx.periphery, nx.center]         max_weight = [5, 10, 1000]         for seed, n, prob in itertools.product(seeds, ns, probs):             rng = np.random.RandomState(seed=seed)             # we compose it with a random tree to ensure graph is connected             G = nx.compose(                 nx.random_labeled_tree(n, seed=seed),                 nx.erdos_renyi_graph(n, prob, seed=seed),             )             for f in methods:                 # checking unweighted case                 assert f(G) == f(G, usebounds=True)                 for w in max_weight:                     for u, v in G.edges():                         G[u][v]["w"] = rng.randint(0, w)                     # checking weighted case                     assert f(G, weight="w") == f(G, weight="w", usebounds=True) ```   
issue
Clarify subgraph node/edge order is not preserved#TITLE_END#Based on discussions from https://github.com/networkx/networkx/issues/8054, users may expect subgraphs to preserve node and edge order. This updates the documentation to clarify that order is not guaranteed to be maintained when creating subgraphs.
issue
Clarifying backend graph class interface is_directed+is_multigraph#TITLE_END#This PR is a follow-up from discussion https://github.com/networkx/networkx/issues/8030. It makes two changes to the backend interface documentation:  1. Fixes a typo in the description of the BackendInterface object 2. Clarifies backend graph interface requirements: Adds an explanation that backend graph objects are required to implement the `is_directed()` and `is_multigraph()` methods and its relation with `@not_implemented_for` decorator.  
issue
nx.diameter inconsistent results with usebounds=True#TITLE_END#Did a random sample comparison of the output of `nx.diameter` function when passing `usebounds=True`.  I ended up finding instances where both algorithms don't match when they are expected to compute the same result.  ```python     def test_ale(self):         import numpy as np         seed = 1         rng = np.random.RandomState(seed=seed)         G = nx.erdos_renyi_graph(10, 0.25, seed=seed)         for u, v in G.edges():             G[u][v]['w'] = rng.randint(0, 1000)         assert nx.diameter(G, weight='w') == nx.diameter(G, usebounds=True, weight='w') ```  Besides this issue, we should incorporate these types of randomized tests for certain algorithms/optimizations where they apply.  ### Current Behavior  ```     def test_ale(self):         import numpy as np         seed = 1         rng = np.random.RandomState(seed=seed)         G = nx.erdos_renyi_graph(10, 0.25, seed=seed)         for u, v in G.edges():             G[u][v]['w'] = rng.randint(0, 1000) >       assert nx.diameter(G, weight='w') == nx.diameter(G, usebounds=True, weight='w') E       AssertionError: assert 1972 == 1257 E        +  where 1972 = <function diameter at 0x103aa1a80>(<networkx.classes.graph.Graph object at 0x128636350>, weight='w') E        +    where <function diameter at 0x103aa1a80> = nx.diameter E        +  and   1257 = <function diameter at 0x103aa1a80>(<networkx.classes.graph.Graph object at 0x128636350>, usebounds=True, weight='w') E        +    where <function diameter at 0x103aa1a80> = nx.diameter ```  ### Expected Behavior  Test should pass as output should be the same.  ### Steps to Reproduce  Add test and run `pytest -k test_ale`  Python version: Python 3.12.7 NetworkX version: I'm at commit `1af2820e3710526248c64d981488f83c3c32e056`   
issue
Fixing Tarjan's strongly connected components algorithm implementation to have O(|E|+|V|) time complexity instead of O(|E|^2/V)#TITLE_END#### The issue The previous implementation traversed the same edges multiple times harming the overall time complexity of the algorithm. This is because if we look at the following lines in current implementation: ``` for w in neighbors[v]:     if w not in preorder: ``` the for loop is executed once for each neighbor of `v`, and therefor the if statement is executed a quadratic number of time per vertex (quadratic in the amount of neighbors). This can lead to cubical complexity with respect to the nodes in the worst case. Moreover, it can be proven that the complexity is `O(E^2/V)` which can be cubical on the vertices as long as the amount of edges is quadratical with respect to the amount of nodes (See complexity proof below).  ### The change In order to avoid traversing the same neighbors every time, we can store a neighbor iterator per vertex instead of iterating the list from the beginning every time. The change consists in only two lines:  ``` neighbors = {v: iter(G[v]) for v in G} ... for w in neighbors[v]: ```  ### Testing  I did a couple of experiments to test the running time in practise, for example: ``` >> G = fast_gnp_random_graph(100, 0.01, directed=1) >> len(G) 100 >> len(G.edges) # not really dense 101 >> l1 = list(strongly_connected_components(G)) >> l2 = list(strongly_connected_components2(G)) >> l1 == l2 True >> len(l1) # many components, almost single node components 92 >>import time   def test_scc(f):        s = time.time()        list(f(G))        e = time.time()        return e - s >> sum(test_scc(strongly_connected_components) for _ in range(100000)) 31.160969018936157 >> sum(test_scc(strongly_connected_components2) for _ in range(100000)) # 20% faster 25.84955143928528 ```  ### Complexity proof ![image](https://user-images.githubusercontent.com/13503925/151784929-a975d7bd-051d-433e-8816-6ae90e94e1e3.png)  (https://docs.google.com/document/d/168EXjtMR8ge3Z-cfdl8X9HxESHsgBmAJDVicUZ7q_5o)
comment
Thanks! Can you add the snippet as a unit test? Also, I think that instead of setting the last value to 1, it would be cleaner if we compute all the sums and then normalize in a second pass.
comment
Thanks! The unit test was failing due to depending on numpy so I took the liberty of updating it with: ``` In [10]: nx.utils.cumulative_distribution([0.1] * 100)[-1] Out[10]: 1.0000000000000007 ```
comment
I agree that floating point precision errors are unavoidable. But I'm still +1 on the PR because it fixes a fundamental property of cdf
comment
Thank you folks!
comment
LGTM!
comment
One way we could solve this is sorting scc output by the Graph order, so we don't need to assume the nodes are comparable. To get that order it is a matter of creating a dict out of enumerate(G) output.  That adds an extra log complexity but it should be diluted by Johnson's complexity. So performance impact should be negligible.
comment
LGTM too!
comment
Why not removing start as an entry on the output? If it is not defined for start, why define an entry for it?
comment
I'm +1 on removing it from the dictionary. Since the start is a parameter the user won't fully lose the information
comment
LGTM!
comment
Many algorithms don't work with floating points. The moment you use them here your solution becomes an approximation. I'm +1 on Dan's comment on multiplying by a big N and converting to int.  I see how this can be a common pain point for users. However the problem comes from using floating points and expecting exact results.  Many algorithms will have the same issue, for example Dijkstra's, so I don't think we should update all numeric comparisons in NetworkX to allow for a tolerance.   What we could do here is provide more flexibility for the capacity and allow users to specify a function (like we do for Dijkstra's and cost). This way users don't need to modify the whole input graph. Moreover, we could also update the tutorial with considerations on using floating point as algorithm inputs.
comment
Thanks! Can you clear the unrelated files you committed?
comment
> Doing so would change behavior for weighted graphs. When edges have a `"weight"` attribute, it is used in calculating the distances - I don't think that is the intention here, so this strikes me (without any real expertise on the Mehlhorn algorithm) as incorrect. >  > If the motivation here is to represent distance as the number-of-hops-between-nodes instead of the length of the node sequence, then I don't think the change is necessary. This scenario strikes me as a distinction without a difference - so long as the path representation is self-consistent.  I think the PR change makes sense and it's consistent with other methods. Current implementation seems to focus only on the unweighted case. If you check MST method calls, weight attribute is never propagated.  @Hadrien-Cr can you also propagate weight keyword to the minimum spanning tree computations? Adding unit tests here would help to catch these
comment
Looks good to me, no more comments from my side!
comment
@dschult are we good to merge or should we get more reviewers? 
comment
> Another note: From some quick profiling, the two most expensive operations were: > - `generate_random_paths` (~38%) > - calculating path similarities (the loop) (~62%) >  > On a 10k node graph, this looks roughly like: > - 52 seconds for `generate_random_paths` > - 85 seconds for the path similarity loop >  > Trying something out to see if we can optimize generate_random_paths since it's the common denominator between both algorithms.  Is your graph sparse? I see generate random path creates an adjacency matrix, which might be inefficient for sparse graphs.
comment
Does it make sense to have this method discoverable from the tree module too?
comment
I like both! For some reason "neighs" sounds very awkward to me but I'm fine with "dists". I like dir but the naming conflict is annoying.
comment
@rossbar what about adj instead of neighbors?
comment
Ah right, it would be adjs which is also awkward!
comment
I think the right thing to do is to fail for complete graphs. The concept is not defined for them.
comment
LGTM too. If you still have the it, it would be good to include asv output on the description 
comment
If you want to optimize for dense cases you can do the same trick as in https://github.com/networkx/networkx/pull/7971. What do you think? ```     post = list(nx.dfs_postorder_nodes(G.reverse(copy=False), source=source))     n = len(post)     seen = set()     while post and len(seen) < n:         r = post.pop()         if r in seen:             continue         new = {r}         seen.add(r)         stack = [r]         while stack and len(seen) < n:             v = stack.pop()             for w in G._adj[v]:                 if w not in seen:                     new.add(w)                     seen.add(w)                     stack.append(w)         yield new ```
comment
Seems like it's much better now!  ``` n=10, p=1.0 fast_kscc time: 0.0076 seconds networkx kosaraju time: 0.0008 seconds tarjan scc time: 0.0006 seconds ale scc time: 0.0002 seconds networkx scc time: 0.0017 seconds  n=100, p=1.0 fast_kscc time: 0.0039 seconds networkx kosaraju time: 0.0065 seconds tarjan scc time: 0.0043 seconds ale scc time: 0.0020 seconds networkx scc time: 0.0091 seconds  n=10, p=0.1 fast_kscc time: 0.0001 seconds networkx kosaraju time: 0.0011 seconds tarjan scc time: 0.0001 seconds ale scc time: 0.0004 seconds networkx scc time: 0.0005 seconds  n=10, p=0.01 fast_kscc time: 0.0001 seconds networkx kosaraju time: 0.0001 seconds tarjan scc time: 0.0000 seconds ale scc time: 0.0000 seconds networkx scc time: 0.0000 seconds  n=10, p=0.001 fast_kscc time: 0.0001 seconds networkx kosaraju time: 0.0001 seconds tarjan scc time: 0.0063 seconds ale scc time: 0.0006 seconds networkx scc time: 0.0001 seconds  n=10, p=0.0001 fast_kscc time: 0.0001 seconds networkx kosaraju time: 0.0009 seconds tarjan scc time: 0.0000 seconds ale scc time: 0.0001 seconds networkx scc time: 0.0000 seconds  n=100, p=0.1 fast_kscc time: 0.0012 seconds networkx kosaraju time: 0.0010 seconds tarjan scc time: 0.0017 seconds ale scc time: 0.0010 seconds networkx scc time: 0.0019 seconds  n=100, p=0.01 fast_kscc time: 0.0002 seconds networkx kosaraju time: 0.0044 seconds tarjan scc time: 0.0002 seconds ale scc time: 0.0009 seconds networkx scc time: 0.0007 seconds  n=100, p=0.001 fast_kscc time: 0.0002 seconds networkx kosaraju time: 0.0013 seconds tarjan scc time: 0.0001 seconds ale scc time: 0.0002 seconds networkx scc time: 0.0002 seconds  n=100, p=0.0001 fast_kscc time: 0.0001 seconds networkx kosaraju time: 0.0005 seconds tarjan scc time: 0.0001 seconds ale scc time: 0.0001 seconds networkx scc time: 0.0002 seconds  n=1000, p=0.1 fast_kscc time: 0.0362 seconds networkx kosaraju time: 0.0337 seconds tarjan scc time: 0.0443 seconds ale scc time: 0.0176 seconds networkx scc time: 0.0438 seconds  n=1000, p=0.01 fast_kscc time: 0.0052 seconds networkx kosaraju time: 0.0110 seconds tarjan scc time: 0.0073 seconds ale scc time: 0.0076 seconds networkx scc time: 0.0083 seconds  n=1000, p=0.001 fast_kscc time: 0.0053 seconds networkx kosaraju time: 0.0161 seconds tarjan scc time: 0.0012 seconds ale scc time: 0.0016 seconds networkx scc time: 0.0041 seconds  n=1000, p=0.0001 fast_kscc time: 0.0042 seconds networkx kosaraju time: 0.0084 seconds tarjan scc time: 0.0027 seconds ale scc time: 0.0029 seconds networkx scc time: 0.0037 seconds   n=10000, p=0.1 fast_kscc time: 8.3025 seconds networkx kosaraju time: 7.5332 seconds tarjan scc time: 10.6029 seconds ale scc time: 4.5603 seconds networkx scc time: 11.3966 seconds  n=10000, p=0.01 fast_kscc time: 1.0399 seconds networkx kosaraju time: 0.4223 seconds tarjan scc time: 0.5747 seconds ale scc time: 0.2562 seconds networkx scc time: 0.7033 seconds  n=10000, p=0.001 fast_kscc time: 0.0841 seconds networkx kosaraju time: 0.2050 seconds tarjan scc time: 0.2217 seconds ale scc time: 0.1874 seconds networkx scc time: 0.1199 seconds  n=10000, p=0.0001 fast_kscc time: 0.0548 seconds networkx kosaraju time: 0.4363 seconds tarjan scc time: 0.0277 seconds ale scc time: 0.0332 seconds networkx scc time: 0.0450 seconds ```
comment
Is Erdos Renyi really representative here? How many SCCs do these random graphs usually have?  Do you have any benchmark suite covering the worst case? 
comment
Another way to do a multi-target is to add a sentinel node and multiple cost-0 edges connecting from each of your targets to the sentinel node. Then you call Dijkstra with one target and drop the last hop.   Ale  El mié, 23 jul 2025 a las 11:02, Tristan F.-R. ***@***.***>) escribió:  > *tristan-f-r* left a comment (networkx/networkx#703) > <https://github.com/networkx/networkx/issues/703#issuecomment-3109593089> > > I see the motivation behind why this design is tricky (it seems like the > most general candidate is to pass in a lambda for filtering target nodes, > which is how petgraph does it with astar > <https://docs.rs/petgraph/latest/petgraph/algo/astar/fn.astar.html>), > though a "multi target" dijkstra function really helps when doing a > dijkstra call on a large graph but only on a few select, close-together > nodes. > > — > Reply to this email directly, view it on GitHub > <https://github.com/networkx/networkx/issues/703#issuecomment-3109593089>, > or unsubscribe > <https://github.com/notifications/unsubscribe-auth/ADHA3NLGAAVHG6QHVG5IYXL3J7E2LAVCNFSM6AAAAACB62O5V6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTCMBZGU4TGMBYHE> > . > You are receiving this because you are subscribed to this thread.Message > ID: ***@***.***> > 
comment
But yeah, the current interface could be extended to follow petgraph's pattern. Target could be either None, str, Callable, if Callable, it will return true once method returns True for that node.  El mié, 23 jul 2025 a las 12:02, Alejandro Candioti ***@***.***>) escribió:  > Another way to do a multi-target is to add a sentinel node and multiple > cost-0 edges connecting from each of your targets to the sentinel node. > Then you call Dijkstra with one target and drop the last hop. > > > Ale > > El mié, 23 jul 2025 a las 11:02, Tristan F.-R. ***@***.***>) > escribió: > >> *tristan-f-r* left a comment (networkx/networkx#703) >> <https://github.com/networkx/networkx/issues/703#issuecomment-3109593089> >> >> I see the motivation behind why this design is tricky (it seems like the >> most general candidate is to pass in a lambda for filtering target nodes, >> which is how petgraph does it with astar >> <https://docs.rs/petgraph/latest/petgraph/algo/astar/fn.astar.html>), >> though a "multi target" dijkstra function really helps when doing a >> dijkstra call on a large graph but only on a few select, close-together >> nodes. >> >> — >> Reply to this email directly, view it on GitHub >> <https://github.com/networkx/networkx/issues/703#issuecomment-3109593089>, >> or unsubscribe >> <https://github.com/notifications/unsubscribe-auth/ADHA3NLGAAVHG6QHVG5IYXL3J7E2LAVCNFSM6AAAAACB62O5V6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTCMBZGU4TGMBYHE> >> . >> You are receiving this because you are subscribed to this thread.Message >> ID: ***@***.***> >> > 
comment
@tristan-f-r I added documentation on the sentinel approach, see https://networkx.org/documentation/latest/reference/algorithms/shortest_paths.html#notes-on-multi-target-shortest-path-queries
comment
This implementation is storing all triangles, which means memory consumption is cubical on the amount of nodes in the worst case. I know in NetworkX you cannot depend on ordering the nodes but you can do a linear memory solution.  You assign an incremental id to each node as you see them for the first time. Then you only yield the ones with form (u, v, w) where id(u) < id(v) < id(w).
comment
Btw, let's update the description before shipping this
comment
I think the description is for a previous approach? 
comment
I'm confused. I don't see any triangle count method?
comment
I see some variance on the measurements of asv. You should probably retry your profiling making sure your computer is not overloaded with other tasks 
comment
Any defensive mechanism that could be placed here? So it fails to load backend but it does not crash the whole import
comment
Yes, I know we couldn't repro but I was wondering if we can skip invalid backend names here: ```python     backend_config = {}     for backend, info in backend_info.items():         if "default_config" not in info:             cfg = Config()         else:             cfg = info["default_config"]             if not isinstance(cfg, Config):                 cfg = Config(**cfg)         backend_config[backend] = cfg     backend_config = Config(**backend_config) ```  That is what's breaking backend loading:  ``` In [4]: Config(**{"bad-config": {}}) Traceback (most recent call last):    File /opt/homebrew/Cellar/ipython/9.0.2/libexec/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3549 in run_code     exec(code_obj, self.user_global_ns, self.user_ns)    Cell In[4], line 1     Config(**{"bad-config": {}})    File ~/workplace/networkx/networkx/utils/configs.py:82 in __new__     cls = dataclass(    File /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:1295 in wrap     return _process_class(cls, init, repr, eq, order, unsafe_hash,    File /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:1157 in _process_class     func_builder.add_fns_to_class(cls)    File /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:498 in add_fns_to_class     exec(txt, self.globals, ns)    File <string>:1     def __create_fn__(__dataclass_type_bad-config__,__dataclass_HAS_DEFAULT_FACTORY__,__dataclass_builtins_object__,__dataclass___init___return_type__,__dataclasses_recursive_repr):                                           ^ SyntaxError: invalid syntax ```  So we could prevent `backend_info` and `backends` to skip containing broken backend names
comment
We can emit a warning and ignore that backend from the dict of valid backends. To me that follows current approach of error handling in the backend module (for example, https://github.com/networkx/networkx/blob/main/networkx/utils/backends.py#L80).
comment
To check for name validity we can use `str.isidentifier`: ``` In [5]: str.isidentifier('nx-loopback') Out[5]: False  In [6]: str.isidentifier('nx_loopback') Out[6]: True ```
comment
A bit late to the party here but @Aditya-Shandilya1182 can you add unit tests that would fail without this fix?
comment
Don't you need to recreate the seed every time you call the method? Otherwise you are not really passing the same random state.  On Tue, Jun 3, 2025, 15:39 Ross Barnowski ***@***.***> wrote:  > *rossbar* left a comment (networkx/networkx#8095) > <https://github.com/networkx/networkx/issues/8095#issuecomment-2937490446> > > I suspect that by using this decorator, everytime one is trying to call > the Louvain partitioning, a new interface is instantiated, resulting in a > different partitioning even when the seed is set. > > If you use an integer seed, then the machinery is creating a consistent > random state (either with NumPy or random) at each call from that > integer, so there should be no variation. The only exception would be if > there were a call to either random or np.random directly, which I don't > see in the source code. > > For reproducibility, you should definitely pass in integer seeds (or > explicitly seeded random states, like seed=np.random.default_rng(my_seed)) > to ensure you are avoiding any sort of global random state. > > I'm still not convinced there's a problem that hasn't already been fixed > in subsequent NX versions - there's nothing we can do to help with bugs in > 2.8.8 or 3.1. > > — > Reply to this email directly, view it on GitHub > <https://github.com/networkx/networkx/issues/8095#issuecomment-2937490446>, > or unsubscribe > <https://github.com/notifications/unsubscribe-auth/ADHA3NLGLTJ62HI2VKSXOWT3BYPYVAVCNFSM6AAAAAB6QK6HA2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDSMZXGQ4TANBUGY> > . > You are receiving this because you are subscribed to this thread.Message > ID: ***@***.***> > 
comment
> Thank you for your work but we have a [deprecation policy](https://github.com/networkx/networkx/blob/15571205e3d2c6327aa5c4294725398ea227e25b/doc/developer/deprecations.rst)-- we show deprecation warnings to users for 2 release cycles before removing an algorithm or making any code breaking change. This kind of explicit error handling is not needed. Thanks!  I'm +1 on this change, it improves user experience. Sure, the warning is there for 2 minor versions but users don't necessarily update versions 1 by 1. Many times you have to make big updates when working in projects with multiple dependencies (and conflicts!).
comment
Do we need to update contributors guidelines or something?
comment
> > Amazing! Implementation looks good to me, no further comments there. I added other minor comments I missed for the unit tests. > > I think we should also polish PR description a bit. Like having different sections: > > ``` > > * What you are adding > >  > > * Why you are adding it > >  > > * Implementation details. You can also include a brief explanation of the algorithm and quote the paper. > >  > > * How you tested it > > ``` > >  > >  > >      > >        > >      > >  > >        > >      > >  > >      > >    > > You can use this one as an example #7945 >  > Should I edit the original description?  Yeah, exactly 
comment
It would be great to deeply understand the relationship between spanning trees and CDS. We could even leverage the random spanning tree functionality to derive a random minimal CDS.  What's not clear to me is how to guarantee that the dominating sets are drafted uniformly.
comment
 > Note that the "minimum" for CDS is just the smallest number of nodes, while the "minimum" for MST is the smallest sum of the weighted edges in the tree. So there might not be any relation at all.  Correct, that's why I said just "spanning tree". Each ST could induce a minimal (not minimum) CDS once you remove the leaves and some other nodes maybe?  > **Most desirable**: are we guaranteed to get a MCDS by removing all leaves from all MSTs? (I suspect not, especially if they are weighted MSTs) **Pretty good**: are we likely in most cases to get close to a MCDS using this approach? How close? How do you even measure how close a CDS is from a MCDS?  Regarding "pretty good" there's this paper https://arxiv.org/abs/2303.03125#:~:text=For%20an%20m%2Dedge%20connected,dear%20friend%2C%20Professor%20Takao%20Nishizeki. If I understand that correctly, the algorithm finds a spanning tree with at most 2x more leaves than optimal solution. Meaning that you can probably use that algo to induce a CDSs of size S where |G|-|S| is at most 2x from optimum.  > I believe this is ready to be merged.  +1 Good job @GalMichaeli!
comment
Nice! Can you add an explicit test case passing a generator?
comment
This is making some unit tests run in parallel, correct? If that's the case it's worth checking if tests are thread-safe. Sometimes developers modify global variables and parallelism creates flaky tests.
comment
> The examples are found automatically IIUC. Sphinx gallery takes care of that.  I meant the content being outdated once you add a new layout method. Could be as simple as having a test  ``` def test_documented_methods():     """Checks that all supported methods are included in the docs. Before changing this check please ensure..."""     assert nx.supported_layout_methods() == ["auto", ...] ```
comment
Great job, thanks for the deep dive! I checked the code and what you are saying makes sense to me. We have some 20 years old code here 😅  Can you update the PR description with all your analysis so it's easier to track in the future? Code-wise I don't have any other comment 
comment
> Thanks for your reply. >  > I thought doing the PR in a separate PR and inheriting the structure you suggested would be a good idea, but I realized that it would be better to do it in the same PR. So I’ve made the changes in this PR. >  > First, I found that the `try/except` block was introduced in the following commit: >  > https://github.com/networkx/networkx/commit/0723fcdd9193ebc9e7ddd61e5b37e4aee0448947 >  > Here is the corresponding file from that commit: >  > https://github.com/networkx/networkx/blob/0723fcdd9193ebc9e7ddd61e5b37e4aee0448947/networkx/drawing/layout.py >  > I believe the `try/except` block is unnecessary. > A `ValueError` can occur in the following situations: >  > * `pos` is a NumPy array and `if pos == None` is evaluated >   (Raises: `ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`) >  > * `fixed` is a NumPy array and `if fixed == None` is evaluated >   (Same error as above) >  > * `dim` is set to -1, leading to calls like `np.random.random((nnodes, dim))` or `np.zeros(dim)` >   (Raises: `ValueError: negative dimensions are not allowed`) >  > However, the first two issues are already addressed in the current code using `if pos is None` and `if fixed is None`, so the `try/except` block is redundant. > For the third case, this ValueError is raised in the current version of NetworkX, so it is not related to the try/except block. >  > --- >  > Based on this, I fixed the bug and cleaned up the code as suggested in the current PR. >  > I also tested the code with the following configurations and confirmed it works successfully: >  > (Please refer to [here](https://github.com/HirokiHamaguchi/Initial_Placement_for_Fruchterman-Reingold_Force_Model_with_Coordinate_Newton_Direction/blob/474bee4702e2d2a21f1b015ecc0d86cae11fcf63/app/test_for_issue.ipynb) for the results) >  > 1. Different `method` values: >  >    * `"auto"` (len(G)=499 and 500) >    * `"energy"` >    * `"force"` >  > 2. Providing an initial layout via the `pos` argument >  > 3. Fixing certain nodes using the `fixed` argument >  > 4. Changing layout dimensionality with the `dim` argument: >  >    * A 3D layout using `dim=3` >    * An invalid layout with `dim=-1` to confirm error handling >  > --- >  > I would appreciate it if you could review the current PR.  @dschult I meant including part of this context on why it is safe to remove try except. Would be nice to see that directly in description  
comment
> Thanks for the quick fix @HirokiHamaguchi ! >  > Since this slipped through review the first time, I thought it was worth adding an explicit unit test for the method selection logic[^1] based on the number-of-nodes heuristic. I took the liberty of pushing such a test up... essentially, it works by computing the seeded spring_layout twice: once with `method="auto"` and once with the method set explicitly based on the expected method given the number of nodes (see the first parametrization). It's not an inexpensive test, but I can't think of another way to probe the number-of-nodes heuristic other than generating inputs that are greater than the limit! >  > Anyways: +1 from me for the code improvements, so I approve. @dschult @amcandio could you take a look and make sure you're okay with the test? The second parametrization could be removed but was inspired by the types of tests @HirokiHamaguchi had set up in the linked notebook. I'm also happy to `pytest.mark` it slow. LMK! >  > [^1]: FWIW the test fails on `main` but passes here, so it checks the intended behavior!  Good call actually. Test looks good to me!
comment
Technically a stack is a LIFO queue. What is the naming used in the rest of the code?
comment
Another thing to consider: even if methods don't require nodes to be sizeable, removing it from the docs means somehow changing the contract. In case the restriction of Sized is needed in the feature, adding it is technically not backwards compatible.
comment
What use case do you see where there is a lot of value on receiving a generator of nodes?
comment
> > Another thing to consider: even if methods don't require nodes to be sizeable, removing it from the docs means somehow changing the contract. In case the restriction of Sized is needed in the feature, adding it is technically not backwards compatible. >  > Currently, the size of an argument, when used, only validates that there are no duplicates. So assuming we just drop this check, the change in the contract would be to switch from raising an error when there are duplicates, to automatic deduping. It seems very unlikely, (but of course possible) that a user would currently be using the error raised as a flag for there being duplicates.  Yeah, seems very unlikely and an odd abuse of interface.   > The second option is to check this without calling `len` on the input argument directly by first casting it as a list when required. Then the list and set lengths can be compared. >  > > What use case do you see where there is a lot of value on receiving a generator of nodes? >  > Streaming nodes from a file or web api, perhaps? Although this doesn't seem particularly useful unless it's a really large file. I could also see a case where node $n$ depends on all previous nodes, in which case a generator might be useful. >   Yeah but those end up in memory anyway, right? I guess we would avoid creating a new set/list.  The main advantage is when the lists are so big that we save a bunch of memory by receiving a generator. But given that we are loading them into sets and graphs are also in memory, I don't see much gain from the generators for these algorithms.  It could impact you negatively if in the future you want to add an algorithm that is better off with a container than a generator. It will force you to assume a generator and then load it into memory.
comment
@Rajendraprasad7 can you provide a step by step example so it's easier to review the change? 
